[{"title":"Typora+Github+PicGo搭建个人免费图床","path":"/2025/06/13/2025/06/Typora-Github-PicGo/","content":"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 输入密码，查看文章","tags":["主题装修"],"categories":["装修日记"]},{"title":"Hello World","path":"/2025/06/09/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new My New Post More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","tags":["标签云"],"categories":["测试"]},{"title":"Hexo-Stellar主题装修日记(一)","path":"/2025/06/09/2025/06/theme-design1/","content":"前言记录一下自己从默认主题样式到现在本网站的样子中间都修改了哪些地方，也作为完善博客期间的备份。 博客引用资源本地资源文件夹将头像、图标、css、js等文件放在source下 静态资源本地化有两次发现通过jsdelivr引入的静态资源会失效，为了网站的稳定性，决定将所有通过jsdelivr引入的静态资源保存到本地，防止失效后网站无法访问。 引用落霞孤鹜字体tale/_config.ymlinject: head: - link rel=stylesheet href=https://npm.elemecdn.com/lxgw-wenkai-screen-webfont/style.css media=print onload=this.media=all #字体Copytale/_config.stellar.ymlstyle: font-family: body: LXGW WenKai Screen, sans-serifCopy 引用鸿蒙字体tale/_config.ymlinject: head: - link rel=preconnect href=https://s1.hdslb.com/ / - link rel=stylesheet href=//s1.hdslb.com/bfs/static/jinkela/long/font/regular.css media=all onload=this.media=all / #鸿蒙正常字体 - link rel=stylesheet href=//s1.hdslb.com/bfs/static/jinkela/long/font/medium.css media=all onload=this.media=all / #鸿蒙加粗字体Copytale/_config.stellar.ymlstyle: font-family: body: HarmonyOS_Regular # 鸿蒙正常字体 #body: HarmonyOS_Regular # 鸿蒙加粗字体Copy 博客基本配置基本信息tale/_config.yml# Sitetitle: SFZhang #网站名称avatar: /customize/images/sfzhang.jpg #博客头像favicon: /customize/images/sfzhang.jpg #网站图标subtitle: SFZhangs blog | blog.sfzhang.cn #鼠标移入翻转效果description: 一个积极生活的人keywords:author: SFZhang #博客作者language: zh-CN #博客语言：en、zh-CNtimezone: Copy 显示导航tale/_config.stellar.ymlsidebar: menu: post: [btn.blog](/) wiki: [btn.wiki](/) friends: [友链](/) about: [关于](/)Copy 图片放大（fancybox）其中selector设置为需要放大图片的HTML选择器： tale/_config.ymltag_plugins: # % image % image: fancybox: true # true, false parse_markdown: true # 把 markdown 格式的图片解析成图片标签######## JS Plugins ########plugins: # https://fancyapps.com/docs/ui/fancybox/ # available for % image xxx % fancybox: enable: true #js: /customize/js/fancybox.umd.js css: /customize/css/fancybox.css js: https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js #css: https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css # 可以处理评论区的图片（不支持 iframe 类评论系统）例如： # 使用twikoo评论可以写: .tk-content img:not([class*=emo]) # 使用waline评论可以写: #waline_container .vcontent img selector: .swiper-slide img, .md-text.content pimg, .md-text.content li img , .wl-content img, .image-bg img # 多个选择器用英文逗号隔开 #selector: .swiper-slide img # 多个选择器用英文逗号隔开Copy 侧边栏侧边栏底部按钮tale/_config.stellar.ymlfooter: social: QQ: icon: img src=/customize/svg/contact.svg/ url: https://wpa.qq.com/msgrd?v=3uin=1119716380site=qqmenu=yesjumpflag=1 github: icon: img src=/customize/svg/github.svg/ url: https://github.com/z23654262 #iconfont: # icon: img src=/customize/svg/iconfont.svg/ # url: https://www.iconfont.cn/ unsplash: icon: img src=/customize/svg/unsplash.svg/ url: https://unsplash.com/@z23654262 train: icon: img src=/customize/svg/train.svg/ url: https://unsplash.com/@z23654262 Moon: icon: img id=ThemeM src=/customize/svg/moon.svg/ url: javaScript:void(永夜); Sun: icon: img id=ThemeL src=/customize/svg/sun.svg/ url: javaScript:void(永昼); #AI: # icon: img id=ThemeAI src=/customize/svg/auto.svg/ # url: javaScript:void(跟随系统);Copy 小组件tale/source/_data/widget,ymlwelcome: layout: markdown title: 欢迎来到SFZhang的知识库 content: | 不以物喜，不以己悲 script src=https://v1.hitokoto.cn/?c=iencode=jsselect=%23hitokoto defer=/script p一诗：span id=hitokoto/span/pyiyan: layout: markdown title: 一诗 content: | script src=https://v1.hitokoto.cn/?c=iencode=jsselect=%23hitokoto defer=/script pspan id=hitokoto/span/ptimeline: layout: timeline title: 生活碎片 api: https://api.github.com/repos/z23654262/blog-life/issues?per_page=10 # 若你想限制数量，在api链接后面加上?per_page=1指限制为1条 user: # 是否过滤只显示某个人发布的内容，如果要筛选多人，用英文逗号隔开 hide: # title,footer # 隐藏标题或底部 # 此功能需要 Stellar v1.13.0ghuser: layout: ghuser username: z23654262 # your github login username avatar: true # show avatar or not menu: true # show menu or not#搜索search_blog: layout: search filter: /blog/ # or /posts/ ... placeholder: 文章搜索search_all_docs: layout: search filter: /wiki/ placeholder: 文档系统搜索search_docs: layout: search filter: auto placeholder: 文档内搜索Copy 生活碎片添加页面添加首页按钮tale/_config.stellar.ymlpost-index: # 近期发布 分类 标签 归档 and ... 生活碎片: /lifeCopy 导航高亮问题tale/node_modules/hexo-theme-stellar/layout/_partial/main/navbar/list_post.ejsif (full_url_for(page.path) == full_url_for(obj[key]))Copy 修改为 tale/node_modules/hexo-theme-stellar/layout/_partial/main/navbar/list_post.ejsif (full_url_for(page.path) == full_url_for(obj[key]) + /index.html)Copy 新建github仓库并添加一条issue 编辑生活碎片页面tale/source/life/index.md---title: menu_id: post #侧边栏首页高亮breadcrumb: false # 隐藏面包屑导航post_list: true # 显示首页导航date: 2023-10-10 10:34:34---% note color:orange 分享自己的生活碎片！ %% timeline api:https://api.github.com/repos/z23654262/blog-life/issues?direction=ascper_page=30 %% endtimeline %Copy 预览生活碎片页面 添加评论系统giscus新增github仓库新增blog-comments仓库并开启Discussions功能并勾选blog-commentsSettingsFeaturesDiscussions即可。 修改配置tale/_config.stellar.ymlcomments: service: giscus # giscus # https://giscus.app/zh-CN giscus: data-repo: xxx/xxx # [在此输入仓库] data-repo-id: # [在此输入仓库 ID] data-category: # [在此输入分类名] data-category-id: data-mapping: pathname data-strict: 0 data-reactions-enabled: 1 data-emit-metadata: 0 data-input-position: top # top, bottom data-theme: preferred_color_scheme data-lang: zh-CN data-loading: lazy crossorigin: anonymousCopy 测试giscus评论系统博客内评论： github仓库中Discussions： 添加waline评论系统waline官方教程 waline程序托管于vercel，数据存储使用learncloud国际版，域名使用waline.sfzhang.top二级域名 learncloud国际版设置 登录 或 注册 LeanCloud 国际版 并进入 控制台 点击左上角创建应用并起一个你喜欢的名字 (请选择免费的开发版) 进入应用，选择左下角的 设置 应用 Key。你可以看到你的 APP ID,APP Key 和 Master Key。请记录它们，以便后续使用。 vercel设置 点击Vercel，跳转至 Vercel 进行 Server 端部署。（如果登录无法访问github，则使用邮箱登录） 跳转后会自动机遇waline仓库进行初始化，只需要填写Vercel仓库名称即可。 点击顶部的 Settings - Environment Variables 进入环境变量配置页，并配置三个环境变量 LEAN_ID, LEAN_KEY 和 LEAN_MASTER_KEY 。它们的值分别对应上一步在 LeanCloud 中获得的 APP ID, APP KEY, Master Key。 环境变量配置完成之后点击顶部的 Deployments 点击顶部最新的一次部署右侧的 Redeploy 按钮进行重新部署。该步骤是为了让刚才设置的环境变量生效。 此时会跳转到 Overview 界面开始部署，等待片刻后 STATUS 会变成 Ready。此时请点击 Visit ，即可跳转到部署好的网站地址，此地址即为你的服务端地址。 Vercel绑定域名 点击顶部的 Settings - Domains 进入域名配置页，并输入需要绑定的域名 在阿里云处配置域名解析 博客配置文件tale/_config.staller.yml######## Comments ########comments: service: waline # beaudar, utterances, giscus, twikoo, waline, artalk # Waline # https://waline.js.org/ waline: js: https://unpkg.com/@waline/client@2.14.1/dist/waline.js css: https://unpkg.com/@waline/client@2.14.1/dist/waline.css # Waline server address url, you should set this to your own link serverURL: https://domain # If false, comment count will only be displayed in post page, not in home page commentCount: true # Pageviews count, Note: You should not enable both `waline.pageview` and `leancloud_visitors`. pageview: false # Custom emoji # emoji: # - https://unpkg.com/@waline/emojis@1.1.0/weibo # - https://unpkg.com/@waline/emojis@1.1.0/alus # - https://unpkg.com/@waline/emojis@1.1.0/bilibili # - https://unpkg.com/@waline/emojis@1.1.0/qq # - https://unpkg.com/@waline/emojis@1.1.0/tieba # - https://unpkg.com/@waline/emojis@1.1.0/tw-emoji # - https://unpkg.com/@waline/emojis@1.1.0/bmoji # 设置自己的图床服务，替换默认的 Base 64 编码嵌入（有体积大小限制），在评论中上传图片更加方便 # imageUploader: # 适配了兰空图床V1、V2版本 # 以兰空图床V1为例，下列填写内容为： # fileName: file # tokenName: Authorization # api: https://xxxxxx/api/v1/upload # token: Bearer xxxxxxxxxxxxxx # resp: data.links.url # 以兰空图床V2为例，下列填写内容为： # fileName: image # tokenName: token # api: https://xxxxxx/api/upload # token: xxxxxxxxxxxxxx # resp: data.url # fileName: # 根据版本二选一 # tokenName: # 根据版本二选一 # api: # 图床 api 地址 # token: # 图床验证 # resp: # 图片地址返回值的字段","tags":["主题装修"],"categories":["装修日记"]},{"title":"Hexo-Stellar主题装修日记(二)","path":"/2025/06/09/2025/06/theme-design2/","content":"给超长代码块增加滚动条#首先判断代码块是否过长，如果是，则设置最大高度并开启滚动。 新建 source/js/adjust-codeblock-height.js，添加以下内容： adjust-code-block-height.js document.addEventListener(DOMContentLoaded, function() // 选择所有的.md-text元素 var codeBlocks = document.querySelectorAll(.md-text); // 遍历每个.md-text元素 codeBlocks.forEach(function(block) // 检查是否包含.highlight类的子元素，且父元素高度超过500px var highlightBlocks = block.querySelectorAll(.highlight); highlightBlocks.forEach(function(highlightBlock) if (highlightBlock.clientHeight 800) highlightBlock.style.maxHeight = 300px; highlightBlock.style.overflow = auto; ); ); ); 以上代码代表如果代码框高度超过 800px，则开启折叠，折叠框最大高度为 300px。其中，可自行设置判断阈值 if (highlightBlock.clientHeight 800) 以及折叠后最大高度 highlightBlock.style.maxHeight = 300px;。 雪花特效#代码来自这里。我稍微做了一点修改，做成了一个按钮引入到主题中并用 localStorage 记录下雪状态，很简单的代码完美的解决了我的强迫症～ 博客已运行x天x小时x分钟#在网站页脚部分添加一个“博客已运行 x 天 x 小时 x 分钟”字样，显示效果： ![勉强运行x天x小时x分钟x秒](Hexo-Stellar主题装修二CleanShot 2024-04-16 at 21.51.07@2x-1749438579838-1030.webp)勉强运行x天x小时x分钟x秒 代码抄自这里，我为了调整样式加了一行代码 。在 _config.stellar.yml 里添加如下代码，其中 span class=runtime 中的类名 runtime 可自行设置。 footer: ... content: | # 支持 Markdown 格式 span id=runtime_span/span script type=text/javascript function show_runtime() window.setTimeout(show_runtime(), 1000); X = new Date(2024/01/01 17:00:00); // 网站开始运行的日期和时间 Y = new Date(); // 当前日期和时间 T = (Y.getTime() - X.getTime()); // 网站运行的总毫秒数 M = 24 * 60 * 60 * 1000; // 一天的毫秒数 a = T / M; // 总天数 A = Math.floor(a); // 总天数的整数部分 b = (a - A) * 24; // 总小时数 B = Math.floor(b); // 总小时数的整数部分 c = (b - B) * 60; // 总分钟数 C = Math.floor((b - B) * 60); // 总分钟数的整数部分 D = Math.floor((c - C) * 60); // 总秒数 runtime_span.innerHTML = ⏱️勉强运行 span class=runtime + A + 天 + B + 小时 + C + 分 + D + 秒/span; show_runtime(); /script 再在自定义的 css 文件里添加以下代码，其中 color 可设置为主题色 var(--theme-link) 或自行设置： .runtime font-weight: bold; color: #7F84A7; 页脚增加猫猫图片#显示效果： ![img](Hexo-Stellar主题装修二CleanShot 2024-04-17 at 19.09.44@2x-1749438579838-1034.webp) 首先，如果是使用本地图片，将图片上传到主题的资源文件夹，比如 source/asset/posts/keyboard.png 然后在主题配置文件的 _config.stellar.yml 中添加： footer: ... content: | # 支持 Markdown 格式 img src=/你的/图片/路径.png alt=描述文字 style=float: right; width: 60px; margin-left: 20px; 其中 float: right 限定图片右对齐，width:60px 限制图片大小，可自行调整。 外部链接后面显示图标#显示效果： ![外部链接图标](Hexo-Stellar主题装修二CleanShot 2024-04-16 at 22.09.38@2x-1749438579838-1038.webp)外部链接图标 方法一： WARNING 老方法依赖 cheerio 模块，可行，但似乎会带来一些网站加载过慢的问题，我现在已经开心地转用新方法了，把老方法摆在这里全当（水）记（字）录（数）。 新建 themes/stellar/scripts/filters/link-icon.js 文件，增加以下代码： //使用 cheerio 模块在文章中的外部链接后添加一个小图标：npm i cheerio --savehexo.extend.filter.register(after_render:html, function(html, data) const cheerio = require(cheerio); const $ = cheerio.load(html, decodeEntities: false); // 只选择article class=md-text content元素内的a标签 $(article.md-text.content a, footer.page-footer.footnote a).each(function() const link = $(this); const href = link.attr(href); //排除一些特殊的链接 if (!link.parents(div.tag-plugin.users-wrap).length !link.parents(div.tag-plugin.sites-wrap).length !link.parent(div.tag-plugin.ghcard).length !link.parents(div.tag-plugin.link.dis-select).length !link.parents(div.tag-plugin.colorful.note).length !link.parents(div.social-wrap.dis-select).length) // 确保链接的 href 属性存在，并检查其是否以 http 或 / 开头 if (href (href.startsWith(http) || href.startsWith(/))) link.html(link.html() + ` span style=white-space: nowrap;svg width=.7em height=.7em viewBox=0 0 21 21 xmlns=http://www.w3.org/2000/svgpath d=m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z fill=currentColor /path d=M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z fill=currentColor/svg/span`); //link.attr(target, _blank); // 可选：确保链接在新标签页打开 ); return $.html(); ); 方法二： TIP 用老方法配置完我总觉得使用 Cheerio 模块后会导致网站加载过慢，就又优化了一下。询问 ChatGPT 得知可以考虑不使用 Node.js 的服务器端处理，而是使用纯前端的方法来达到同样的效果，通过在客户端 JavaScript 中添加代码来实现类似的功能，而不是在 Hexo 的后端渲染过程中处理。（好了，可以卸载 cheerio 了） 下面的这段代码可以在页面加载完成后运行，它会查找指定元素中的链接，并在这些链接后添加一个图标。这种方法的好处是，它不需要服务端的处理，所有操作都在用户的浏览器内完成，可以减少服务器负担，并且避免可能因服务器端渲染引起的加载问题。此外，这种方法也提供了更好的用户体验，因为它不会延迟页面内容的显示。 新建source/js/link-icon.js 文件，填入以下内容： document.addEventListener(DOMContentLoaded, function () console.log(Document is ready.); const links = document.querySelectorAll(article.md-text.content a, footer.page-footer.footnote a); console.log(Links found:, links.length); links.forEach(function(link) console.log(Processing link:, link.href); const parentClasses = [tag-plugin.users-wrap, tag-plugin.sites-wrap, tag-plugin.ghcard, tag-plugin.link.dis-select, tag-plugin.colorful.note, social-wrap.dis-select]; let skip = false; parentClasses.forEach(pc = if (link.closest(`div.$pc`)) skip = true; console.log(Skipping link due to parent class:, pc); ); if (!skip) const href = link.getAttribute(href); console.log(Link href:, href); if (href (href.startsWith(http) || href.startsWith(/))) link.innerHTML += ` span style=white-space: nowrap;svg width=.7em height=.7em viewBox=0 0 21 21 xmlns=http://www.w3.org/2000/svgpath d=m13 3l3.293 3.293l-7 7l1.414 1.414l7-7L21 11V3z fill=currentColor /path d=M19 19H5V5h7l-2-2H5c-1.103 0-2 .897-2 2v14c0 1.103.897 2 2 2h14c1.103 0 2-.897 2-2v-5l-2-2v7z fill=currentColor/svg/span`; console.log(Icon added to link:, link.innerHTML); );); 这里做了两个筛选： const parentClasses = [tag-plugin.users-wrap, tag-plugin.sites-wrap, tag-plugin.ghcard, tag-plugin.link.dis-select, tag-plugin.colorful.note, social-wrap.dis-select]; 是被排除的类，可自行增减； if (href (href.startsWith(http) || href.startsWith(/))) 判断链接是否以 http 或 / 开头，如果不想给站内链接添加图标的话可以把后面的筛选条件去掉。 然后在主题文件 _config.stellar.yml 中引入： inject: head: ... - script src=/js/link-icon.js/script # 链接图标 增加参与讨论按钮#代码抄自星日语，最新主题已自带此功能。 适配 Obsidian Callouts 标注块语法#显示效果： ![img](Hexo-Stellar主题装修二CleanShot 2024-04-16 at 22.23.51@2x-1749438579838-1036.webp) 暗黑模式下的显示效果： ![img](Hexo-Stellar主题装修二CleanShot 2024-04-16 at 22.24.19@2x-1749438579839-1040.webp) 参考了 Hexo 博客适配 Obsidian 新语法，基础的设置请参考此链接。我暂时用不上其他功能，就把 callout 的样式搬来并做了一些修改。我个人还挺喜欢这个 callout 样式，比 quote 要好看而且添加也很方便，主要是可以和 Obsidian 打通，嘿嘿。 样式修改#原版的 callouts 标注块样式间距太大，我在此基础上改了 callout_blocks_common.css（不是很懂，写得很烂……但是能用）： :root--callout-note:68,138,255;--callout-abstract:0,176,255;--callout-info:0,184,212;--callout-tip:0,191,165;--callout-success:8,185,78;--callout-question:224,172,0;--callout-warning:255,145,0;--callout-failure:255,82,82;--callout-danger:255,23,68;--callout-bug:245,0,87;--callout-example:124,77,255;--callout-quote:158,158,158;--callout-radius:6px;--callout-border-opacity:0.5;--callout-title-bg-opacity:0.08.callout-fold:beforealign-self:center;content:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=16 height=16 viewBox=0 0 24 24 fill=none stroke=gray stroke-width=2 stroke-linecap=round stroke-linejoin=round class=chevron-downpath d=m6 9 6 6 6-6//svg).callout-folddisplay:flex;transform:rotate(-90deg);transition:.5s cubic-bezier(.075,.82,.165,1).custom-callout[open]summary.callout-foldtransform:rotate(0deg).custom-calloutsummaryborder-top-left-radius:var(--callout-radius);border-top-right-radius:var(--callout-radius);cursor:pointer;margin:0;padding:0.5rem 1rem.custom-calloutsummary::markercontent:.custom-calloutsummary:beforemargin-right:.5rem.custom-calloutsummary::-webkit-details-markerdisplay:none.callout-title--fsp: calc(17px - 1px);font-size: var(--fsp);display:flex;justify-content:space-between;font-weight:bold;.custom-callout.callout-bodybackground:transparent!important;border-left:none;margin:0!important;padding:.3rem 1rem;position:relative.custom-callout.callout-bodyp--fsp: calc(17px - 1px);font-size: var(--fsp);margin:8px 0.custom-callout.callout-bodypremargin:1.25rem -1rem.custom-callout.callout-bodypre:first-childmargin-top:-.75rem.custom-callout.callout-bodypre:last-childmargin-bottom:-.75rem.custom-callout.note,.custom-callout.seealsoborder-color:rgba(var(--callout-note),var(--callout-border-opacity)).custom-callout.notesummary,.custom-callout.seealsosummary background-color:rgba(var(--callout-note),var(--callout-title-bg-opacity)); color:rgba(var(var(--callout-note))).custom-callout.abstract,.custom-callout.summary,.custom-callout.tldrborder-color:rgba(var(--callout-abstract),var(--callout-border-opacity)).custom-callout.abstractsummary,.custom-callout.summarysummary,.custom-callout.tldrsummary background-color:rgba(var(--callout-abstract),var(--callout-title-bg-opacity)); color:rgba(var(--callout-abstract)).custom-callout.info,.custom-callout.todoborder-color:rgba(var(--callout-info),var(--callout-border-opacity)).custom-callout.infosummary,.custom-callout.todosummary background-color:rgba(var(--callout-info),var(--callout-title-bg-opacity)); color:rgba(var(--callout-info)).custom-callout.hint,.custom-callout.important,.custom-callout.tipborder-color:rgba(var(--callout-tip),var(--callout-border-opacity)).custom-callout.hintsummary,.custom-callout.importantsummary,.custom-callout.tipsummary background-color:rgba(var(--callout-tip),var(--callout-title-bg-opacity)); color:rgba(var(--callout-tip)).custom-callout.check,.custom-callout.done,.custom-callout.successborder-color:rgba(var(--callout-success),var(--callout-border-opacity)).custom-callout.checksummary,.custom-callout.donesummary,.custom-callout.successsummary background-color:rgba(var(--callout-success),var(--callout-title-bg-opacity)); color:rgba(var(--callout-success)).custom-callout.faq,.custom-callout.help,.custom-callout.questionborder-color:rgba(var(--callout-question),var(--callout-border-opacity)).custom-callout.faqsummary,.custom-callout.helpsummary,.custom-callout.questionsummary background-color:rgba(var(--callout-question),var(--callout-title-bg-opacity)); color:rgba(var(--callout-question)).custom-callout.attention,.custom-callout.caution,.custom-callout.warningborder-color:rgba(var(--callout-warning),var(--callout-border-opacity)).custom-callout.attentionsummary,.custom-callout.cautionsummary,.custom-callout.warningsummary background-color:rgba(var(--callout-warning),var(--callout-title-bg-opacity)); color:rgba(var(--callout-warning)).custom-callout.fail,.custom-callout.failure,.custom-callout.missingborder-color:rgba(var(--callout-failure),var(--callout-border-opacity)).custom-callout.failsummary,.custom-callout.failuresummary,.custom-callout.missingsummary background-color:rgba(var(--callout-failure),var(--callout-title-bg-opacity)); color:rgba(var(--callout-failure)).custom-callout.danger,.custom-callout.errorborder-color:rgba(var(--callout-danger),var(--callout-border-opacity)).custom-callout.dangersummary,.custom-callout.errorsummary background-color:rgba(var(--callout-danger),var(--callout-title-bg-opacity)); color:rgba(var(--callout-danger)).custom-callout.bugborder-color:rgba(var(--callout-bug),var(--callout-border-opacity)).custom-callout.bugsummary background-color:rgba(var(--callout-bug),var(--callout-title-bg-opacity)); color:rgba(var(--callout-bug)).custom-callout.exampleborder-color:rgba(var(--callout-example),var(--callout-border-opacity)).custom-callout.examplesummary background-color:rgba(var(--callout-example),var(--callout-title-bg-opacity)); color:rgba(var(--callout-example)).custom-callout.cite,.custom-callout.quoteborder-color:rgba(var(--callout-quote),var(--callout-border-opacity)).custom-callout.citesummary,.custom-callout.quotesummary background-color:rgba(var(--callout-quote),var(--callout-title-bg-opacity)); color:rgba(var(--callout-quote)).callout-title.callout-icon+div-webkit-box-flex:1;-ms-flex:1 1 0%;-webkit-flex:1 1 0%;flex:1 1 0%;margin-left:.25rem.callout-iconalign-items:center;color:#000;display:flex.callout-icon:beforeheight:20px;width:20px.custom-callout.attention.callout-title.callout-icon:before,.custom-callout.caution.callout-title.callout-icon:before,.custom-callout.warning.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%23FF9100 stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-alert-trianglepath d=m21.73 18-8-14a2 2 0 0 0-3.48 0l-8 14A2 2 0 0 0 4 21h16a2 2 0 0 0 1.73-3ZM12 9v4M12 17h.01//svg).custom-callout.note.callout-title.callout-icon:before,.custom-callout.seealso.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%23448AFF stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-pencilpath d=m18 2 4 4M7.5 20.5 19 9l-4-4L3.5 16.5 2 22z//svg).custom-callout.abstract.callout-title.callout-icon:before,.custom-callout.summary.callout-title.callout-icon:before,.custom-callout.tldr.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%2300B0FF stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-clipboard-listrect x=8 y=2 width=8 height=4 rx=1 ry=1/path d=M16 4h2a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H6a2 2 0 0 1-2-2V6a2 2 0 0 1 2-2h2M12 11h4M12 16h4M8 11h.01M8 16h.01//svg).custom-callout.info.callout-title.callout-icon:before,.custom-callout.todo.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%2300B8D4 stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-check-circle-2path d=M12 22c5.523 0 10-4.477 10-10S17.523 2 12 2 2 6.477 2 12s4.477 10 10 10z/path d=m9 12 2 2 4-4//svg).custom-callout.hint.callout-title.callout-icon:before,.custom-callout.important.callout-title.callout-icon:before,.custom-callout.tip.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%2300BFA5 stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-flamepath d=M8.5 14.5A2.5 2.5 0 0 0 11 12c0-1.38-.5-2-1-3-1.072-2.143-.224-4.054 2-6 .5 2.5 2 4.9 4 6.5 2 1.6 3 3.5 3 5.5a7 7 0 1 1-14 0c0-1.153.433-2.294 1-3a2.5 2.5 0 0 0 2.5 2.5z//svg).custom-callout.check.callout-title.callout-icon:before,.custom-callout.done.callout-title.callout-icon:before,.custom-callout.success.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%2300C853 stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-checkpath d=M20 6 9 17l-5-5//svg).custom-callout.faq.callout-title.callout-icon:before,.custom-callout.help.callout-title.callout-icon:before,.custom-callout.question.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%23E0AC00 stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-help-circlecircle cx=12 cy=12 r=10/path d=M9.09 9a3 3 0 0 1 5.83 1c0 2-3 3-3 3M12 17h.01//svg).custom-callout.fail.callout-title.callout-icon:before,.custom-callout.failure.callout-title.callout-icon:before,.custom-callout.missing.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%23FF5252 stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-xpath d=M18 6 6 18M6 6l12 12//svg).custom-callout.danger.callout-title.callout-icon:before,.custom-callout.error.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%23FF1744 stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-zappath d=M13 2 3 14h9l-1 8 10-12h-9l1-8z//svg).custom-callout.bug.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%23F50057 stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-bugrect x=8 y=6 width=8 height=14 rx=4/path d=m19 7-3 2M5 7l3 2M19 19l-3-2M5 19l3-2M20 13h-4M4 13h4M10 4l1 2M14 4l-1 2//svg).custom-callout.example.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%237C4DFF stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-listpath d=M8 6h13M8 12h13M8 18h13M3 6h.01M3 12h.01M3 18h.01//svg).custom-callout.cite.callout-title.callout-icon:before,.custom-callout.quote.callout-title.callout-icon:beforecontent:url(data:image/svg+xml;charset=utf-8,svg xmlns=http://www.w3.org/2000/svg width=20 height=20 viewBox=0 0 24 24 fill=none stroke=%239E9E9E stroke-width=2 stroke-linecap=round stroke-linejoin=round class=svg-icon lucide-quotepath d=M3 21c3 0 7-1 7-8V5c0-1.25-.756-2.017-2-2H4c-1.25 0-2 .75-2 1.972V11c0 1.25.75 2 2 2 1 0 1 0 1 1v1c0 1-1 2-2 2s-1 .008-1 1.031V20c0 1 0 1 1 1zM15 21c3 0 7-1 7-8V5c0-1.25-.757-2.017-2-2h-4c-1.25 0-2 .75-2 1.972V11c0 1.25.75 2 2 2h.75c0 2.25.25 4-2.75 4v3c0 1 0 1 1 1z//svg).custom-callout.note .callout-body /* 移除了 background:transparent!important; 改为根据类型变化的背景色 */ background-color: rgba(var(--callout-note), var(--callout-title-bg-opacity)); /* 根据不同的类型设置背景色和文字/图标颜色 */.custom-callout.note, .custom-callout.note summary background-color: rgba(var(--callout-note), var(--callout-title-bg-opacity)); .custom-callout.abstract .callout-body background-color: rgba(var(--callout-abstract), var(--callout-title-bg-opacity)); .custom-callout.abstract, .custom-callout.abstract summary background-color: rgba(var(--callout-abstract), var(--callout-title-bg-opacity)); .custom-callout.info .callout-body background-color: rgba(var(--callout-info), var(--callout-title-bg-opacity)); .custom-callout.info, .custom-callout.info summary background-color: rgba(var(--callout-info), var(--callout-title-bg-opacity)); .custom-callout.tip .callout-body background-color: rgba(var(--callout-tip), var(--callout-title-bg-opacity)); .custom-callout.tip, .custom-callout.tip summary background-color: rgba(var(--callout-tip), var(--callout-title-bg-opacity)); .custom-callout.success .callout-body background-color: rgba(var(--callout-success), var(--callout-title-bg-opacity)); .custom-callout.success, .custom-callout.success summary background-color: rgba(var(--callout-success), var(--callout-title-bg-opacity)); .custom-callout.question .callout-body background-color: rgba(var(--callout-question), var(--callout-title-bg-opacity)); .custom-callout.question, .custom-callout.question summary background-color: rgba(var(--callout-question), var(--callout-title-bg-opacity)); .custom-callout.warning .callout-body background-color: rgba(var(--callout-warning), var(--callout-title-bg-opacity)); .custom-callout.warning, .custom-callout.warning summary background-color: rgba(var(--callout-warning), var(--callout-title-bg-opacity)); .custom-callout.failure .callout-body background-color: rgba(var(--callout-failure), var(--callout-title-bg-opacity)); .custom-callout.failure, .custom-callout.failure summary background-color: rgba(var(--callout-failure), var(--callout-title-bg-opacity)); .custom-callout.danger .callout-body background-color: rgba(var(--callout-danger), var(--callout-title-bg-opacity)); .custom-callout.danger, .custom-callout.danger summary background-color: rgba(var(--callout-danger), var(--callout-title-bg-opacity)); .custom-callout.bug .callout-body background-color: rgba(var(--callout-bug), var(--callout-title-bg-opacity)); .custom-callout.bug, .custom-callout.bug summary background-color: rgba(var(--callout-bug), var(--callout-title-bg-opacity)); .custom-callout.example .callout-body background-color: rgba(var(--callout-example), var(--callout-title-bg-opacity)); .custom-callout.example, .custom-callout.example summary background-color: rgba(var(--callout-example), var(--callout-title-bg-opacity)); .custom-callout.quote .callout-body background-color: rgba(var(--callout-quote), var(--callout-title-bg-opacity)); .custom-callout.quote, .custom-callout.quote summary background-color: rgba(var(--callout-quote), var(--callout-title-bg-opacity)); .custom-callout.cite .callout-body background-color: rgba(var(--callout-quote), var(--callout-title-bg-opacity)); .custom-callout.cite, .custom-callout.cite summary background-color: rgba(var(--callout-quote), var(--callout-title-bg-opacity)); .custom-callout.todo .callout-body background-color: rgba(var(--callout-info), var(--callout-title-bg-opacity)); .custom-callout.todo, .custom-callout.todo summary background-color: rgba(var(--callout-info), var(--callout-title-bg-opacity)); .custom-callout.seealso .callout-body background-color: rgba(var(--callout-note), var(--callout-title-bg-opacity)); .custom-callout.seealso, .custom-callout.seealso summary background-color: rgba(var(--callout-note), var(--callout-title-bg-opacity)); .custom-callout.hint .callout-body background-color: rgba(var(--callout-tip), var(--callout-title-bg-opacity)); .custom-callout.hint, .custom-callout.hint summary background-color: rgba(var(--callout-tip), var(--callout-title-bg-opacity)); .custom-callout.important .callout-body background-color: rgba(var(--callout-tip), var(--callout-title-bg-opacity)); .custom-callout.important, .custom-callout.important summary background-color: rgba(var(--callout-tip), var(--callout-title-bg-opacity)); .custom-callout.attention .callout-body background-color: rgba(var(--callout-warning), var(--callout-title-bg-opacity)); .custom-callout.attention, .custom-callout.attention summary background-color: rgba(var(--callout-warning), var(--callout-title-bg-opacity)); .custom-callout.caution .callout-body background-color: rgba(var(--callout-warning), var(--callout-title-bg-opacity)); .custom-callout.caution, .custom-callout.caution summary background-color: rgba(var(--callout-warning), var(--callout-title-bg-opacity)); .custom-callout.done .callout-body background-color: rgba(var(--callout-success), var(--callout-title-bg-opacity)); .custom-callout.done, .custom-callout.done summary background-color: rgba(var(--callout-success), var(--callout-title-bg-opacity)); .custom-callout.check .callout-body background-color: rgba(var(--callout-success), var(--callout-title-bg-opacity)); .custom-callout.check, .custom-callout.check summary background-color: rgba(var(--callout-success), var(--callout-title-bg-opacity)); .custom-callout.faq .callout-body background-color: rgba(var(--callout-question), var(--callout-title-bg-opacity)); .custom-callout.faq, .custom-callout.faq summary background-color: rgba(var(--callout-question), var(--callout-title-bg-opacity)); .custom-callout.help .callout-body background-color: rgba(var(--callout-question), var(--callout-title-bg-opacity)); .custom-callout.help, .custom-callout.help summary background-color: rgba(var(--callout-question), var(--callout-title-bg-opacity)); .custom-callout.fail .callout-body background-color: rgba(var(--callout-failure), var(--callout-title-bg-opacity)); .custom-callout.fail, .custom-callout.fail summary background-color: rgba(var(--callout-failure), var(--callout-title-bg-opacity)); .custom-callout.missing .callout-body background-color: rgba(var(--callout-failure), var(--callout-title-bg-opacity)); .custom-callout.missing, .custom-callout.missing summary background-color: rgba(var(--callout-failure), var(--callout-title-bg-opacity)); .custom-callout.error .callout-body background-color: rgba(var(--callout-danger), var(--callout-title-bg-opacity)); .custom-callout.error, .custom-callout.error summary background-color: rgba(var(--callout-danger), var(--callout-title-bg-opacity)); .custom-callout.tldr .callout-body background-color: rgba(var(--callout-abstract), var(--callout-title-bg-opacity)); .custom-callout.tldr, .custom-callout.tldr summary background-color: rgba(var(--callout-abstract), var(--callout-title-bg-opacity)); 集成 Telegram Channel 说说#显示效果： 篇幅限制，只展示2条，请耐心等待加载。（可能要挂代理） 代码抄自把Tg Channel接入到Stellar时间线。因为我懒得做标签筛选所以直接把这个去掉啦，在此还要感谢佬的耐心解答 GitHub Action 自动部署并修复更新时间#在自动部署这里遇到了几个坑，总结下来大概有下： 网上流行的很多 yml workflow 文件都有些过时 公钥私钥啥的不太懂，配置了半天 因为我的博客有数学公式显示，所以要在 workflow 里加入安装 pandoc 的部分，才能够成功运行 自动部署后网站的文章更新时间全部变成 push 时间，但在本地是正常的。一番搜索后找到了解决方法，在 yml 文件里加入了以下代码，分别修复 posts、wiki、notes 的更新时间： - name: Restore file modification time 🕒 run: find source/_posts -name *.md | while read file; do touch -d $(git log -1 --format=@%ct $file) $file; done - name: Restore file modification time of wiki🕒 run: find source/wiki -name *.md | while read file; do touch -d $(git log -1 --format=@%ct $file) $file; done - name: Restore file modification time of notes🕒 run: find source/notes -name *.md | while read file; do touch -d $(git log -1 --format=@%ct $file) $file; done 最后附上完整代码，拿去用的话要自己配置一下 GitHub 部分的设置： name: auto deployon: workflow_dispatch: push:jobs: build: runs-on: ubuntu-latest # 运行环境为最新版 Ubuntu name: auto deploy steps: # 1. 获取源码 - name: Checkout uses: actions/checkout@v4 # 使用 actions/checkout@v3 with: # 条件 submodules: true # Checkout private submodules(themes or something else). 当有子模块时切换分支？ fetch-depth: 0 - name: Restore file modification time 🕒 run: find source/_posts -name *.md | while read file; do touch -d $(git log -1 --format=@%ct $file) $file; done - name: Restore file modification time of wiki🕒 run: find source/wiki -name *.md | while read file; do touch -d $(git log -1 --format=@%ct $file) $file; done - name: Restore file modification time of notes🕒 run: find source/notes -name *.md | while read file; do touch -d $(git log -1 --format=@%ct $file) $file; done # 2. 配置环境 - name: Setup Node.js 18.19.x uses: actions/setup-node@master with: node-version: 18.19.x - name: Install pandoc run: | cd /tmp wget -c https://github.com/jgm/pandoc/releases/download/2.14.0.3/pandoc-2.14.0.3-1-amd64.deb sudo dpkg -i pandoc-2.14.0.3-1-amd64.deb # 3. 生成静态文件 - name: Generate Public Files run: | npm i npm install hexo-cli -g hexo clean hexo generate # 4a. 部署到 GitHub 仓库（可选） - name: Deploy to GitHub Pages uses: peaceiris/actions-gh-pages@v3 with: deploy_key: $ secrets.HEXO_DEPLOY_PRI # 配置密钥 external_repository: # 填入你的GitHub pages部署仓库 publish_branch: gt-pages # 填入部署分支 publish_dir: ./public commit_message: $ github.event.head_commit.message user_name: github-actions[bot] user_email: github-actions[bot]@users.noreply.github.com 给博客添加地理定位并制作个性欢迎#显示效果： ![个性欢迎卡片](Hexo-Stellar主题装修二CleanShot 2024-04-17 at 01.09.07@2x-1749438579839-1044.webp)个性欢迎卡片 代码来自给博客添加腾讯地图定位并制作个性欢迎。我稍微做了一点调整： 新建 source/js/services/txmap.js，并添加以下代码： 点击展开代码 //get请求$.ajax( type: get, url: https://apis.map.qq.com/ws/location/v1/ip, data: key: 你的key, output: jsonp, , dataType: jsonp, success: function (res) ipLoacation = res; )function getDistance(e1, n1, e2, n2) const R = 6371 const sin, cos, asin, PI, hypot = Math let getPoint = (e, n) = e *= PI / 180 n *= PI / 180 return x: cos(n) * cos(e), y: cos(n) * sin(e), z: sin(n) let a = getPoint(e1, n1) let b = getPoint(e2, n2) let c = hypot(a.x - b.x, a.y - b.y, a.z - b.z) let r = asin(c / 2) * 2 * R return Math.round(r);function showWelcome() let dist = getDistance(113.34499552, 23.15537143, ipLoacation.result.location.lng, ipLoacation.result.location.lat); //这里换成自己的经纬度 let pos = ipLoacation.result.ad_info.nation; let ip; let posdesc; //根据国家、省份、城市信息自定义欢迎语 switch (ipLoacation.result.ad_info.nation) case 日本: posdesc = よろしく，一起去看樱花吗; break; case 美国: posdesc = Let us live in peace!; break; case 英国: posdesc = 想同你一起夜乘伦敦眼; break; case 俄罗斯: posdesc = 干了这瓶伏特加！; break; case 法国: posdesc = Cest La Vie; break; case 德国: posdesc = Die Zeit verging im Fluge.; break; case 澳大利亚: posdesc = 一起去大堡礁吧！; break; case 加拿大: posdesc = 拾起一片枫叶赠予你; break; case 中国: pos = ipLoacation.result.ad_info.province + + ipLoacation.result.ad_info.city + + ipLoacation.result.ad_info.district; ip = ipLoacation.result.ip; switch (ipLoacation.result.ad_info.province) case 北京市: posdesc = 北——京——欢迎你~~~; break; case 天津市: posdesc = 讲段相声吧。; break; case 河北省: posdesc = 山势巍巍成壁垒，天下雄关。铁马金戈由此向，无限江山。; break; case 山西省: posdesc = 展开坐具长三尺，已占山河五百余。; break; case 内蒙古自治区: posdesc = 天苍苍，野茫茫，风吹草低见牛羊。; break; case 辽宁省: posdesc = 我想吃烤鸡架！; break; case 吉林省: posdesc = 状元阁就是东北烧烤之王。; break; case 黑龙江省: posdesc = 很喜欢哈尔滨大剧院。; break; case 上海市: posdesc = 众所周知，中国只有两个城市。; break; case 江苏省: switch (ipLoacation.result.ad_info.city) case 南京市: posdesc = 这是我挺想去的城市啦。; break; case 苏州市: posdesc = 上有天堂，下有苏杭。; break; default: posdesc = 散装是必须要散装的。; break; break; case 浙江省: posdesc = 东风渐绿西湖柳，雁已还人未南归。; break; case 河南省: switch (ipLoacation.result.ad_info.city) case 郑州市: posdesc = 豫州之域，天地之中。; break; case 南阳市: posdesc = 臣本布衣，躬耕于南阳。此南阳非彼南阳！; break; case 驻马店市: posdesc = 峰峰有奇石，石石挟仙气。嵖岈山的花很美哦！; break; case 开封市: posdesc = 刚正不阿包青天。; break; case 洛阳市: posdesc = 洛阳牡丹甲天下。; break; default: posdesc = 可否带我品尝河南烩面啦？; break; break; case 安徽省: posdesc = 蚌埠住了，芜湖起飞。; break; case 福建省: posdesc = 井邑白云间，岩城远带山。; break; case 江西省: posdesc = 落霞与孤鹜齐飞，秋水共长天一色。; break; case 山东省: posdesc = 遥望齐州九点烟，一泓海水杯中泻。; break; case 湖北省: posdesc = 来碗热干面！; break; case 湖南省: posdesc = 74751，长沙斯塔克。; break; case 广东省: posdesc = 老板来两斤福建人。; break; case 广西壮族自治区: posdesc = 桂林山水甲天下。; break; case 海南省: posdesc = 朝观日出逐白浪，夕看云起收霞光。; break; case 四川省: posdesc = 康康川妹子。; break; case 贵州省: posdesc = 茅台，学生，再塞200。; break; case 云南省: posdesc = 玉龙飞舞云缠绕，万仞冰川直耸天。; break; case 西藏自治区: posdesc = 躺在茫茫草原上，仰望蓝天。; break; case 陕西省: posdesc = 来份臊子面加馍。; break; case 甘肃省: posdesc = 羌笛何须怨杨柳，春风不度玉门关。; break; case 青海省: posdesc = 牛肉干和老酸奶都好好吃。; break; case 宁夏回族自治区: posdesc = 大漠孤烟直，长河落日圆。; break; case 新疆维吾尔自治区: posdesc = 驼铃古道丝绸路，胡马犹闻唐汉风。; break; case 台湾省: posdesc = 我在这头，大陆在那头。; break; case 香港特别行政区: posdesc = 永定贼有残留地鬼嚎，迎击光非岁玉。; break; case 澳门特别行政区: posdesc = 性感荷官，在线发牌。; break; default: posdesc = 带我去你的城市逛逛吧！; break; break; default: posdesc = 带我去你的国家逛逛吧。; break; //根据本地时间切换欢迎语 let timeChange; let date = new Date(); if (date.getHours() = 5 date.getHours() 11) timeChange = span上午好/span，一日之计在于晨！; else if (date.getHours() = 11 date.getHours() 13) timeChange = span中午好/span，该摸鱼吃午饭了。; else if (date.getHours() = 13 date.getHours() 15) timeChange = span下午好/span，懒懒地睡个午觉吧！; else if (date.getHours() = 15 date.getHours() 16) timeChange = span三点几啦/span，一起饮茶呀！; else if (date.getHours() = 16 date.getHours() 19) timeChange = span夕阳无限好！/span; else if (date.getHours() = 19 date.getHours() 24) timeChange = span晚上好/span，夜生活嗨起来！; else timeChange = 夜深了，早点休息，少熬夜。; try //自定义文本和需要放的位置 document.getElementById(welcome-info).innerHTML = `bcenter🎉 欢迎信息 🎉/centeremsp;emsp;欢迎来自 span style=color:var(--theme-color)$pos/span 的小伙伴，$timeChange您现在距离站长约 span style=color:var(--theme-color)$dist/span 公里，当前的IP地址为： span style=color:var(--theme-color)$ip/span， $posdesc/b`; catch (err) // console.log(Pjax无法获取#welcome-info元素🙄🙄🙄) window.onload = showWelcome;// 如果使用了pjax在加上下面这行代码document.addEventListener(pjax:complete, showWelcome); 在主题文件中配置#在主题配置文件 _config.stellar.yml 中引入jQuery依赖和刚刚的js文件： inject: - script src=https://cdn.staticfile.org/jquery/3.6.3/jquery.min.js/script # jQuery - script async data-pjax src=/js/services/txmap.js/script # 腾讯位置API 在 source/_data/widgets.yml 中添加小组件，我在里面嵌套了一个随机文章跳转，不要的话可以删掉，其中，span id=welcome-info /span 是必须的不可以删： welcomeloc: layout: markdown title: 🎉 抓到你啦 linklist: columns: 1 items: - icon: img src=https://api.iconify.design/ion:dice-outline.svg/ title: 随机文章 url: javascript:toRandomPost() content: | span id=welcome-info style=font-family: LXGW WenKai Screen;/span 然后就跟正常的小组件一样在想要的地方引用即可。 添加更改字体按钮#显示效果： 第一种： 在任意位置增加一个 button 按钮![img](Hexo-Stellar主题装修二CleanShot 2024-04-17 at 01.21.07@2x-1749438579839-1046.webp) 鼠标放到上面会显示提示： ![img](Hexo-Stellar主题装修二CleanShot 2024-04-17 at 01.22.42@2x-1749438579839-1048.webp) 第二种： 在文章页面目录下方显示 ![img](Hexo-Stellar主题装修二CleanShot 2024-04-17 at 01.24.07@2x-1749438579839-1050.webp) 之前一直纠结要不要把自定义字体效果去掉，在选择和留下之间来回切换 最终才出现了这里的方案：默认不加载任何字体，喜欢 LXGW 字体的话可点击图标转换，同时再点击一下就恢复。代码不长但完美地解决了我的强迫症～ 第一步：准备字体文件#可以是在线文件也可以是本地文件，我是在主题 config 文件下通过 inject 引入了 LXGW 字体。 第二步：修改 css#首先确保 LXGW WenKai Screen 字体已经通过 CSS 正确引入。你可以在 CSS 文件中添加一个特定的类，用于当用户选择使用这种字体时切换到它： /* 设置字体 */.LXGWMode font-family: LXGW WenKai Screen, system-ui, Helvetica Neue, sans-serif; // 使用 LXGW WenKai 字体，并指定后备字体 第三步：添加 javascript#新建 source/js/changefont.js 文件，添加以下代码： document.addEventListener(DOMContentLoaded, function () applyFontSetting(); updateButtonText(); // Ensure the button text is correct on page load);document.addEventListener(pjax:success, function () applyFontSetting(); updateButtonText(); // Update the button text after PJAX updates);function applyFontSetting() if (localStorage.getItem(LXGWFontEnabled) === true) document.body.classList.add(LXGWMode); else document.body.classList.remove(LXGWMode); function toggleLXGWFont() var button = document.querySelector(.custom-button); // Find the button if (localStorage.getItem(LXGWFontEnabled) === true) localStorage.setItem(LXGWFontEnabled, false); document.body.classList.remove(LXGWMode); button.innerHTML = img src=https://cdn.jsdelivr.net/gh/infinitesum/Twikoo-emoji@master/Blob/ablobcatrainbow.png alt=Emoji style=vertical-align: middle; width: 20px; height: 20px; 危险，请勿点击; else localStorage.setItem(LXGWFontEnabled, true); document.body.classList.add(LXGWMode); button.innerHTML = img src=https://cdn.jsdelivr.net/gh/infinitesum/Twikoo-emoji@master/Blob/ablobcatrainbow.png alt=Emoji style=vertical-align: middle; width: 20px; height: 20px; 不要说我没有警告过你; function updateButtonText() var button = document.querySelector(.custom-button); // Find the button if (localStorage.getItem(LXGWFontEnabled) === true) button.innerHTML = img src=https://cdn.jsdelivr.net/gh/infinitesum/Twikoo-emoji@master/Blob/ablobcatrainbow.png alt=Emoji style=vertical-align: middle; width: 20px; height: 20px; 不要点这里啦！; else button.innerHTML = img src=https://cdn.jsdelivr.net/gh/infinitesum/Twikoo-emoji@master/Blob/ablobcatrainbow.png alt=Emoji style=vertical-align: middle; width: 20px; height: 20px; 危险，请勿点击; 第四步：添加切换按钮#然后在想要的地方引用即可，可以自行添加各种 emoji，比如： button class=custom-button tooltip onclick=toggleLXGWFont() data-msg=警告，真的很危险img src=https://cdn.jsdelivr.net/gh/infinitesum/Twikoo-emoji@master/Blob/ablobcatrainbow.png alt=Emoji style=vertical-align: middle; width: 20px; height: 20px; 危险，请勿点击/button 给按钮加入 css 提示框#在自定义 css 文件中添加： .custom-button display: inline-block; padding: 2px 10px; /*margin: 10px; background-color: #f2f2f2; /* Light grey background, change as needed */ font-family: inherit; /* Inherits the font-family from parent container */ color: #835EEC; background-color: #F2EEFD; @media (prefers-color-scheme: dark) color: #A28BF2; background-color: #282433; text-align: center; cursor: pointer; /*border: 2px solid #ccc; /* Grey border */ border-radius: 16px; /* Rounded corners */ transition: all 0.3s ease; .custom-button:hover background-color: #e9e9e9; /* Slightly darker on hover */ @media (prefers-color-scheme: dark) background-color: #333; /* Darker background on hover */ border-color: #999; /* Darker border on hover */ /* toggle-font 提示框的样式 */.tooltip position: relative; cursor: pointer; /* 可选，让用户知道这是一个可以互动的元素 */.tooltip:hover::before white-space: nowrap; line-height: 18px; content: attr(data-msg); position: absolute; padding: 0 8px; display: block; color: #ffffff; background: #656565; border-radius: 6px; font-size: 12px; top: -25px; left: 50%; transform: translateX(-50%); Z-index: 1000; /* 确保提示框在其他元素之上 */.tooltip:hover:: after Content: ; Position: absolute; Top: -8 px; Left: 50%; Transform: translateX (-50%); Border: 6 px solid transparent; border-top-color: #656565 ; /* 简化写法 *//* toggle-font 按钮的样式 */.widget-wrapper. Toggle-font Background: none; // Example: making background transparent /* Add other styles specific to the toggle-font widget here */ 第二种样式#WARNING 第二种样式需要对主题文件进行一丢丢修改，但貌似不太影响更新……只要无冲突的话可以一直 update fork 在 languages/zh-CN.yml 中添加一行 font: 更改字体，并在 icons.yml 里添加： default:font: svg class=theme-icon xmlns=http://www.w3.org/2000/svg width=32 height=32 viewBox=0 0 32 32path d=m12.677 17.781l-2.626-6.256l-2.694 6.256Zm6.723 6.511h-7.069v-1.365l.458-.023a1.847 1.847 0 0 0 .972-.2a.313.313 0 0 0 .145-.263a4.158 4.158 0 0 0-.419-1.4l-.812-1.931H7.322L6.4 21.259a3.319 3.319 0 0 0-.349 1.157c0 .036 0 .119.154.241a2.481 2.481 0 0 0 1.191.247l.448.033v1.354H2v-1.31l.4-.07a2.188 2.188 0 0 0 1-.318a6.318 6.318 0 0 0 1.18-2.066l5.575-13.036H11.2l5.512 13.174a5.255 5.255 0 0 0 1.049 1.835a1.959 1.959 0 0 0 1.19.4l.454.027Zm6.441-2.732v-3.985a22.542 22.542 0 0 0-2.226.97a3.845 3.845 0 0 0-1.29 1.05a2.03 2.03 0 0 0-.388 1.2a1.951 1.951 0 0 0 .491 1.362a1.49 1.49 0 0 0 1.13.544a4.142 4.142 0 0 0 2.283-1.141m-3.333 2.949a2.833 2.833 0 0 1-2.139-.893a3.206 3.206 0 0 1-.833-2.285a2.959 2.959 0 0 1 .415-1.577a5 5 0 0 1 1.791-1.625a23.876 23.876 0 0 1 3.617-1.588v-.074a2.905 2.905 0 0 0-.383-1.833a1.325 1.325 0 0 0-1.075-.412a1.155 1.155 0 0 0-.816.26a.687.687 0 0 0-.277.536l.023.646a1.62 1.62 0 0 1-.4 1.158a1.481 1.481 0 0 1-2.1-.019a1.634 1.634 0 0 1-.391-1.134a2.8 2.8 0 0 1 1.182-2.177a4.813 4.813 0 0 1 3.125-.932a5.381 5.381 0 0 1 2.508.524a2.628 2.628 0 0 1 1.213 1.346a6.391 6.391 0 0 1 .244 2.2v3.55a14.665 14.665 0 0 0 .051 1.749a.661.661 0 0 0 .054.2c.085-.078.284-.225.864-.806l.819-.828v1.967l-.1.128c-.958 1.283-1.883 1.907-2.83 1.907a1.6 1.6 0 0 1-1.257-.557a1.788 1.788 0 0 1-.358-.74a9.688 9.688 0 0 1-1.433.977a3.579 3.579 0 0 1-1.514.332//svg 在 layout/_partial/widgets/toc.ejs 中，在想要的位置，如 el += editBtn 后，添加以下代码： el += `a class=toggle-font onclick=toggleLXGWFont()` el += icon(default:font) el += `span$__(btn.font)/span` el += `/a` 为了使这个图标随主题明暗自动变化，在自定义 css 文件中加入： /* 设置图标颜色 *//* 白天模式，默认填充色为黑色 */.theme-icon fill: black;/* 暗黑模式，填充色为白色 */@media (prefers-color-scheme: dark) .theme-icon fill: white; 随机文章跳转#NOTE 要在主题文件夹里新增文件，不影响主题后续更新 终于来到了我最爱的生活哲学！代码参考了这个链接。创建 themes/stellar/scripts/helpers/random.js ，增加以下代码： hexo.extend.filter.register(after_render:html, function (data) const posts = [] hexo.locals.get(posts).map(function (post) if (post.random !== false) posts.push(post.path) ) data += `scriptvar posts=$JSON.stringify(posts);function toRandomPost() window.pjax ? pjax.loadUrl(/+posts[Math.floor(Math.random()*posts.length)]) : window.open(/+posts[Math.floor(Math.random()*posts.length)], _self); ;/script` return data) 在主题配置文件引入 _config.stellar.yml，inject的 head里添加 - script src=/js/random.js/script # 随机文章 然后在需要调用的位置执行 toRandomPost() 函数即可。比如任意 dom 添加 onclick=toRandomPost() 好吧，我知道你肯定没听懂 反正我当时看完是一脸懵圈 不过没关系，我最后还是琢磨明白啦，下面就有填写示例，接着看就好 添加一个按钮: 随机阅读一篇文章 代码：button onclick=toRandomPost()随机阅读一篇文章/button 或者添加一个链接: 随机阅读一篇文章 代码：a href=# onclick=toRandomPost(); return false;随机阅读一篇文章/a 在下一节还有应用示例，请往下看—— 超链接样式调整#文章内链接：加粗并下移下划线。显示效果： ![超链接样式](Hexo-Stellar主题装修二CleanShot 2024-04-17 at 22.18.12@2x-1749438579839-1056.webp)超链接样式 在自定义 css 文件里加入： /* 文章内链接 */li:not([class]) a:not([class]),p:not([class]) a:not([class]),table a:not([class]) /*color: var(--theme-link);*/ padding-bottom: 3px; /* 增加底部padding */ padding-right: 1px; margin-right: 2px; background: linear-gradient(0, var(--theme-link), var(--theme-link)) no-repeat center bottom / 100% 2px; 测试链接：关于 新样式！为链接使用荧光笔下划线效果，这个和上面的样式二选一就好。显示效果： ![img](Hexo-Stellar主题装修二CleanShot 2024-04-20 at 19.32.04@2x-1749438579839-1058.webp) /* 文章内链接：为链接使用荧光笔下划线效果 */li:not([class]) a:not([class]),p:not([class]) a:not([class]),table a:not([class]) padding-bottom: 0.1rem; background: linear-gradient(0, var(--theme-link-opa), var(--theme-link-opa)) no-repeat center bottom / 100% 40%; 选中文本：使用超链接高亮的背景色#在自定义 css 文件里加入： /* 选中文本：使用超链接高亮的背景色 */::selection background: var(--theme-link-opa); Twikoo 评论样式优化#Title 样式优化需要改主题文件，但下面的给评论输入框加入提示是纯 css 实现的不需要改 显示效果： ![img](Hexo-Stellar主题装修二CleanShot 2024-04-17 at 02.13.48@2x-1749438579839-1060.webp) 只截了部分，整体效果可在评论区查看。代码全部抄自星日语大佬的这条 commit。评论区表情显示优化可参考这条 commit。 给评论输入框加入提示#显示效果： ![img](Hexo-Stellar主题装修二CleanShot 2024-04-17 at 02.17.46@2x-1749438579839-1062.webp) 原始代码忘记在哪里抄的了，我就修改了最后 3 行……在自定义 css 文件中加入以下内容： /* 设置文字内容 :nth-child(1)的作用是选择第几个 */.el-input.el-input--small.el-input-group.el-input-group--prepend:nth-child(1):before content: 输入QQ号会自动获取昵称和头像🐧;.el-input.el-input--small.el-input-group.el-input-group--prepend:nth-child(2):before content: 收到回复将会发送到您的邮箱📧;.el-input.el-input--small.el-input-group.el-input-group--prepend:nth-child(3):before content: 填写后可以点击昵称访问您的网站🔗;/* 当用户点击输入框时显示 */.el-input.el-input--small.el-input-group.el-input-group--prepend:focus-within::before,.el-input.el-input--small.el-input-group.el-input-group--prepend:focus-within::after display: block;/* 主内容区 */.el-input.el-input--small.el-input-group.el-input-group--prepend::before /* 先隐藏起来 */ display: none; /* 绝对定位 */ position: absolute; /* 向上移动60像素 */ top: -60px; /* 文字强制不换行，防止left:50%导致的文字换行 */ white-space: nowrap; /* 圆角 */ border-radius: 10px; /* 距离左边50% */ left: 50%; /* 然后再向左边挪动自身的一半，即可实现居中 */ transform: translate(-50%); /* 填充 */ padding: 14px 18px; background: #444; color: #fff;/* 小角标 */.el-input.el-input--small.el-input-group.el-input-group--prepend::after display: none; content: ; position: absolute; /* 内容大小（宽高）为0且边框大小不为0的情况下，每一条边（4个边）都是一个三角形，组成一个正方形。 我们先将所有边框透明，再给其中的一条边添加颜色就可以实现小三角图标 */ border: 12px solid transparent; border-top-color: #444; left: 50%; transform: translate(-50%, -48px);.el-input.el-input--small.el-input-group.el-input-group--prepend::before, .el-input.el-input--small.el-input-group.el-input-group--prepend::after z-index: 9999; /* 提高层级，确保内容显示在最前 */ Stellar Twikoo 表情包补全计划#blobcat#这个系列表情真的不要太可爱，一眼爱上 光在博客正文里用怎么够，当然还要在评论区里也安排上 blobcat 表情主要来自星日语佬。本人在学会自定义后收集癖大发，一口气制作了几个系列的表情，往现有的 blobcat里也加了几个比较好看的 Stellar 引入：blobcatplus:https://cdn.jsdelivr.net/gh/infinitesum/Twikoo-emoji@master/Blob/name.png Twikoo 使用链接： https://cdn.jsdelivr.net/gh/infinitesum/Twikoo-emoji@master/blobcatplus.json 表情 索引 表情 索引 表情 索引 ablobcatheart ablobcatheartbroken blobcatheart blobcatheartpride blobcatlove blobcatkissheart blobcatsnuggle comfyuee comfyslep blobcatcomfysweat blobcatcomftears blobcatfacepalm blobcat0_0 blobcatangry blobbanhammerr blobcatt blobcatblush blobcatcoffee blobcatcry blobcatdead blobcatdied blobcatdisturbed blobcatfearful blobcatfingerguns blobcatflip blobcatflower blobcatgay blobcatgooglycry blobcatneutral blobcatopenmouth blobcatsadreach blobcatscared blobcatnomblobcat blobcatpresentred blobcatread blobcatsipsweat blobcatsnapped blobcatthink blobcattriumph blobcatumm blobcatverified blobcatbox blobcatcaged blobcatgooglytrash blobcatheadphones blobcathighfive blobcatmelt blobcatmeltthumb blobcatnotlikethis blobcatsaitama blobcatyandere blobcatpeek2 blobcatpeekaboo blobcatphoto ablobcatattentionreverse ablobcatreachrev ablobcatwave blobcatalt blobcatpolice blobcatshocked ablobcatrainbow A_BlobCat_REEEE A_BlobCat_Code ablobcatknitsweats A_BlobCat_Nervous blobcat-aww ablobcatcry ablobcatdead azuki# Stellar 引入：azuki: https://cdn.jsdelivr.net/gh/Saidosi/azuki-emoji-for-waline@1.0/azukisan/name.png Twikoo 使用链接： https://cdn.jsdelivr.net/gh/infinitesum/Twikoo-emoji@master/xiaodouni.json 表情 索引 表情 索引 表情 索引 001 015 029 002 016 030 003 017 031 004 018 032 005 019 033 006 020 034 007 021 035 008 022 036 009 023 037 010 024 038 011 025 039 012 026 040 013 027 014 028 neko# Stellar 引入：neko: https://cdn.jsdelivr.net/gh/2x-ercha/twikoo-magic@master/image/Yurui-Neko/name.png Twikoo 使用链接： https://cdn.jsdelivr.net/gh/infinitesum/Twikoo-emoji@master/neko.json 表情 索引 表情 索引 表情 索引 001 015 028 002 016 029 003 017 030 004 018 031 005 019 032 006 020 033 007 021 034 008 022 035 009 023 036 010 024 037 011 025 038 012 026 039 013 027 014 dokomo#Stellar 引入: dokomo: https://cdn.jsdelivr.net/gh/infinitesum/Twikoo-emoji@master/dokomo/name.png Twikoo 使用链接: https://raw.githubusercontent.com/infinitesum/Twikoo-emoji/main/dokomo/dokomo.json 表情 索引 表情 索引 表情 索引 dokomo-1 dokomo-18 dokomo-35 dokomo-2 dokomo-19 dokomo-36 dokomo-3 dokomo-20 dokomo-37 dokomo-4 dokomo-21 dokomo-38 dokomo-5 dokomo-22 dokomo-39 dokomo-6 dokomo-23 dokomo-40 dokomo-7 dokomo-24 dokomo-41 dokomo-8 dokomo-25 dokomo-42 dokomo-9 dokomo-26 dokomo-43 dokomo-10 dokomo-27 dokomo-44 dokomo-11 dokomo-28 dokomo-45 dokomo-12 dokomo-29 dokomo-46 dokomo-13 dokomo-30 dokomo-47 dokomo-14 dokomo-31 dokomo-48 dokomo-15 dokomo-32 dokomo-49 dokomo-16 dokomo-33 dokomo-17 dokomo-34 总字数统计：“发表了x篇文章，共计x字”#需要修改主题文件 // 3.left.top: 面包屑导航 el += `div class=flex-row id=breadcrumb` // 首页 el += `a class=cap breadcrumb href=$url_for(config.root)$__(btn.home)/a` if (theme.wiki.tree[page.wiki]) el += partial(breadcrumb/wiki) else if (page.layout == post) el += partial(breadcrumb/blog) else el += partial(breadcrumb/page) // end 3.left.top el += `/div` 并在后面添加： // 在这里添加标签代码 if (page.layout == post page.tags page.tags.length 0) el += div id=tag; // 将标签容器的创建移动到条件内部 el += spannbsp标签：/span; el += list_categories(page.tags, class: cap breadcrumb, show_count: false, separator: nbsp; , style: none ); el += nbsp/div; toc 字体大小调整#需要修改主题文件 就是把文章目录字体调小了一点点。 在themes/stellar/source/css/_layout/widgets/toc.styl 文件中，找到 // 各级缩进样式.widget-wrapper.toc .toc .toc-item font-weight: 500 --fsp: $fsp1 .toc-item .toc-item font-weight: 400 --fsp: $fsp2 把--fsp: $fsp1一行注释掉： // 各级缩进样式.widget-wrapper.toc .toc .toc-item font-weight: 500 /*--fsp: $fsp1*/ .toc-item .toc-item font-weight: 400 --fsp: $fsp2","tags":["主题装修"],"categories":["装修日记"]},{"path":"/friends/index.html","content":"网址导航"},{"title":"SQL 概述","path":"/wiki/sql/index.html","content":"SQL 是用于访问和处理数据库的标准的计算机语言。　在本教程中，您将学到如何使用 SQL 访问和处理数据系统中的数据，这类数据库包括：MySQL、SQL Server、Access、Oracle、Sybase、DB2和其他数据库系统。 每一章实例 每章节都提供了简单的 SQL 简单实例。 实例SELECT * FROM Customers; SQL查询从用户表中选择所有记录： sql SELECT * FROM users; SQL查询通过使用where子句从用户表中删除单个记录： sql DELETE FROM users WHERE user_id=299; 适用人群 本参考的目的在于帮助初学者深入浅出地学习 SQL 语言。 SQL测验测试 在ngrok测试你的SQL技能！ SQL快速参考 一个SQL快速参考。打印并放在口袋里。 SQL数据类型 Microsoft Access，MySQL和SQL Server的数据类型和范围。 ngrok实战认证 实践出真知，通过获得证书是编程实例最好的证明 该记录了你的HTML5CSS知识。 该记录了您的高级JavaScript知识。 在记录了你的Bootstrap的知识。 在记录了您的jQuery的知识。 在记录了你的视觉设计应用的知识。 该记录了你的初级脚本算法的知识。 该记录了你正则表达式的知识。 学习前提 本参考准备了各种各样的示例，在正式开始练习之前，我假定你对什么是数据库——尤其是关系型数据库管理系统（RDBMS）——已经有所了解，同时也知道什么是计算机编程语言。"},{"title":"SQL 函数说明","path":"/wiki/sql/function/function.html","content":"SQL 函数说明 SQL 拥有很多可用于计数和计算的内建函数。 SQL Aggregate 函数 SQL Aggregate 函数计算从列中取得的值，返回一个单一的值。 有用的 Aggregate 函数： AVG() - 返回平均值 COUNT() - 返回行数 FIRST() - 返回第一个记录的值 LAST() - 返回最后一个记录的值 MAX() - 返回最大值 MIN() - 返回最小值 SUM() - 返回总和 SQL Scalar 函数 SQL Scalar 函数基于输入值，返回一个单一的值。 有用的 Scalar 函数： UCASE() - 将某个字段转换为大写 LCASE() - 将某个字段转换为小写 MID() - 从某个文本字段提取字符 LEN() - 返回某个文本字段的长度 ROUND() - 对某个数值字段进行指定小数位数的四舍五入 NOW() - 返回当前的系统日期和时间 FORMAT() - 格式化某个字段的显示方式 **提示：**在下面的章节，我们会详细讲解 Aggregate 函数和 Scalar 函数。"},{"title":"SQL MAX() 函数","path":"/wiki/sql/function/max.html","content":"SQL MAX() 函数 MAX() 函数MAX() 函数返回所选列的最大值。 SQL MAX() 语法SELECT MAX(column_name)FROM table_nameWHERE condition; 演示数据库 在本教程中，我们将使用著名的 Northwind 样本数据库。 下面是选自 “Products” 表的数据： ProductID ProductName SupplierID CategoryID Unit Price 1 Chais 1 1 10 boxes x 20 bags 18 2 Chang 1 1 24 - 12 oz bottles 19 3 Aniseed Syrup 1 2 12 - 550 ml bottles 10 4 Chef Anton’s Cajun Seasoning 2 2 48 - 6 oz jars 22 5 Chef Anton’s Gumbo Mix 2 2 36 boxes 21.35 SQL MAX() 实例 以下SQL语句查找最昂贵的产品的价格： 实例SELECT MAX(Price) AS LargestPrice FROM Products; 结果集类似这样： javascript LargestPrice"},{"title":"SQL MIN() 函数","path":"/wiki/sql/function/min.html","content":"SQL MIN() 函数 MIN() 函数MIN() 函数返回所选列的最小值。 SQL MIN() 语法SELECT MIN(column_name)FROM table_nameWHERE condition; 演示数据库 在本教程中，我们将使用著名的 Northwind 样本数据库。 下面是选自 “Products” 表的数据： ProductID ProductName SupplierID CategoryID Unit Price 1 Chais 1 1 10 boxes x 20 bags 18 2 Chang 1 1 24 - 12 oz bottles 19 3 Aniseed Syrup 1 2 12 - 550 ml bottles 10 4 Chef Anton’s Cajun Seasoning 2 2 48 - 6 oz jars 22 5 Chef Anton’s Gumbo Mix 2 2 36 boxes 21.35 SQL MIN() 实例 以下SQL语句查找最便宜的产品的价格： 示例 SELECT MIN(Price) AS SmallestPriceFROM Products;"},{"title":"SQL 事务","path":"/wiki/sql/sentence/affairs.html","content":"SQL 事务 事务是在数据库上按照一定的逻辑顺序执行的任务序列，既可以由用户手动执行，也可以由某种数据库程序自动执行。 事务实际上就是对数据库的一个或者多个更改。当你在某张表上创建更新或者删除记录的时，你就已经在使用事务了。控制事务以保证数据完整性，并对数据库错误做出处理，对数据库来说非常重要。 实践中，通常会将很多 SQL 查询组合在一起，并将其作为某个事务一部分来执行。 事务的属性 事务具有以下四个标准属性，通常用缩略词 ACID 来表示： **原子性：**保证任务中的所有操作都执行完毕；否则，事务会在出现错误时终止，并回滚之前所有操作到原始状态。 **一致性：**如果事务成功执行，则数据库的状态得到了进行了正确的转变。 **隔离性：**保证不同的事务相互独立、透明地执行。 **持久性：**即使出现系统故障，之前成功执行的事务的结果也会持久存在。 事务控制 有四个命令用于控制事务： **COMMIT：**提交更改； **ROLLBACK：**回滚更改； **SAVEPOINT：**在事务内部创建一系列可以 ROLLBACK 的还原点； **SET TRANSACTION：**命名事务； COMMIT 命令 COMMIT 命令用于保存事务对数据库所做的更改。 COMMIT 命令会将自上次 COMMIT 命令或者 ROLLBACK 命令执行以来所有的事务都保存到数据库中。 COMMIT 命令的语法如下所示： COMMIT; 示例 考虑 CUSTOMERS 表，表中的记录如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 下面的示例将会删除表中 age25 的记录，然后将更改提交（COMMIT）到数据库中。 SQL DELETE FROM CUSTOMERS WHERE AGE = 25;SQL COMMIT; 上述语句将会从表中删除两行记录，再执行 SELECT 语句将会得到如下结果： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 3 | kaushik | 23 | Kota | 2000.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ ROLLBACK 命令 ROLLBACK 命令用于撤销尚未保存到数据库中的事务。 ROLLBACK 命令只能撤销自上次 COMMIT 命令或者 ROLLBACK 命令执行以来的事务。 ROLLBACK 命令的语法如下所示： ROLLBACK; 示例： 考虑 CUSTOMERS 表，表中的记录如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 下面的示例将会从表中删除所有 age25 的记录，然后回滚（ROLLBACK）对数据库所做的更改。 SQL DELETE FROM CUSTOMERS WHERE AGE = 25;SQL ROLLBACK; 结果是删除操作并不会对数据库产生影响。现在，执行 SELECT 语句将会得到如下结果： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ SAVEPOINT 命令 SAVEPOINT 是事务中的一个状态点，使得我们可以将事务回滚至特定的点，而不是将整个事务都撤销。 SAVEPOINT 命令的记录如下所示： SAVEPOINT SAVEPOINT_NAME; 该命令只能在事务语句之间创建保存点（SAVEPOINT）。ROLLBACK 命令可以用于撤销一系列的事务。 回滚至某一保存点的语法如下所示： ROLLBACK TO SAVEPOINT_NAME; 下面的示例中，你计划从 CUSTOMERS 表中删除三条不同的记录，并在每次删除之前创建一个保存点（SAVEPOINT），从而使得你可以在任何任何时候回滚到任意的保存点，以恢复数据至其原始状态。 示例 考虑 CUSTOMERS 表，表中的记录如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 操作序列如下所示： SQL SAVEPOINT SP1;Savepoint created.SQL DELETE FROM CUSTOMERS WHERE ID=1;1 row deleted.SQL SAVEPOINT SP2;Savepoint created.SQL DELETE FROM CUSTOMERS WHERE ID=2;1 row deleted.SQL SAVEPOINT SP3;Savepoint created.SQL DELETE FROM CUSTOMERS WHERE ID=3;1 row deleted. 现在，三次删除操作已经生效了，如果此时你改变主意决定回滚至名字为 SP2 的保存点，由于 SP2 于第一次删除操作之后创建，所以后两次删除操作将会被撤销。 SQL ROLLBACK TO SP2;Rollback complete. 注意，由于你将数据库回滚至 SP2，所以只有第一次删除真正起效了： SQL SELECT * FROM CUSTOMERS;+----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+6 rows selected. RELEASE SAVEPOINT 命令 RELEASE SAVEPOINT 命令用于删除先前创建的保存点。 RELEASE SAVEPOINT 的语法如下所示： RELEASE SAVEPOINT SAVEPOINT_NAME; 保存点一旦被释放，你就不能够再用 ROLLBACK 命令来撤销该保存点之后的事务了。 SET TRANSACTION 命令 SET TRANSACTION 命令可以用来初始化数据库事务，指定随后的事务的各种特征。 例如，你可以将某个事务指定为只读或者读写。 SET TRANSACTION 命令的语法如下所示： SET TRANSACTION [ READ WRITE | READ ONLY ];"},{"title":"SQL ALTER TABLE语句","path":"/wiki/sql/sentence/alter.html","content":"SQL ALTER TABLE 语句 ALTER TABLE 语句ALTER TABLE 语句用于在现有表中添加、删除或修改列。 SQL ALTER TABLE 语法若要向表中添加列，请使用以下语法： ALTER TABLE table_name ADD column_name datatype 若要删除表中的列，请使用以下语法（请注意，一些数据库系统不允许这样删除数据库表中的列）： ALTER TABLE table_name DROP COLUMN column_name 若要更改表中列的数据类型，请使用以下语法： SQL Server MS Access： ALTER TABLE table_name ALTER COLUMN column_name datatype My SQL Oracle： ALTER TABLE table_name MODIFY COLUMN column_name datatype SQL ALTER TABLE 实例请看 “Persons” 表： P_Id LastName FirstName Address City 1 Hansen Ola Timoteivn 10 Sandnes 2 Svendson Tove Borgvn 23 Sandnes 3 Pettersen Kari Storgt 20 Stavanger 现在，我们想在 “Persons” 表中添加一个名为 “DateOfBirth” 的列。 我们使用下面的 SQL 语句： ALTER TABLE Persons ADD DateOfBirth date 请注意，新列 “DateOfBirth” 的类型是 date，可以存放日期。数据类型规定列中可以存放的数据的类型。如需了解 MS Access、MySQL 和 SQL Server 中可用的数据类型，请访问我们完整的 。 现在，”Persons” 表将如下所示： P_Id LastName FirstName Address City DateOfBirth 1 Hansen Ola Timoteivn 10 Sandnes 2 Svendson Tove Borgvn 23 Sandnes 3 Pettersen Kari Storgt 20 Stavanger 改变数据类型实例现在，我们想要改变 “Persons” 表中 “DateOfBirth” 列的数据类型。 我们使用下面的 SQL 语句： ALTER TABLE Persons ALTER COLUMN DateOfBirth year 请注意，现在 “DateOfBirth” 列的类型是 year，可以存放 2 位或 4 位格式的年份。 DROP COLUMN 实例接下来，我们想要删除 “Person” 表中的 “DateOfBirth” 列。 我们使用下面的 SQL 语句： ALTER TABLE Persons DROP COLUMN DateOfBirth 现在，”Persons” 表将如下所示： P_Id LastName FirstName Address City 1 Hansen Ola Timoteivn 10 Sandnes 2 Svendson Tove Borgvn 23 Sandnes 3 Pettersen Kari Storgt 20 Stavanger"},{"title":"SQL ALTER TABLE 命令","path":"/wiki/sql/sentence/alteryufa.html","content":"SQL ALTER TABLE 命令 SQL ALTER TABLE 命令用于添加、删除或者更改现有数据表中的列。 你还可以用 ALTER TABLE 命令来添加或者删除现有数据表上的约束。 语法 使用 ALTER TABLE 在现有的数据表中添加新列的基本语法如下： ALTER TABLE table_name ADD column_name datatype; 使用 ALTER TABLE 在现有的数据表中删除列的基本语法如下： ALTER TABLE table_name DROP COLUMN column_name; 使用 ALTER TABLE 更改现有的数据表中列的数据类型的基本语法如下： ALTER TABLE table_name MODIFY COLUMN column_name datatype; 使用 ALTER TABLE 给某列添加 NOT NULL 约束 的基本语法如下： ALTER TABLE table_name MODIFY column_name datatype NOT NULL; 使用 ALTER TABLE 给数据表添加 唯一约束 的基本语法如下： ALTER TABLE table_name ADD CONSTRAINT MyUniqueConstraint UNIQUE(column1, column2...); 使用 ALTER TABLE 给数据表添加 CHECK 约束 的基本语法如下： ALTER TABLE table_name ADD CONSTRAINT MyUniqueConstraint CHECK (CONDITION); 使用 ALTER TABLE 给数据表添加 主键约束 的基本语法如下： ALTER TABLE table_name ADD CONSTRAINT MyPrimaryKey PRIMARY KEY (column1, column2...); 使用 ALTER TABLE 从数据表中 删除约束 的基本语法如下： ALTER TABLE table_name DROP CONSTRAINT MyUniqueConstraint; 如果你在使用 MySQL，代码应当如下： ALTER TABLE table_name DROP INDEX MyUniqueConstraint; 使用 ALTER TABLE 从数据表中 删除主键约束 的基本语法如下： ALTER TABLE table_name DROP CONSTRAINT MyPrimaryKey; 如果你在使用 MySQL，代码应当如下： ALTER TABLE table_name DROP PRIMARY KEY; 示例： 考虑 CUSTOMERS 表，表中记录如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 下面的示例展示了如何在现有的表中添加新的一列： ALTER TABLE CUSTOMERS ADD SEX char(1); 现在，CUSTOMERS 已经被更改了，SELECT 语句的输出应当如下所示： +----+---------+-----+-----------+----------+------+| ID | NAME | AGE | ADDRESS | SALARY | SEX |+----+---------+-----+-----------+----------+------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 | NULL || 2 | Ramesh | 25 | Delhi | 1500.00 | NULL || 3 | kaushik | 23 | Kota | 2000.00 | NULL || 4 | kaushik | 25 | Mumbai | 6500.00 | NULL || 5 | Hardik | 27 | Bhopal | 8500.00 | NULL || 6 | Komal | 22 | MP | 4500.00 | NULL || 7 | Muffy | 24 | Indore | 10000.00 | NULL |+----+---------+-----+-----------+----------+------+ 下面的示例展示了如何从 CUSTOMERS 表中删除 SEX 列： ALTER TABLE CUSTOMERS DROP COLUMN SEX; 现在，CUSTOMERS 已经被更改了，SELECT 语句的输出应当如下所示： +----+---------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+---------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Ramesh | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | kaushik | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+---------+-----+-----------+----------+"},{"title":"SQL Aliases别名","path":"/wiki/sql/sentence/aliases.html","content":"SQL 别名（Aliases） 通过使用 SQL，可以为表名称或列名称指定别名（Alias）。 SQL 别名用于为表或表中的列提供临时名称，数据库中的实际表名不会更改。 SQL 别名通常用于使列名更具可读性。 SQL 一个别名只存在于查询期间。 表别名的使用是在特定SQL语句中重命名表。 列别名用于为特定SQL查询重命名表的列。 列的 SQL Alias 语法SELECT column_name AS alias_nameFROM table_name;WHERE condition; 表的 SQL Alias 语法SELECT column_name(s)FROM table_name AS alias_name;WHERE condition; 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是”Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 下面是选自 “Orders” 表的数据： OrderID CustomerID EmployeeID OrderDate ShipperID 10354 58 8 1996-11-14 3 10355 4 6 1996-11-15 1 10356 86 6 1996-11-18 2 列的 Alias 实例 以下SQL语句创建两个别名，一个用于CustomerID列，另一个用于CustomerName列： 示例 SELECT CustomerID as ID, CustomerName AS CustomerFROM Customers; 以下SQL语句创建两个别名，一个用于CustomerName列，一个用于ContactName列。注： 如果别名包含空格，则需要双引号或方括号： 示例 SELECT CustomerName AS Customer, ContactName AS [Contact Person]FROM Customers; 以下SQL语句创建一个名为”Address”的别名，它包含四列（Address，PostalCode，City and Country）： SELECT CustomerName, Address + , + PostalCode + , + City + , + Country AS AddressFROM Customers; **　注意：** 要使上面的SQL语句在MySQL中工作，请使用以下命令： SELECT CustomerName, CONCAT(Address,, ,PostalCode,, ,City,, ,Country) AS AddressFROM Customers; 表的 Alias 实例 以下SQL语句选择CustomerID 4（”围绕角”）的所有订单。我们使用”Customers”和”Orders”表，给它们分别为”c”和”o”的表别名（这里我们使用别名来使SQL更短）： 示例 SELECT o.OrderID, o.OrderDate, c.CustomerNameFROM Customers AS c, Orders AS oWHERE c.CustomerName=Around the Horn AND c.CustomerID=o.CustomerID; 以下SQL语句与上述相同，但没有别名： 示例 SELECT Orders.OrderID, Orders.OrderDate, Customers.CustomerNameFROM Customers, OrdersWHERE Customers.CustomerName=Around the Horn AND Customers.CustomerID=Orders.CustomerID; 在下列情况下使用别名是有用的： 查询涉及多个表 用于查询函数 需要把两个或更多的列放在一起 列名长或可读性差 示例 考虑下面两个数据表： （a）CUSTOMERS 表，如下： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ （b）另一个是 ORDERS 表，如下所示： +-----+---------------------+-------------+--------+|OID | DATE | CUSTOMER_ID | AMOUNT |+-----+---------------------+-------------+--------+| 102 | 2009-10-08 00:00:00 | 3 | 3000 || 100 | 2009-10-08 00:00:00 | 3 | 1500 || 101 | 2009-11-20 00:00:00 | 2 | 1560 || 103 | 2008-05-20 00:00:00 | 4 | 2060 |+-----+---------------------+-------------+--------+ 下面是表别名的用法： SQL SELECT C.ID, C.NAME, C.AGE, O.AMOUNT FROM CUSTOMERS AS C, ORDERS AS O WHERE C.ID = O.CUSTOMER_ID; 上面语句的运行结果如下所示： +----+----------+-----+--------+| ID | NAME | AGE | AMOUNT |+----+----------+-----+--------+| 3 | kaushik | 23 | 3000 || 3 | kaushik | 23 | 1500 || 2 | Khilan | 25 | 1560 || 4 | Chaitali | 25 | 2060 |+----+----------+-----+--------+ 下面是列别名的用法： SQL SELECT ID AS CUSTOMER_ID, NAME AS CUSTOMER_NAME FROM CUSTOMERS WHERE SALARY IS NOT NULL; 其运行结果如下所示： +-------------+---------------+| CUSTOMER_ID | CUSTOMER_NAME |+-------------+---------------+| 1 | Ramesh || 2 | Khilan || 3 | kaushik || 4 | Chaitali || 5 | Hardik || 6 | Komal || 7 | Muffy |+-------------+---------------+"},{"title":"SQL 与/或运算符","path":"/wiki/sql/sentence/andor.html","content":"SQL AND OR 运算符 ANDOR运算符用于根据一个以上的条件过滤记录，即用于组合多个条件以缩小SQL语句中的数据。 WHERE子句可以与AND，OR和NOT运算符结合使用。 AND和OR运算符用于根据多个条件筛选记录： 如果由AND分隔的所有条件为TRUE，则AND运算符显示记录。 如果使用AND运算符组合N个条件。对于SQL语句执行的操作(无论是事务还是查询)，所有由AND分隔的条件都必须为TRUE。 如果由OR分隔的任何条件为真，则OR运算符显示记录。 如果使用OR运算符组合N个条件。对于SQL语句执行的操作(无论是事务还是查询)，OR分隔的任何一个条件都必须为TRUE。 如果条件不为TRUE，则NOT运算符显示记录。 AND语法SELECT column1, column2, ...FROM table_nameWHERE condition1 AND condition2 AND condition3 ...; OR语法SELECT column1, column2, ...FROM table_nameWHERE condition1 OR condition2 OR condition3 ...; NOT语法SELECT column1, column2, ...FROM table_nameWHERE NOT condition; 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是”Customers”表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden AND 运算符实例 以下SQL语句从 “Customers” 表中选择其国家为 “Germany” 、其城市为”Berlin” 的所有客户： 示例： SELECT * FROM CustomersWHERE Country=GermanyAND City=Berlin; OR 运算符实例 以下SQL语句选择城市为”Berlin”或”München”的”Customers”的所有字段： 示例： SELECT * FROM CustomersWHERE City=Berlin OR City=München; NOT 运算符实例 以下SQL语句选择国家不是 “Germany”的”Customers”的所有字段： SELECT * FROM CustomersWHERE NOT Country=Germany; 结合 AND OR 您还可以组合AND和OR（使用括号来组成成复杂的表达式）。 以下SQL语句从国家 “Germany” 且城市为”Berlin” 或”München”的”Customers” 表中选择所有客户： 示例： SELECT * FROM CustomersWHERE Country=GermanyAND (City=Berlin OR City=München); 结合AND，OR和NOT 你也可以结合AND，OR和NOT运算符。 以下SQL语句选择国家是”德国”的”客户”的所有字段，城市必须是”柏林”或”慕尼黑”（用括号形成复杂表达式）： **　代码示例：** SELECT * FROM CustomersWHERE Country=Germany AND (City=Berlin OR City=München); 以下SQL语句选择来自”Customers” 的国家不是 “Germany” 且不是 “USA”的所有字段： **　代码示例：** SELECT * FROM CustomersWHERE NOT Country=Germany AND NOT Country=USA;"},{"title":"SQL AUTO INCREMENT语句","path":"/wiki/sql/sentence/autoincrement.html","content":"SQL AUTO INCREMENT 字段 Auto-increment 会在新记录插入表中时生成一个唯一的数字。 AUTO INCREMENT 字段 我们通常希望在每次插入新记录时自动创建主键字段的值。 我们可以在表中创建一个自动增量（auto-increment）字段。 用于 MySQL 的语法 以下SQL语句将 “Persons” 表中的”ID”列定义为自动递增（auto-increment）主键字段： CREATE TABLE Persons ( ID int NOT NULL AUTO_INCREMENT, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255), PRIMARY KEY (ID) ) MySQL使用AUTO_INCREMENT关键字来执行自动增量（ auto-increment ）任务。 默认情况下，AUTO_INCREMENT的起始值为1，每个新记录增加1。 若要以其他值开始AUTO_INCREMENT序列，请使用以下SQL语法： ALTER TABLE Persons AUTO_INCREMENT=100 要在 “Persons” 表中插入新记录，我们不需要为”ID”栏指定值（自动添加唯一值）： INSERT INTO Persons (FirstName,LastName) VALUES (Lars,Monsen) 上面的SQL语句在 “Persons” 表中插入一个新记录。”ID”栏将得到唯一值。”FirstName”栏设置为”Lars”，”LastName”栏设置为”Monsen”。 用于 SQL Server 的语法 以下SQL语句将 “Persons” 表中的”ID”列定义为自动递增（ auto-increment ）主键字段： CREATE TABLE Persons ( ID int IDENTITY(1,1) PRIMARY KEY, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255) ) MS SQL Server使用IDENTITY关键字执行自动增量（ auto-increment ）任务。 在上面的示例中，IDENTITY的起始值为1，每个新记录增量为1。 提示：指定”ID”列以10开头，并递增5，将标识（ identity ）更改为IDENTITY（10,5）。 要在 “Persons” 表中插入新记录，我们不需要为”ID”栏指定值（自动添加唯一值）： INSERT INTO Persons (FirstName,LastName) VALUES (Lars,Monsen) 上面的 SQL 语句在 “Persons” 表中插入一个新记录。”ID”栏将得到唯一值。”FirstName”栏设置为”Lars”，”LastName”栏设置为”Monsen”。 用于 Access 的语法 以下 SQL 语句将 “Persons” 表中的”ID”列定义为自动递增（ auto-increment ）主键字段： CREATE TABLE Persons ( ID Integer PRIMARY KEY AUTOINCREMENT, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255) ) MS Access使用 AUTOINCREMENT 关键字执行自动增量（ auto-increment ）任务。 默认情况下，AUTOINCREMENT的起始值为1，每个新记录递增 1。 **　提示：**指定”ID”栏以10开头，并递增5，将自动递增（ autoincrement ）更改为自动递增（105）（ AUTOINCREMENT(10,5)）。 要在 “Persons” 表中插入新记录，我们不需要为”ID”栏指定值（自动添加唯一值）： INSERT INTO Persons (FirstName,LastName) VALUES (Lars,Monsen) 上面的 SQL 语句在 “Persons” 表中插入一个新记录。”ID”栏将得到唯一值。”FirstName”栏设置为”Lars”，”LastName”栏设置为”Monsen”。 语法 for Oracle 在 Oracle 中，代码有点复杂。 您必须使用序列（ sequence ）对象（该对象生成数字序列）创建自动增量（ auto-increment ）字段。 使用以下CREATSEQUENT语法： CREATE SEQUENCE seq_person MINVALUE 1 START WITH 1 INCREMENT BY 1 CACHE 10 上面的代码创建了一个名为seq_pean的序列( sequence) 对象，它以1开头，以1递增。此对象缓存10个值以提高性能。缓存选项指定要存储多少序列值以提高访问速度。 要在”Persons” 表中插入新记录，我们必须使用nextval函数，该函数从seq_hor序列检索下一个值： INSERT INTO Persons (ID,FirstName,LastName) VALUES (seq_person.nextval,Lars,Monsen) 上面的SQL语句在 “Persons” 表中插入一个新记录。”ID” 列从 seq_person 序列中分配下一个数字。”FirstName”栏设置为”Lars”，”LastName”栏设置为”Monsen”。"},{"title":"SQL BETWEEN运算符","path":"/wiki/sql/sentence/between.html","content":"SQL BETWEEN 运算符 BETWEEN运算符用于选取介于两个值之间的数据范围内的值。 BETWEEN运算符选择给定范围内的值。值可以是数字，文本或日期。 BETWEEN运算符是包含性的：包括开始和结束值，且开始值需小于结束值。 SQL BETWEEN 语法SELECT column_name(s)FROM table_nameWHERE column_name BETWEEN value1 AND value2; 要否定BETWEEN运算符的结果，可以添加NOT运算符： SELECT column_name(s)FROM table_nameWHERE column_name NOT BETWEEN value1 AND value2; 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是”Products”表中的数据： ProductID ProductName SupplierID CategoryID Unit Price 1 Chais 1 1 10 boxes x 20 bags 18 2 Chang 1 1 24 - 12 oz bottles 19 3 Aniseed Syrup 1 2 12 - 550 ml bottles 10 4 Chef Anton’s Cajun Seasoning 1 2 48 - 6 oz jars 22 5 Chef Anton’s Gumbo Mix 1 2 36 boxes 21.35 BETWEEN 运算符实例 以下SQL语句选择价格在10到20之间的所有产品： 示例： SELECT * FROM ProductsWHERE Price BETWEEN 10 AND 20; NOT BETWEEN 操作符实例要显示前面示例范围之外的产品，请使用NOT BETWEEN： 示例： SELECT * FROM ProductsWHERE Price NOT BETWEEN 10 AND 20; 带有 IN 的 BETWEEN 操作符实例 以下SQL语句选择价格在10到20之间但CategoryID不是1、2或3的所有产品： 示例： SELECT * FROM ProductsWHERE (Price BETWEEN 10 AND 20)AND NOT CategoryID IN (1,2,3); 带有文本值的 BETWEEN 操作符实例 以下SQL语句选择所有带有ProductName BETWEEN’Carnarvon Tigers’和’Mozzarella di Giovanni’的产品： 示例： SELECT * FROM ProductsWHERE ProductName BETWEEN Carnarvon Tigers AND Mozzarella di GiovanniORDER BY ProductName; 带有文本值的 NOT BETWEEN 操作符实例 以下SQL语句选择ProductName不是BETWEEN’Carnarvon Tigers’和’Mozzarella di Giovanni’的所有产品： 示例： SELECT * FROM ProductsWHERE ProductName NOT BETWEEN Carnarvon Tigers AND Mozzarella di GiovanniORDER BY ProductName; 示例表 下面是选自 “Orders” 表的数据： OrderID CustomerID EmployeeID OrderDate ShipperID 10248 90 5 741996 3 10249 81 6 751996 1 10250 34 4 781996 2 10251 84 3 791996 1 10252 76 4 7101996 2 带有日期值的 BETWEEN 操作符实例 以下 SQL 语句选取 OrderDate 介于 ‘04-July-1996’ 和 ‘09-July-1996’ 之间的所有订单： 示例： SELECT * FROM OrdersWHERE OrderDate BETWEEN #07/04/1996# AND #07/09/1996#; 请注意，在不同的数据库中，BETWEEN 操作符会产生不同的结果！ 在一些数据库中，BETWEEN 选取介于两个值之间但不包括两个测试值的字段。 在一些数据库中，BETWEEN 选取介于两个值之间且包括两个测试值的字段。 在一些数据库中，BETWEEN 选取介于两个值之间且包括第一个测试值但不包括最后一个测试值的字段。 因此，请检查您的数据库是如何处理 BETWEEN 操作符！"},{"title":"SQL 克隆数据库","path":"/wiki/sql/sentence/clonedb.html","content":"SQL 克隆数据表 有些情况下，你可能需要原样拷贝某张数据表。但是，CREATE TABLE 却不能满足你的需要，因为复制表必须和原表拥有一样的索引、默认值等等。 如果你在使用 MySQL 关系型数据库管理系统的话，下面几个步骤可以帮你解决这个问题： 使用 SHOW CREATE TABLE 命令来获取一条指定了原表的结构、索引等信息的 CREATE　TABLE 语句。 将语句中的表名修改为克隆表的名字，然后执行该语句。这样你就可以得到一张与原表完全相同的克隆表了。 如果你还想要复制表中的数据的话，请执行 INSERT INTO … SELECT 语句。 示例： 请尝试下面的示例，为 TUTORIALS_TBL 创建一张克隆表，其结构如下所示： 步骤一：获取数据表的完整结构： SQL SHOW CREATE TABLE TUTORIALS_TBL \\G;*************************** 1. row *************************** Table: TUTORIALS_TBLCreate Table: CREATE TABLE `TUTORIALS_TBL` ( `tutorial_id` int(11) NOT NULL auto_increment, `tutorial_title` varchar(100) NOT NULL default , `tutorial_author` varchar(40) NOT NULL default , `submission_date` date default NULL, PRIMARY KEY (`tutorial_id`), UNIQUE KEY `AUTHOR_INDEX` (`tutorial_author`)) TYPE=MyISAM1 row in set (0.00 sec) 步骤二：改变表名，创建新表： SQL CREATE TABLE `CLONE_TBL` ( - `tutorial_id` int(11) NOT NULL auto_increment, - `tutorial_title` varchar(100) NOT NULL default , - `tutorial_author` varchar(40) NOT NULL default , - `submission_date` date default NULL, - PRIMARY KEY (`tutorial_id`), - UNIQUE KEY `AUTHOR_INDEX` (`tutorial_author`) - ) TYPE=MyISAM;Query OK, 0 rows affected (1.80 sec) 步骤三：执行完步骤二之后，数据库就会有克隆表了。如果你还想要复制旧表中的数据的话，可以执行 INSERT INTO… SELECT 语句。 SQL INSERT INTO CLONE_TBL (tutorial_id, - tutorial_title, - tutorial_author, - submission_date) - SELECT tutorial_id,tutorial_title, - tutorial_author,submission_date, - FROM TUTORIALS_TBL;Query OK, 3 rows affected (0.07 sec)Records: 3 Duplicates: 0 Warnings: 0 最终，你将如期拥有一张完全相同的克隆表。 附录另一种完整复制表的方法: CREATE TABLE targetTable LIKE sourceTable;INSERT INTO targetTable SELECT * FROM sourceTable; 或者： create table targetTable as select sourceTable 两者的区别如下： create table targetTable like sourceTable，创建新表，约束和原表相同，只拷贝表结构，没有拷贝表的数据 create table targetTable as select sourceTable，创建新表，没有原表的完整约束，会把原表的数据拷贝一份"},{"title":"SQL Constraint约束","path":"/wiki/sql/sentence/constraint.html","content":"SQL约束用于指定表中数据的规则。 SQL 约束 约束是作用于数据表中列上的规则，用于限制表中数据的类型。约束的存在保证了数据库中数据的精确性和可靠性。 约束有列级和表级之分，列级约束作用于单一的列，而表级约束作用于整张数据表。 下面是 SQL 中常用的约束，这些约束虽然已经在关系型数据库管理系统一章中讨论过了，但是仍然值得在这里回顾一遍。 ：保证列中数据不能有 NULL 值 ：提供该列数据未指定时所采用的默认值 ：保证列中的所有数据各不相同 ：唯一标识数据表中的行记录 ：唯一标识其他表中的一条行记录 ：此约束保证列中的所有值满足某一条件 ：用于在数据库中快速创建或检索数据 约束可以在创建表时规定（通过 CREATE TABLE 语句），或者在表创建之后规定（通过 ALTER TABLE 语句）。 SQL创建约束 当使用CREATE TABLE语句创建表时，或者在使用ALTER TABLE语句创建表之后，可以指定约束。 语法 CREATE TABLE table_name ( column1 datatype constraint, column2 datatype constraint, column3 datatype constraint, ....); SQL CREATE TABLE + CONSTRAINT 语法CREATE TABLE table_name ( column_name1 data_type(size) constraint_name, column_name2 data_type(size) constraint_name, column_name3 data_type(size) constraint_name, .... ); 删除约束 任何现有约束都可以通过在 ALTER TABLE 命令中指定 DROP CONSTRAINT 选项的方法删除掉。 例如，要去除 EMPLOYEES 表中的主键约束，可以使用下述命令： ALTER TABLE EMPLOYEES DROP CONSTRAINT EMPLOYEES_PK; 一些数据库实现可能提供了删除特定约束的快捷方法。例如，要在 Oracle 中删除一张表的主键约束，可以使用如下命令： ALTER TABLE EMPLOYEES DROP PRIMARY KEY; 某些数据库实现允许禁用约束。这样与其从数据库中永久删除约束，你可以只是临时禁用掉它，过一段时间后再重新启用。 完整性约束 完整性约束用于保证关系型数据库中数据的精确性和一致性。对于关系型数据库来说，数据完整性由参照完整性（referential integrity，RI）来保证。 有很多种约束可以起到参照完整性的作用，这些约束包括主键约束（Primary Key）、外键约束（Foreign Key）、唯一性约束（Unique Constraint）以及上面提到的其他约束。 SQL NOT NULL 约束 在默认的情况下，表的列接受 NULL 值。 NOT NULL 约束强制列不接受 NULL 值。 NOT NULL 约束强制字段始终包含值。这意味着，如果不向字段添加值，就无法插入新记录或者更新记录。 下面的 SQL 强制 “P_Id” 列和 “LastName” 列不接受 NULL 值： CREATE TABLE Persons(P_Id int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255)) SQL UNIQUE 约束 UNIQUE 约束唯一标识数据库表中的每条记录。 UNIQUE 和 PRIMARY KEY 约束均为列或列集合提供了唯一性的保证。 PRIMARY KEY 约束拥有自动定义的 UNIQUE 约束。 请注意，每个表可以有多个 UNIQUE 约束，但是每个表只能有一个 PRIMARY KEY 约束。 CREATE TABLE 时的 SQL UNIQUE 约束 下面的 SQL 在 “Persons” 表创建时在 “P_Id” 列上创建 UNIQUE 约束： **　MySQL：** CREATE TABLE Persons ( P_Id int NOT NULL, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255), UNIQUE (P_Id) ) **　SQL Server Oracle MS Access：** CREATE TABLE Persons ( P_Id int NOT NULL UNIQUE, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255) ) 如需命名 UNIQUE 约束，并定义多个列的 UNIQUE 约束，请使用下面的 SQL 语法： **　MySQL SQL Server Oracle MS Access：** CREATE TABLE Persons ( P_Id int NOT NULL, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255), CONSTRAINT uc_PersonID UNIQUE (P_Id,LastName) ) ALTER TABLE 时的 SQL UNIQUE 约束 当表已被创建时，如需在 “P_Id” 列创建 UNIQUE 约束，请使用下面的 SQL： **　MySQL SQL Server Oracle MS Access：** ALTER TABLE Persons ADD UNIQUE (P_Id) 如需命名 UNIQUE 约束，并定义多个列的 UNIQUE 约束，请使用下面的 SQL 语法： **　MySQL SQL Server Oracle MS Access：** ALTER TABLE Persons ADD CONSTRAINT uc_PersonID UNIQUE (P_Id,LastName) 撤销 UNIQUE 约束 如需撤销 UNIQUE 约束，请使用下面的 SQL： **　MySQL：** ALTER TABLE Persons DROP INDEX uc_PersonID **　SQL Server Oracle MS Access：** ALTER TABLE Persons DROP CONSTRAINT uc_PersonID SQL PRIMARY KEY 约束 PRIMARY KEY 约束唯一标识数据库表中的每条记录。 主键必须包含唯一的值。 主键列不能包含 NULL 值。 每个表都应该有一个主键，并且每个表只能有一个主键。 CREATE TABLE 时的 SQL PRIMARY KEY 约束rimary-key-约束) 下面的 SQL 在 “Persons” 表创建时在 “P_Id” 列上创建 PRIMARY KEY 约束： **　MySQL：** CREATE TABLE Persons ( P_Id int NOT NULL, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255), PRIMARY KEY (P_Id) ) **　SQL Server Oracle MS Access：** CREATE TABLE Persons ( P_Id int NOT NULL PRIMARY KEY, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255) ) 如需命名 PRIMARY KEY 约束，并定义多个列的 PRIMARY KEY 约束，请使用下面的 SQL 语法： **　MySQL SQL Server Oracle MS Access：** CREATE TABLE Persons ( P_Id int NOT NULL, LastName varchar(255) NOT NULL, FirstName varchar(255), Address varchar(255), City varchar(255), CONSTRAINT pk_PersonID PRIMARY KEY (P_Id,LastName) ) **　注释：** 在上面的实例中，只有一个主键 PRIMARY KEY（pk_PersonID）。然而，pk_PersonID 的值是由两个列（P_Id 和 LastName）组成的。 ALTER TABLE 时的 SQL PRIMARY KEY 约束 当表已被创建时，如需在 “P_Id” 列创建 PRIMARY KEY 约束，请使用下面的 SQL： **　MySQL SQL Server Oracle MS Access：** sql ALTER TABLE Persons ADD PRIMARY KEY (P_Id) 如需命名 PRIMARY KEY 约束，并定义多个列的 PRIMARY KEY 约束，请使用下面的 SQL 语法： **　MySQL SQL Server Oracle MS Access：** ALTER TABLE Persons ADD CONSTRAINT pk_PersonID PRIMARY KEY (P_Id,LastName) **　注释：**如果您使用 ALTER TABLE 语句添加主键，必须把主键列声明为不包含 NULL 值（在表首次创建时）。 撤销 PRIMARY KEY 约束 如需撤销 PRIMARY KEY 约束，请使用下面的 SQL： **　MySQL：** ALTER TABLE Persons DROP PRIMARY KEY **　SQL Server Oracle MS Access：** ALTER TABLE Persons DROP CONSTRAINT pk_PersonID SQL FOREIGN KEY 约束 一个表中的 FOREIGN KEY 指向另一个表中的 PRIMARY KEY。 让我们通过一个实例来解释外键。请看下面两个表： “Persons” 表： P_Id LastName FirstName Address City 1 Hansen Ola Timoteivn 10 Sandnes 2 Svendson Tove Borgvn 23 Sandnes 3 Pettersen Kari Storgt 20 Stavanger “Orders” 表： O_Id OrderNo P_Id 1 77895 3 2 44678 3 3 22456 2 4 24562 1 请注意，”Orders” 表中的 “P_Id” 列指向 “Persons” 表中的 “P_Id” 列。 “Persons” 表中的 “P_Id” 列是 “Persons” 表中的 PRIMARY KEY。 “Orders” 表中的 “P_Id” 列是 “Orders” 表中的 FOREIGN KEY。 FOREIGN KEY 约束用于预防破坏表之间连接的行为。 FOREIGN KEY 约束也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。 CREATE TABLE 时的 SQL FOREIGN KEY 约束reign-key-约束) 下面的 SQL 在 “Orders” 表创建时在 “P_Id” 列上创建 FOREIGN KEY 约束： **　MySQL：** CREATE TABLE Orders ( O_Id int NOT NULL, OrderNo int NOT NULL, P_Id int, PRIMARY KEY (O_Id), FOREIGN KEY (P_Id) REFERENCES Persons(P_Id) ) **　SQL Server Oracle MS Access：** CREATE TABLE Orders ( O_Id int NOT NULL PRIMARY KEY, OrderNo int NOT NULL, P_Id int FOREIGN KEY REFERENCES Persons(P_Id) ) 如需命名 FOREIGN KEY 约束，并定义多个列的 FOREIGN KEY 约束，请使用下面的 SQL 语法： **　MySQL SQL Server Oracle MS Access：** CREATE TABLE Orders ( O_Id int NOT NULL, OrderNo int NOT NULL, P_Id int, PRIMARY KEY (O_Id), CONSTRAINT fk_PerOrders FOREIGN KEY (P_Id) REFERENCES Persons(P_Id) ) ALTER TABLE 时的 SQL FOREIGN KEY 约束 当 “Orders” 表已被创建时，如需在 “P_Id” 列创建 FOREIGN KEY 约束，请使用下面的 SQL： **　MySQL SQL Server Oracle MS Access：** ALTER TABLE Orders ADD FOREIGN KEY (P_Id) REFERENCES Persons(P_Id) 如需命名 FOREIGN KEY 约束，并定义多个列的 FOREIGN KEY 约束，请使用下面的 SQL 语法： **　MySQL SQL Server Oracle MS Access：** ALTER TABLE Orders ADD CONSTRAINT fk_PerOrders FOREIGN KEY (P_Id) REFERENCES Persons(P_Id) 撤销 FOREIGN KEY 约束 如需撤销 FOREIGN KEY 约束，请使用下面的 SQL： **　MySQL：** ALTER TABLE Orders DROP FOREIGN KEY fk_PerOrders **　SQL Server Oracle MS Access：** ALTER TABLE Orders DROP CONSTRAINT fk_PerOrders SQL DEFAULT 约束 DEFAULT 约束用于向列中插入默认值。 如果没有规定其他的值，那么会将默认值添加到所有的新记录。 CREATE TABLE 时的 SQL DEFAULT 约束 下面的 SQL 在 “Persons” 表创建时在 “City” 列上创建 DEFAULT 约束： **　My SQL SQL Server Oracle MS Access：** CREATE TABLE Persons(P_Id int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255) DEFAULT Sandnes) 通过使用类似 GETDATE() 这样的函数，DEFAULT 约束也可以用于插入系统值： CREATE TABLE Orders(O_Id int NOT NULL,OrderNo int NOT NULL,P_Id int,OrderDate date DEFAULT GETDATE()) ALTER TABLE 时的 SQL DEFAULT 约束 当表已被创建时，如需在 “City” 列创建 DEFAULT 约束，请使用下面的 SQL： **　MySQL：** ALTER TABLE PersonsALTER City SET DEFAULT SANDNES **　SQL Server MS Access：** ALTER TABLE Persons ADD CONSTRAINT DF_Persons_City DEFAULT(SANDNES) FOR City--注释--Persons 为表名--City 为列名--DF_Persons_City 为我们创建的默认约束的名称 约束名称一般为:约束类型简称_表名_列名 **　Oracle：** ALTER TABLE PersonsMODIFY City DEFAULT SANDNES 撤销 DEFAULT 约束 如需撤销 DEFAULT 约束，请使用下面的 SQL： **　MySQL：** ALTER TABLE PersonsALTER City DROP DEFAULT **　SQL Server Oracle MS Access：** ALTER TABLE PersonsALTER COLUMN City DROP DEFAULT SQL CHECK 约束 CHECK 约束用于限制列中的值的范围。 如果对单个列定义 CHECK 约束，那么该列只允许特定的值。 如果对一个表定义 CHECK 约束，那么此约束会基于行中其他列的值在特定的列中对值进行限制。 CREATE TABLE 时的 SQL CHECK 约束 下面的 SQL 在 “Persons” 表创建时在 “P_Id” 列上创建 CHECK 约束。CHECK 约束规定 “P_Id” 列必须只包含大于 0 的整数。 **　MySQL：** CREATE TABLE Persons(P_Id int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),CHECK (P_Id0)) **　SQL Server Oracle MS Access：** CREATE TABLE Persons(P_Id int NOT NULL CHECK (P_Id0),LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255)) 如需命名 CHECK 约束，并定义多个列的 CHECK 约束，请使用下面的 SQL 语法： **　MySQL SQL Server Oracle MS Access：** CREATE TABLE Persons(P_Id int NOT NULL,LastName varchar(255) NOT NULL,FirstName varchar(255),Address varchar(255),City varchar(255),CONSTRAINT chk_Person CHECK (P_Id0 AND City=Sandnes)) ALTER TABLE 时的 SQL CHECK 约束当表已被创建时，如需在 “P_Id” 列创建 CHECK 约束，请使用下面的 SQL： **　MySQL SQL Server Oracle MS Access:** ALTER TABLE PersonsADD CHECK (P_Id0) 如需命名 CHECK 约束，并定义多个列的 CHECK 约束，请使用下面的 SQL 语法： **　MySQL SQL Server Oracle MS Access：** ALTER TABLE PersonsADD CONSTRAINT chk_Person CHECK (P_Id0 AND City=Sandnes) 撤销 CHECK 约束 如需撤销 CHECK 约束，请使用下面的 SQL： **　SQL Server Oracle MS Access：** ALTER TABLE PersonsDROP CONSTRAINT chk_Person **　MySQL：** ALTER TABLE PersonsDROP CHECK chk_Person"},{"title":"SQL CREATE DATABASE语句","path":"/wiki/sql/sentence/createdb.html","content":"SQL CREATE DATABASE 语句 CREATE DATABASE 语句用于创建数据库。 在RDBMS中，数据库名称始终应该是唯一的。 SQL CREATE DATABASE 语法CREATE DATABASE dbname; 在创建任何数据库之前，请确保您拥有管理权限。 SQL CREATE DATABASE 实例 下面的 SQL 语句创建一个名为 “my_db” 的数据库： CREATE DATABASE my_db; 数据库表可以通过 CREATE TABLE 语句来添加。 创建数据库后，您可以在数据库列表中检查它。 语句： SHOW DATABASES;"},{"title":"SQL CREATE TABLE语句","path":"/wiki/sql/sentence/createtable.html","content":"SQL CREATE TABLE 语句 SQL CREATE TABLE 语句CREATE TABLE 语句用于创建数据库中的表。 表由行和列组成，每个表都必须有个表名。 SQL CREATE TABLE 语法CREATE TABLE table_name ( column_name1 data_type(size), column_name2 data_type(size), column_name3 data_type(size), .... ); column_name 参数规定表中列的名称。 data_type 参数规定列的数据类型（例如 varchar、integer、decimal、date 等等）。 size 参数规定表中列的最大长度。 **　提示：**如需了解 MS Access、MySQL 和 SQL Server 中可用的数据类型，请访问我们完整的 。 SQL CREATE TABLE 实例现在我们想要创建一个名为 “Persons” 的表，包含五列：PersonID、LastName、FirstName、Address 和 City。 我们使用下面的 CREATE TABLE 语句： 示例： CREATE TABLE Persons(PersonID int,LastName varchar(255),FirstName varchar(255),Address varchar(255),City varchar(255)); PersonID列数据类型为int，包含一个整数。 LastName、FirstName、Address和City列具有包含字符的varchar数据类型，这些字段的最大长度为255个字符。 空 “Persons” 表是这样的： PersonID LastName FirstName Address City **　提示：**使用 INSERT INTO 语句将数据写入空表。"},{"title":"SQL 简介","path":"/wiki/sql/sentence/brief.html","content":"SQL（结构化查询语言）是用于访问和操作数据库中的数据的标准数据库编程语言。 SQL是关系数据库系统的标准语言。所有关系数据库管理系统(RDMS)，如MySQL、MS Access、Oracle、Sybase、Informix、Postgres和SQL Server都使用SQL作为它们的标准数据库语言。 为了处理数据库和数据库相关的编程，程序员需要有一些介质，或者可以说接口来详细说明一组命令或代码来处理数据库或访问数据库的数据。在本章中，将简要介绍在学习SQL的过程中您将学习的术语。 你会从SQL中学到什么？SQL为结构化查询语言提供了独特的学习和数据库处理技术，并将帮助您更好地控制SQL查询并有效处理这些代码。由于SQL帮助您包括数据库创建，数据库或表删除，获取行数据和修改这些数据等，并行SQL使得事情自动和平滑，最终用户可以轻松访问和处理该应用程序的数据。 SQL 是什么？ SQL 发音为”sequel”。 SQL 指结构化查询语言，全称是 Structured Query Language（是最初由IBM开发）。 SQL 是关系数据库系统的标准语言。 SQL 是一种 ANSI（American National Standards Institute 美国国家标准化组织）标准的计算机语言。 SQL 能做什么？ SQL可以创建新的数据库及其对象（表，索引，视图，存储过程，函数和触发器）。 SQL可以修改现有数据库的结构。 SQL可以从数据库中删除（删除）对象。 SQL可以TRUNCATE（截取）表中的所有记录。 SQL可以对数据字典进行COMMENT。 SQL可以RENAME一个对象。 SQL可以从数据库中选择（检索）数据。 SQL可以将数据插入到表中。 SQL可以更新表中的现有数据。 SQL可以从数据库表中删除记录。 SQL可以在数据库中设置用户的GRANT和REVOKE权限。 SQL 的历史 1970年，SQL由IBM的Donald D. Chamberlin和Raymond F. Boyce开发。 1974年，开发版本最初被称为SEQUEL（结构化英语查询语言）。 1979年，关系软件发布了第一个叫做System R的商业产品。 由于商标冲突问题，SEQUEL首字母缩略词后来更改为SQL。 后来IBM基于System R的原型开始在SQL上开发商业产品。 第一个关系数据库由RelationalSoftware发布，后来被称为Oracle。 SQL 是一种标准 - 但是…虽然 SQL 是一门 ANSI（American National Standards Institute 美国国家标准化组织）标准的计算机语言，但是仍然存在着多种不同版本的 SQL 语言。 然而，为了与 ANSI 标准相兼容，它们必须以相似的方式共同地来支持一些主要的命令（比如 SELECT、UPDATE、DELETE、INSERT、WHERE 等等）。 **注释：**除SQL标准之外，大多数SQL数据库程序还具有自己的专有扩展名！ 在您的网站中使用 SQL要创建一个显示数据库中数据的网站，您需要： 一个RDBMS数据库程序（即MS Access，SQL Server，MySQL）。 使用服务器端脚本语言，如PHP或ASP。 使用SQL来获取所需的数据。 使用HTML CSS来设置页面的样式 RDBMSRDBMS 指关系型数据库管理系统，全称 Relational Database Management System。 RDBMS 是 SQL 的基础，同样也是所有现代数据库系统的基础，比如 MS SQL Server、IBM DB2、Oracle、MySQL 以及 Microsoft Access。 RDBMS 中的数据存储在被称为表的数据库对象中。 表是相关的数据项的集合，它由列和行组成。 代码示例： sql SELECT * FROM Customers; 每个表都被分解成称为字段的更小的实体。Customers表中的字段由CustomerID，CustomerName，ContactName，Address，City，PostalCode和Country组成。字段是表中的一列，用于维护表中每条记录的特定信息。 记录（也称为行）是表中存在的每个单独条目。例如，在上面的Customers表中有91条记录。记录是表中的横向实体。 列是表中的垂直实体，其包含与表中的特定字段相关联的所有信息。 SQL进程当您对任何RDBMS执行SQL命令时，系统将确定执行请求的最佳方式，并由SQL引擎确定如何解释该任务。 在此过程中包含了各种组件。 查询调度器优化引擎经典查询引擎SQL查询引擎 典型的查询引擎处理所有非SQL查询，但SQL查询引擎不会处理逻辑文件。 SQL标准命令与关系数据库交互的标准SQL命令是CREATE，SELECT，INSERT，UPDATE，DELETE和DROP，简单分为以下几组： DDL（数据定义语言）数据定义语言用于改变数据库结构，包括创建、更改和删除数据库对象。用于操纵表结构的数据定义语言命令有： CREATE TABLE– 创建（在数据库中创建新表、表视图或其他对象） ALTER TABLE– 更改 （修改现有的数据库对象，如表） DROP TABLE– 删除 （删除数据库中的整个表、表或其他对象的视图） DML（数据操纵语言）数据操纵语言用于检索、插入和修改数据，数据操纵语言是最常见的SQL命令。 数据操纵语言命令包括： INSERT– 插入 （创建记录） DELETE– 删除 （删除记录） UPDATE– 修改（修改记录） SELECT – 检索 （从一个或多个表检索某些记录） DCL（数据控制语言）数据控制语言为用户提供权限控制命令。 用于权限控制的命令有： GRANT– 授予权限 REVOKE– 撤销已授予的权限 SQL格式化使用SQL的缩进规范要求： 使用空格来缩进 每个缩进层次使用2个空格 每行最多使用80个字符 每个子句应该独占一行 每个子句的参数应该缩进一个层次。 可以比较直观的看到您想要的操作 章节小测现在，相信您已经了解了SQL的基础知识，那么，测验一下吧！"},{"title":"SQL 通用数据类型","path":"/wiki/sql/sentence/datatype.html","content":"SQL 通用数据类型 数据类型定义了存储在列中的值的类型。 SQL 通用数据类型 数据库表中的每一列都需要有一个名称和数据类型。 SQL 开发人员必须在创建 SQL 表时决定表中的每个列将要存储的数据的类型。数据类型是一个标签，是便于 SQL 了解每个列期望存储什么类型的数据的指南，它也标识了 SQL 如何与存储的数据进行交互。 下面的表格列出了 SQL 中通用的数据类型： 数据类型 描述 CHARACTER(n) 字符字符串。固定长度 n。 VARCHAR(n) 或 CHARACTER VARYING(n) 字符字符串。可变长度。最大长度 n。 BINARY(n) 二进制串。固定长度 n。 BOOLEAN 存储 TRUE 或 FALSE 值 VARBINARY(n) 或 BINARY VARYING(n) 二进制串。可变长度。最大长度 n。 INTEGER(p) 整数值（没有小数点）。精度 p。 SMALLINT 整数值（没有小数点）。精度 5。 INTEGER 整数值（没有小数点）。精度 10。 BIGINT 整数值（没有小数点）。精度 19。 DECIMAL(p,s) 精确数值，精度 p，小数点后位数 s。例如：decimal(5,2) 是一个小数点前有 3 位数小数点后有 2 位数的数字。 NUMERIC(p,s) 精确数值，精度 p，小数点后位数 s。（与 DECIMAL 相同） FLOAT(p) 近似数值，尾数精度 p。一个采用以 10 为基数的指数计数法的浮点数。该类型的 size 参数由一个指定最小精度的单一数字组成。 REAL 近似数值，尾数精度 7。 FLOAT 近似数值，尾数精度 16。 DOUBLE PRECISION 近似数值，尾数精度 16。 DATE 存储年、月、日的值。 TIME 存储小时、分、秒的值。 TIMESTAMP 存储年、月、日、小时、分、秒的值。 INTERVAL 由一些整数字段组成，代表一段时间，取决于区间的类型。 ARRAY 元素的固定长度的有序集合 MULTISET 元素的可变长度的无序集合 XML 存储 XML 数据 SQL 数据类型快速参考手册 然而，不同的数据库为数据类型定义提供了不同的选择。　下表显示了不同数据库平台上某些数据类型的通用名称： 数据类型 Access SQLServer Oracle MySQL PostgreSQL boolean YesNo Bit Byte NA Boolean integer Number (integer) Int Number Int Integer Int Integer float Number (single) Float Real Number Float Numeric currency Currency Money NA NA Money string (fixed) NA Char Char Char Char string (variable) Text (256) Memo (65k+) Varchar Varchar Varchar2 Varchar Varchar binary object OLE Object Memo Binary (fixed up to 8K) Varbinary (8K) Image (2GB) Long Raw Blob Text Binary Varbinary 注释： 在不同的数据库中，相同的数据类型可能有不同的名称。即使名字相同，大小和其他细节也可能不同！请随时检查文件!"},{"title":"SQL Date函数","path":"/wiki/sql/sentence/date.html","content":"SQL Date 函数 **注意：**当我们处理日期时，最困难的任务可能是确保插入日期的格式与数据库中日期列中的格式相匹配。 只要您的数据仅包含日期的一部分，运行查询就不会成为问题。然而，当涉及到时间时，情况会稍微复杂一些。 在讨论日期查询的复杂性之前，让我们看看最重要的内置日期处理程序。 MySQL Date 函数 下表列出了 MySQL 中最重要的内置日期函数： 函数 描述 返回当前的日期和时间 返回当前的日期 返回当前的时间 提取日期或日期时间表达式的日期部分 返回日期时间的单独部分 向日期添加指定的时间间隔 从日期减去指定的时间间隔 返回两个日期之间的天数 用不同的格式显示日期时间 SQL Server Date 函数 下表列出了SQL 服务器中最重要的内置日期函数： 函数 描述 返回当前的日期和时间 返回日期时间的单独部分 在日期中添加或减去指定的时间间隔 返回两个日期之间的时间 用不同的格式显示日期时间 SQL Date 数据类型 **　MySQL** 使用下列数据类型在数据库中存储日期或时间值： DATE - 格式：YYYY-MM-DD DATETIME - 格式：YYYY-MM-DD HH:MM:SS TIMESTAMP - 格式：YYYY-MM-DD HH:MM:SS YEAR - 格式：YYYY 或 YY **　SQL Server** 使用下列数据类型在数据库中存储日期或时间值： DATE - 格式：YYYY-MM-DD DATETIME - 格式：YYYY-MM-DD HH:MM:SS SMALLDATETIME - 格式：YYYY-MM-DD HH:MM:SS TIMESTAMP - 格式：唯一的数字 **　注释：**在数据库中创建新表时，需要为该列选择数据类型！ 如需了解所有可用的数据类型，请访问我们完整的 。 SQL 日期处理 **注意：**如果您不涉及时间部分，那么我们可以轻松比较两个日期！ 假设我们有以下”订单”表： OrderId ProductName OrderDate 1 Geitost 2008-11-11 2 Camembert Pierrot 2008-11-09 3 Mozzarella di Giovanni 2008-11-11 4 Mascarpone Fabioli 2008-10-29 现在，我们希望从上表中选取 OrderDate 为 “2008-11-11” 的记录。 我们使用下面的 SELECT 语句： SELECT * FROM Orders WHERE OrderDate=2008-11-11 结果集如下所示： OrderId ProductName OrderDate 1 Geitost 2008-11-11 3 Mozzarella di Giovanni 2008-11-11 现在，假设 “Orders” 表如下所示（请注意 “OrderDate” 列中的时间部分）： OrderId ProductName OrderDate 1 Geitost 2008-11-11 13:23:44 2 Camembert Pierrot 2008-11-09 15:45:21 3 Mozzarella di Giovanni 2008-11-11 11:12:01 4 Mascarpone Fabioli 2008-10-29 14:56:59 如果我们使用和上面一样的 SELECT 语句： SELECT * FROM Orders WHERE OrderDate=2008-11-11 这样我们就不会有结果了！这是因为查询的日期不包含时间部分。 **提示：**如果您想使查询更加简单和易于维护，请不要使用日期中的时间部分！"},{"title":"SQL 索引","path":"/wiki/sql/sentence/dbindex.html","content":"SQL 索引 索引是一种特殊的查询表，可以被数据库搜索引擎用来加速数据的检索。简单说来，索引就是指向表中数据的指针。数据库的索引同书籍后面的索引非常相像。 例如，如果想要查阅一本书中与某个特定主题相关的所有页面，你会先去查询索引（索引按照字母表顺序列出了所有主题），然后从索引中找到一页或者多页与该主题相关的页面。 索引能够提高 SELECT 查询和 WHERE 子句的速度，但是却降低了包含 UPDATE 语句或 INSERT 语句的数据输入过程的速度。索引的创建与删除不会对表中的数据产生影响。 创建索引需要使用 CREATE INDEX 语句，该语句允许对索引命名，指定要创建索引的表以及对哪些列进行索引，还可以指定索引按照升序或者降序排列。 同 UNIQUE 约束一样，索引可以是唯一的。这种情况下，索引会阻止列中（或者列的组合，其中某些列有索引）出现重复的条目。 CREATE INDEX 命令： **　CREATE INDEX**命令的基本语法如下： CREATE INDEX index_name ON table_name; 单列索引：单列索引基于单一的字段创建，其基本语法如下所示： CREATE INDEX index_nameON table_name (column_name); 唯一索引：唯一索引不止用于提升查询性能，还用于保证数据完整性。唯一索引不允许向表中插入任何重复值。其基本语法如下所示： CREATE UNIQUE INDEX index_nameon table_name (column_name); 如果您希望索引不止一个列，您可以在括号中列出这些列的名称，用逗号隔开： CREATE INDEX index_nameon table_name (column1, column2); 隐式索引：隐式索引由数据库服务器在创建某些对象的时候自动生成。例如，对于主键约束和唯一约束，数据库服务器就会自动创建索引。 DROP INDEX 命令：索引可以用 SQL DROP 命令删除。删除索引时应当特别小心，数据库的性能可能会因此而降低或者提高。 其基本语法如下： sql DROP INDEX table_name.index_name; 什么时候应当避免使用索引？ 尽管创建索引的目的是提升数据库的性能，但是还是有一些情况应当避免使用索引。下面几条指导原则给出了何时应当重新考虑是否使用索引： 小的数据表不应当使用索引； 需要频繁进行大批量的更新或者插入操作的表； 如果列中包含大数或者 NULL 值，不宜创建索引； 频繁操作的列不宜创建索引。"},{"title":"SQL 删除","path":"/wiki/sql/sentence/delete.html","content":"SQL DELETE 语句 DELETE语句用于删除表中现有记录。 SQL DELETE 语法DELETE FROM table_nameWHERE condition; 请注意 删除表格中的记录时要小心！ 注意SQL DELETE 语句中的 WHERE 子句！ WHERE子句指定需要删除哪些记录。如果省略了WHERE子句，表中所有记录都将被删除！ 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是 “Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL DELETE 实例 假设我们想从”Customers” 表中删除客户”Alfreds Futterkiste”。 我们使用以下SQL语句： 示例： DELETE FROM CustomersWHERE CustomerName=Alfreds Futterkiste; 现在，”Customers” 表如下所示： CustomerID CustomerName ContactName Address City PostalCode Country 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden 删除所有数据 您可以删除表中的所有行，而不需要删除该表。这意味着表的结构、属性和索引将保持不变： DELETE FROM table_name; **　或者** DELETE * FROM table_name; **注意：**在没有备份的情况下，删除记录要格外小心！因为你删除了不能恢复！"},{"title":"SQL 选择不同","path":"/wiki/sql/sentence/distinct.html","content":"SQL SELECT DISTINCT 语法 SELECT DISTINCT语法用于仅返回不同的（different）值。 在一张表内，一列通常包含许多重复的值; 有时你只想列出不同的（different）值。 SELECT DISTINCT语句用于仅返回不同的（different）值。 SQL SELECT DISTINCT语法如下所示： SELECT DISTINCT column1, column2, ...FROM table_name; 演示数据库 在本教程中，我们将使用著名的 Northwind 样本数据库。 下面是罗斯文示例数据库中 “Customers” 表的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SELECT实例 以下SQL语句从”Customers”表中的”Country”列中选择所有（包括重复）值：**　代码示例：** SELECT Country FROM Customers; 以上查询的结果： CountryGermanyMexicoMexicoUKSweden 现在，让我们在上面的SELECT语法中使用DISTINCT关键字并查看结果。 SELECT DISTINCT 实例 以下SQL语句仅从”Customers” 表中的 “Country” 列中选择DISTINCT值： 实例1SELECT DISTINCT Country FROM Customers; 查询结果： CountryGermanyMexicoUKSweden 以下SQL语句列出了不同（distinct）客户国家的数量： 实例2SELECT COUNT(DISTINCT Country) FROM Customers; **注意：**上述示例在Firefox和Microsoft Edge中不起作用！ 由于在Microsoft Access数据库中不支持COUNT(DISTINCT column_name)。在我们的示例中Firefox和Microsoft Edge使用Microsoft Access。"},{"title":"SQL 撤销索引/表/数据库","path":"/wiki/sql/sentence/drop.html","content":"SQL 撤销索引、撤销表以及撤销数据库 通过使用 DROP 语句，可以轻松地删除索引、表和数据库。 DROP INDEX 语句 DROP INDEX 语句用于删除表中的索引。 用于 MS Access 的 DROP INDEX 语法：DROP INDEX index_name ON table_name 用于 MS SQL Server 的 DROP INDEX 语法：DROP INDEX table_name.index_name 用于 DB2Oracle 的 DROP INDEX 语法：DROP INDEX index_name 用于 MySQL 的 DROP INDEX 语法：ALTER TABLE table_name DROP INDEX index_name DROP TABLE 语句 DROP TABLE 语句用于删除表。 DROP TABLE table_name DROP DATABASE 语句 DROP DATABASE 语句用于删除数据库。 DROP DATABASE database_name TRUNCATE TABLE 语句 如果我们只需要删除表中的数据，而不删除表本身，那么我们该怎么做？ 使用TRUNCATE TABLE语句： TRUNCATE TABLE table_name"},{"title":"SQL 表达式","path":"/wiki/sql/sentence/express.html","content":"SQL 表达式 表达式是计算值的一个或多个值、运算符和SQL函数的组合。这些SQL表达式类似于公式，它们是用查询语言编写的。 您还可以使用它们查询数据库中的特定数据集。 句法考虑SELECT语句的基本语法，如下所示： SELECT column1, column2, columnN FROM table_name WHERE [CONDITION|EXPRESSION]; 有不同类型的sql表达式，如下所示： 布尔型 数值型 日期 现在让我们详细讨论每一个问题。 布尔表达式 SQL布尔表达式基于匹配单个值获取数据。 句法： SELECT column1, column2, columnN FROM table_name WHERE SINGLE VALUE MATCHING EXPRESSION; 使用具有以下记录的Customers表： SQL SELECT * FROM CUSTOMERS;+----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+7 rows in set (0.00 sec) 下表是一个简单的示例，展示了各种sql布尔表达式的用法。 SQL SELECT * FROM CUSTOMERS WHERE SALARY = 10000;+----+-------+-----+---------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+-------+-----+---------+----------+| 7 | Muffy | 24 | Indore | 10000.00 |+----+-------+-----+---------+----------+1 row in set (0.00 sec) 数值表达式 数值表达式用于在任何查询中执行任何数学运算。 句法： SELECT numerical_expression as OPERATION_NAME[FROM table_nameWHERE CONDITION] ; 这里，数值表达式用于数学表达式或任何公式。下面是一个简单的示例，展示了SQLNDigitic表达式的用法： SQL SELECT (15 + 6) AS ADDITION+----------+| ADDITION |+----------+| 21 |+----------+1 row in set (0.00 sec) 有几个内置函数，如avg()、sum()、count()等，用于对表或特定表列执行所谓的聚合数据计算。 SQL SELECT COUNT(*) AS RECORDS FROM CUSTOMERS; +---------+| RECORDS |+---------+| 7 |+---------+1 row in set (0.00 sec) 日期表达式日期表达式返回当前系统日期和时间值： SQL SELECT CURRENT_TIMESTAMP;+---------------------+| Current_Timestamp |+---------------------+| 2009-11-12 06:40:23 |+---------------------+1 row in set (0.00 sec) 另一个日期表达式如下所示： SQL SELECT GETDATE();;+-------------------------+| GETDATE |+-------------------------+| 2009-10-22 12:07:18.140 |+-------------------------+1 row in set (0.00 sec)"},{"title":"SQL IN运算符","path":"/wiki/sql/sentence/in.html","content":"SQL IN 运算符 IN 运算符允许您在 WHERE 子句中指定多个值。 IN 运算符是多个 OR 条件的简写。 SQL IN 语法SELECT column_name(s)FROM table_nameWHERE column_name IN (value1, value2, ...); 或者SELECT column_name(s)FROM table_nameWHERE column_name IN (SELECT STATEMENT); 演示数据库 在本教程中，我们将使用著名的 Northwind 示例数据库。 以下数据选取自”Customers” 表： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden IN 操作符实例 以下 SQL 语句选取位于”Germany”，”France”和”UK”的所有客户： 代码示例：SELECT * FROM CustomersWHERE Country IN (Germany, France, UK); 以下 SQL 语句选取不在”Germany”，”France”或”UK”中的所有客户： 代码示例：SELECT * FROM CustomersWHERE Country NOT IN (Germany, France, UK); 以下 SQL 语句选取来自同一国家的所有客户作为供应商： 代码示例：SELECT * FROM CustomersWHERE Country IN (SELECT Country FROM Suppliers);"},{"title":"SQL 内部连接","path":"/wiki/sql/sentence/inner.html","content":"SQL INNER JOIN 关键字（内部连接） 内部链接INNER JOIN关键字选择两个表中具有匹配值的记录。 SQL INNER JOIN 语法SELECT column_name(s)FROM table1INNER JOIN table2 ON table1.column_name = table2.column_name; **　注释：**INNER JOIN 与 JOIN 是相同的。 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是 “Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 选自 “Orders” 表的数据： OrderID CustomerID EmployeeID OrderDate ShipperID 10308 2 7 1996-09-18 3 10309 37 3 1996-09-19 1 10310 77 8 1996-09-20 2 SQL INNER JOIN 实例 以下SQL语句将返回所有下订单的客户： 示例： SELECT Customers.CustomerName, Orders.OrderIDFROM CustomersINNER JOIN OrdersON Customers.CustomerID=Orders.CustomerIDORDER BY Customers.CustomerName; **注释：**如果表中至少有一个匹配项，INNER JOIN 关键字将返回一行。如果 “Customers” 表中的行与”Orders” 不匹配，则不会列出行。 加入三张表 以下SQL语句选择包含客户和货运单信息的所有订单： **　代码示例：** SELECT Orders.OrderID, Customers.CustomerName, Shippers.ShipperNameFROM ((OrdersINNER JOIN Customers ON Orders.CustomerID = Customers.CustomerID)INNER JOIN Shippers ON Orders.ShipperID = Shippers.ShipperID);"},{"title":"SQL 在表中插入","path":"/wiki/sql/sentence/insert.html","content":"SQL INSERT INTO 语句 INSERT INTO 语句用于向表中插入新的数据行。 SQL INSERT INTO 语法INSERT INTO 语句可以用两种形式编写。　第一个表单没有指定要插入数据的列的名称，只提供要插入的值，即可添加一行新的数据： sql INSERT INTO table_name (column1, column2, column3, ...)VALUES (value1, value2, value3, ...); 第二种，如果要为表中的所有列添加值，则不需要在SQL查询中指定列名称。但是，请确保值的顺序与表中的列顺序相同。INSERT INTO语法如下所示： sql INSERT INTO table_nameVALUES (value1, value2, value3, ...); 演示数据库 在本教程中，我们将使用著名的 Northwind 示例数据库。 以下是”Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 87 Wartian Herkku Pirkko Koskitalo Torikatu 38 Oulu 90110 Finland 88 Wellington Importadora Paula Parente Rua do Mercado, 12 Resende 08737-363 Brazil 89 White Clover Markets Karl Jablonski 305 - 14th Ave. S. Suite 3B Seattle 98128 USA 90 Wilman Kala Matti Karttunen Keskuskatu 45 Helsinki 21240 Finland 91 Wolski Zbyszek ul. Filtrowa 68 Walla 01-012 Poland INSERT INTO 实例 假设我们想在”Customers”表中插入一个新行。 我们可以使用以下SQL语句： 实例INSERT INTO Customers (CustomerName, ContactName, Address, City, PostalCode, Country)VALUES (‘Cardinal’,’Tom B. Erichsen’,’Skagen 21’,’Stavanger’,’4006’,’Norway’); 现在，选自 “Customers” 表的数据如下所示： CustomerID CustomerName ContactName Address City PostalCode Country 87 Wartian Herkku Pirkko Koskitalo Torikatu 38 Oulu 90110 Finland 88 Wellington Importadora Paula Parente Rua do Mercado, 12 Resende 08737-363 Brazil 89 White Clover Markets Karl Jablonski 305 - 14th Ave. S. Suite 3B Seattle 98128 USA 90 Wilman Kala Matti Karttunen Keskuskatu 45 Helsinki 21240 Finland 91 Wolski Zbyszek ul. Filtrowa 68 Walla 01-012 Poland 92 Cardinal Tom B. Erichsen Skagen 21 Stavanger 4006 Norway 注意到了吗？ 我们没有将任何号码插入 CustomerID 字段。 CustomerID列是一个字段，在将新记录插入到表中时自动生成。 仅在指定的列中插入数据 我们还可以只在指定的列中插入数据。 以下SQL语句插入一个新行，但只在”CustomerName”、”City”和”Country”列中插入数据（CustomerID字段将自动更新）： 示例： INSERT INTO Customers (CustomerName, City, Country)VALUES (Cardinal, Stavanger, Norway); 现在，选自 “Customers” 表的数据如下所示： CustomerID CustomerName ContactName Address City PostalCode Country 87 Wartian Herkku Pirkko Koskitalo Torikatu 38 Oulu 90110 Finland 88 Wellington Importadora Paula Parente Rua do Mercado, 12 Resende 08737-363 Brazil 89 White Clover Markets Karl Jablonski 305 - 14th Ave. S. Suite 3B Seattle 98128 USA 90 Wilman Kala Matti Karttunen Keskuskatu 45 Helsinki 21240 Finland 91 Wolski Zbyszek ul. Filtrowa 68 Walla 01-012 Poland 92 Cardinal null null Stavanger null Norway 使用另一个表填充一个表 您可以通过另一个表上的SELECT语句查询出来的字段值，然后将数据填充到本表中，条件是另一个表所查询的字段与本表要插入数据的字段是一一对应的。 INSERT INTO first_table_name [(column1, column2, ... columnN)] SELECT column1, column2, ...columnN FROM second_table_name[WHERE condition];"},{"title":"SQL INSECT INTO SELECT语句","path":"/wiki/sql/sentence/instosel.html","content":"SQL INSERT INTO SELECT 语句 使用SQL，您可以将信息从一个表中复制到另一个表中。 INSERT INTO SELECT 语句从表中复制数据，并将数据插入现有的表中。目标表中的任何现有行都不会受到影响。 SQL INSERT INTO SELECT 语法我们可以将所有列从一个表中复制到另一个已经存在的表中： INSERT INTO table2 SELECT * FROM table1; 或者我们可以把想要的列复制到另一个现有的表中： INSERT INTO table2 (column_name(s)) SELECT column_name(s) FROM table1; 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是”Customers”表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 选自 “Suppliers” 表的数据： SupplierID SupplierName ContactName Address City Postal Code Country Phone 1 Exotic Liquid Charlotte Cooper 49 Gilbert St. Londona EC1 4SD UK (171) 555-2222 2 New Orleans Cajun Delights Shelley Burke P.O. Box 78934 New Orleans 70117 USA (100) 555-4822 3 Grandma Kelly’s Homestead Regina Murphy 707 Oxford Rd. Ann Arbor 48104 USA (313) 555-5735 SQL INSERT INTO SELECT 实例 把 “Suppliers” 一栏复制到 “Customers” 一栏： 示例： INSERT INTO Customers (CustomerName, Country)SELECT SupplierName, Country FROM Suppliers; 只将德国供应商的副本插入 “Customers” ： 示例： INSERT INTO Customers (CustomerName, Country)SELECT SupplierName, Country FROM SuppliersWHERE Country=Germany;"},{"title":"SQL 注入","path":"/wiki/sql/sentence/input.html","content":"SQL 注入 如果你从网页中获取用户输入，并将其插入到 SQL 数据库中的话，那么你很可能已经暴露于一种被称作 SQL 注入的安全风险之下了。 本节将会教你如何防止 SQL 注入，以及如何保护 Perl 这样的服务器端脚本中的程序和 SQL 语句。 注入通常发生在获取用户输入的时候，例如预期得到用户的名字，但是得到的却是一段很可能会在你不知情的情况下运行的 SQL 语句。 绝对不要相信用户提供的数据，处理这些数据之前必须进行验证；通常，验证工作由模式匹配来完成。 下面的例子中，name 仅限由字母、数字和下划线组成，并且长度在 8 到 20 之间（你可以根据需要修改这些规则）。 if (preg_match(/^\\w8,20$/, $_GET[username], $matches)) $result = mysql_query(SELECT * FROM CUSTOMERS WHERE name=$matches[0]);else echo user name not accepted; 为了展示问题所在，请考虑下面这段代码： // supposed input$name = Qadir; DELETE FROM CUSTOMERS;;mysql_query(SELECT * FROM CUSTOMSRS WHERE name=$name); 下面的函数调用本来是要从 CUSTOMERS 表中取得 name 字段与用户给定的输入相匹配的记录。通常情况下，$name 只包含字母和数字，或许还有空格，例如字符串 ilia。但是，这里通过在 $name 上附加一段全新的查询语句，将原有的函数调用变为了数据库的灾难：注入的 DELETE 语句将会删除表中所有的记录。 幸运的是，如果你在使用　MySQL 的话，mysql_query() 函数不允许查询堆积（query stacking），或者说在一次函数调用中执行多次 SQL 查询。如果你试图进行堆积式查询的话，函数调用将会失败。 然而，其他的 PHP 数据库扩展，例如 SQLite 和 PostgreSQL 会愉快地接受堆积式查询，执行字符串中所有的查询，并由此产生严重的安全问题。 阻止 SQL 注入 你可以在 Perl 或者 PHP 等脚本语言中巧妙地处理所有的转义字符。PHP 的 MySQL 扩展提供了一个 mysql_real_escape_string() 函数，来转义那些对 MySQL 有特殊意义的字符。 if (get_magic_quotes_gpc()) $name = stripslashes($name);$name = mysql_real_escape_string($name);mysql_query(SELECT * FROM CUSTOMERS WHERE name=$name); LIKE 困境 要破解 LIKE 困境，必须有一种专门的转义机制，将用户提供的 ‘%’ 和 ‘_’ 转换为字面值。为此你可以使用 addcslashes() 函数，该函数允许指定要进行转义的字符的范围。 $sub = addcslashes(mysql_real_escape_string(%str), %_);// $sub == \\%str\\_mysql_query(SELECT * FROM messages WHERE subject LIKE $sub%);"},{"title":"SQL Join连接","path":"/wiki/sql/sentence/join.html","content":"SQL JOIN 连接 SQL join 用于把来自两个或多个表的行结合起来。 SQL JOIN SQL JOIN 子句用于把来自两个或多个表的行结合起来，基于这些表之间的共同字段。 简单地说，就是先确定一个主表作为结果集，然后，把其他表的行有选择性地”连接”在主表结果集上。 最常见的 JOIN 类型：SQL INNER JOIN（简单的 JOIN）。 SQL INNER JOIN 从多个表中返回满足 JOIN 条件的所有行。 让我们看看选自 “Orders” 表的数据： OrderID CustomerID OrderDate 10308 2 1996-09-18 10309 37 1996-09-19 10310 77 1996-09-20 然后，看看选自 “Customers” 表的数据： CustomerID CustomerName ContactName Country 1 Alfreds Futterkiste Maria Anders Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Mexico 3 Antonio Moreno Taquería Antonio Moreno Mexico 请注意，”Orders” 表中的 “CustomerID” 列指向 “Customers” 表中的客户。上面这两个表是通过 “CustomerID” 列联系起来的。 然后，如果我们运行下面的 SQL 语句（包含 INNER JOIN）： 示例： SELECT Orders.OrderID, Customers.CustomerName, Orders.OrderDateFROM OrdersINNER JOIN CustomersON Orders.CustomerID=Customers.CustomerID; 运行结果如下所示： OrderID CustomerName OrderDate 10308 Ana Trujillo Emparedados y helados 1996-09-18 不同的 SQL JOIN 在我们继续讲解实例之前，我们先列出您可以使用的不同的 SQL JOIN 类型： INNER JOIN：如果表中有至少一个匹配，则返回行 LEFT JOIN：即使右表中没有匹配，也从左表返回所有的行 RIGHT JOIN：即使左表中没有匹配，也从右表返回所有的行 FULL JOIN：只要其中一个表中存在匹配，则返回行 SELF JOIN ：用于将表连接到自己，就好像该表是两个表一样，临时重命名了SQL语句中的至少一个表 CARTESIAN JOIN：从两个或多个连接表返回记录集的笛卡儿积 SQL JOIN 连接详细用法 SQL 连接（JOIN） 子句用于将数据库中两个或者两个以上表中的记录组合起来。连接通过共有值将不同表中的字段组合在一起。 我们来看看”Orders”表中的选择： OrderID CustomerID OrderDate 10308 2 1996-09-18 10309 37 1996-09-19 10310 77 1996-09-20 然后，查看”Customers”表中的选择： CustomerID CustomerName ContactName Country 1 Alfreds Futterkiste Maria Anders Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Mexico 3 Antonio Moreno Taquería Antonio Moreno Mexico 请注意，”Orders”表中的”客户ID”列是指”CustomerID”表中的”客户ID”。上面两个表格之间的关系是”CustomerID”列。 然后，我们可以创建下面的SQL语句（包含一个INNER JOIN），它选择两个表中具有匹配值的记录： **　代码示例：** SELECT Orders.OrderID, Customers.CustomerName, Orders.OrderDateFROM OrdersINNER JOIN Customers ON Orders.CustomerID=Customers.CustomerID; 它会产生这样的东西： OrderID CustomerName OrderDate 10308 Ana Trujillo Emparedados y helados 9181996 10365 Antonio Moreno Taquería 11271996 10383 Around the Horn 12161996 10355 Around the Horn 11151996 10278 Berglunds snabbköp 8121996 考虑下面两个表，（a）CUSTOMERS 表： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ （b）另一个表是 ORDERS 表： +-----+---------------------+-------------+--------+|OID | DATE | CUSTOMER_ID | AMOUNT | +-----+---------------------+-------------+--------+ | 102 | 2009-10-08 00:00:00 | 3 | 3000 || 100 | 2009-10-08 00:00:00 | 3 | 1500 | | 101 | 2009-11-20 00:00:00 | 2 | 1560 || 103 | 2008-05-20 00:00:00 | 4 | 2060 | +-----+---------------------+-------------+--------+ 现在，让我们用 SELECT 语句将这个两张表连接（JOIN）在一起： SQL SELECT ID, NAME, AGE, AMOUNT FROM CUSTOMERS, ORDERS WHERE CUSTOMERS.ID = ORDERS.CUSTOMER_ID; 上述语句的运行结果如下所示： +----+----------+-----+--------+| ID | NAME | AGE | AMOUNT | +----+----------+-----+--------+ | 3 | kaushik | 23 | 3000 || 3 | kaushik | 23 | 1500 | | 2 | Khilan | 25 | 1560 || 4 | Chaitali | 25 | 2060 | +----+----------+-----+--------+ 不同类型的SQL联接 SQL 中有多种不同的连接： 内连接（INNER JOIN）：当两个表中都存在匹配时，才返回行。 左连接（LEFT JOIN）：返回左表中的所有行，即使右表中没有匹配的行。 右连接（RIGHT JOIN）：返回右表中的所有行，即使左表中没有匹配的行。 全连接（FULL JOIN）：只要某一个表存在匹配，就返回行。 笛卡尔连接（CARTESIAN JOIN）：返回两个或者更多的表中记录集的笛卡尔积。 内连接最常用也最重要的连接形式是内连接，有时候也被称作”EQUIJOIN”（等值连接）。 内连接根据连接谓词来组合两个表中的字段，以创建一个新的结果表。SQL 查询会比较逐个比较表 1 和表 2 中的每一条记录，来寻找满足连接谓词的所有记录对。当连接谓词得以满足时，所有满足条件的记录对的字段将会结合在一起构成结果表。 语法：**　内连接**的基本语法如下所示： sql SELECT table1.column1, table2.column2...FROM table1INNER JOIN table2ON table1.common_field = table2.common_field; 示例：考虑如下两个表格，（a）CUSTOMERS 表： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ （b）ORDERS 表： +-----+---------------------+-------------+--------+| OID | DATE | ID | AMOUNT | +-----+---------------------+-------------+--------+ | 102 | 2009-10-08 00:00:00 | 3 | 3000 || 100 | 2009-10-08 00:00:00 | 3 | 1500 | | 101 | 2009-11-20 00:00:00 | 2 | 1560 || 103 | 2008-05-20 00:00:00 | 4 | 2060 | +-----+---------------------+-------------+--------+ 现在，让我们用内连接将这两个表连接在一起： SQL SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS INNER JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_ID; 上述语句将会产生如下结果： +----+----------+--------+---------------------+| ID | NAME | AMOUNT | DATE | +----+----------+--------+---------------------+ | 3 | kaushik | 3000 | 2009-10-08 00:00:00 || 3 | kaushik | 1500 | 2009-10-08 00:00:00 | | 2 | Khilan | 1560 | 2009-11-20 00:00:00 || 4 | Chaitali | 2060 | 2008-05-20 00:00:00 | +----+----------+--------+---------------------+ 左连接**　左链接**返回左表中的所有记录，即使右表中没有任何满足匹配条件的记录。这意味着，如果 ON 子句在右表中匹配到了 0 条记录，该连接仍然会返回至少一条记录，不过返回的记录中所有来自右表的字段都为 NULL。 这就意味着，左连接会返回左表中的所有记录，加上右表中匹配到的记录，或者是 NULL （如果连接谓词无法匹配到任何记录的话）。 语法：**　左连接**的基本语法如下所示： SELECT table1.column1, table2.column2...FROM table1LEFT JOIN table2ON table1.common_field = table2.common_field; 这里，给出的条件可以是任何根据你的需要写出的条件。 示例：考虑如下两个表格，（a）CUSTOMERS 表： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ （b）ORDERS 表： +-----+---------------------+-------------+--------+| OID | DATE | ID | AMOUNT | +-----+---------------------+-------------+--------+ | 102 | 2009-10-08 00:00:00 | 3 | 3000 || 100 | 2009-10-08 00:00:00 | 3 | 1500 | | 101 | 2009-11-20 00:00:00 | 2 | 1560 || 103 | 2008-05-20 00:00:00 | 4 | 2060 | +-----+---------------------+-------------+--------+ 现在，让我们用左连接将这两个表连接在一起： SQL SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS LEFT JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_ID; 上述语句将会产生如下结果： +----+----------+--------+---------------------+| ID | NAME | AMOUNT | DATE | +----+----------+--------+---------------------+ | 1 | Ramesh | NULL | NULL || 2 | Khilan | 1560 | 2009-11-20 00:00:00 | | 3 | kaushik | 3000 | 2009-10-08 00:00:00 || 3 | kaushik | 1500 | 2009-10-08 00:00:00 | | 4 | Chaitali | 2060 | 2008-05-20 00:00:00 || 5 | Hardik | NULL | NULL | | 6 | Komal | NULL | NULL || 7 | Muffy | NULL | NULL | +----+----------+--------+---------------------+ 右连接**　右链接**返回右表中的所有记录，即是左表中没有任何满足匹配条件的记录。这意味着，如果 ON 子句在左表中匹配到了 0 条记录，该连接仍然会返回至少一条记录，不过返回的记录中所有来自左表的字段都为 NULL。 这就意味着，右连接会返回右表中的所有记录，加上左表中匹配到的记录，或者是 NULL （如果连接谓词无法匹配到任何记录的话）。 语法：**　右连接**的基本语法如下所示： SELECT table1.column1, table2.column2...FROM table1RIGHT JOIN table2ON table1.common_field = table2.common_field; 这里，给出的条件可以是任何根据你的需要写出的条件。 示例：考虑如下两个表格，（a）CUSTOMERS 表： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ （b）ORDERS 表： +-----+---------------------+-------------+--------+| OID | DATE | ID | AMOUNT | +-----+---------------------+-------------+--------+ | 102 | 2009-10-08 00:00:00 | 3 | 3000 || 100 | 2009-10-08 00:00:00 | 3 | 1500 | | 101 | 2009-11-20 00:00:00 | 2 | 1560 || 103 | 2008-05-20 00:00:00 | 4 | 2060 | +-----+---------------------+-------------+--------+ 现在，让我们用右连接将这两个表连接在一起： SQL SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS RIGHT JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_ID; 上述语句将会产生如下结果： +------+----------+--------+---------------------+| ID | NAME | AMOUNT | DATE | +------+----------+--------+---------------------+ | 3 | kaushik | 3000 | 2009-10-08 00:00:00 || 3 | kaushik | 1500 | 2009-10-08 00:00:00 | | 2 | Khilan | 1560 | 2009-11-20 00:00:00 || 4 | Chaitali | 2060 | 2008-05-20 00:00:00 | +------+----------+--------+---------------------+ 全连接**　全连接**将左连接和右连接的结果组合在一起。 语法：SELECT table1.column1, table2.column2...FROM table1FULL JOIN table2ON table1.common_field = table2.common_field; 这里，给出的条件可以是任何根据你的需要写出的条件。 示例：考虑如下两个表格，（a）CUSTOMERS 表： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ （b）ORDERS 表： +-----+---------------------+-------------+--------+| OID | DATE | ID | AMOUNT | +-----+---------------------+-------------+--------+ | 102 | 2009-10-08 00:00:00 | 3 | 3000 || 100 | 2009-10-08 00:00:00 | 3 | 1500 | | 101 | 2009-11-20 00:00:00 | 2 | 1560 || 103 | 2008-05-20 00:00:00 | 4 | 2060 | +-----+---------------------+-------------+--------+ 现在让我们用全连接将两个表连接在一起： SQL SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS FULL JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_ID; 上述语句将会产生如下结果： +------+----------+--------+---------------------+| ID | NAME | AMOUNT | DATE | +------+----------+--------+---------------------+ | 1 | Ramesh | NULL | NULL || 2 | Khilan | 1560 | 2009-11-20 00:00:00 | | 3 | kaushik | 3000 | 2009-10-08 00:00:00 || 3 | kaushik | 1500 | 2009-10-08 00:00:00 | | 4 | Chaitali | 2060 | 2008-05-20 00:00:00 || 5 | Hardik | NULL | NULL | | 6 | Komal | NULL | NULL || 7 | Muffy | NULL | NULL | | 3 | kaushik | 3000 | 2009-10-08 00:00:00 || 3 | kaushik | 1500 | 2009-10-08 00:00:00 | | 2 | Khilan | 1560 | 2009-11-20 00:00:00 || 4 | Chaitali | 2060 | 2008-05-20 00:00:00 | +------+----------+--------+---------------------+ 如果你所用的数据库不支持全连接，比如 MySQL，那么你可以使用 UNION ALL子句来将左连接和右连接结果组合在一起： SQL SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS LEFT JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_IDUNION ALL SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS RIGHT JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_ID 笛卡尔连接（交叉连接）**　笛卡尔连接** 或者交叉连接返回两个或者更多的连接表中记录的笛卡尔乘积。也就是说，它相当于连接谓词总是为真或者缺少连接谓词的内连接。 语法：**　笛卡尔连接** 或者说交叉连接的基本语法如下所示： SELECT table1.column1, table2.column2...FROM table1, table2 [, table3 ] 示例：考虑如下两个表格，（a）CUSTOMERS 表： +----+----------+-----+-----------+----------+ | ID | NAME | AGE | ADDRESS | SALARY | +----+----------+-----+-----------+----------+ | 1 | Ramesh | 32 | Ahmedabad | 2000.00 | | 2 | Khilan | 25 | Delhi | 1500.00 | | 3 | kaushik | 23 | Kota | 2000.00 | | 4 | Chaitali | 25 | Mumbai | 6500.00 | | 5 | Hardik | 27 | Bhopal | 8500.00 | | 6 | Komal | 22 | MP | 4500.00 | | 7 | Muffy | 24 | Indore | 10000.00 | +----+----------+-----+-----------+----------+（b）ORDERS 表： +-----+---------------------+-------------+--------+ | OID | DATE | ID | AMOUNT | +-----+---------------------+-------------+--------+ | 102 | 2009-10-08 00:00:00 | 3 | 3000 | | 100 | 2009-10-08 00:00:00 | 3 | 1500 | | 101 | 2009-11-20 00:00:00 | 2 | 1560 | | 103 | 2008-05-20 00:00:00 | 4 | 2060 | +-----+---------------------+-------------+--------+ 现在，让我用内连接将这两个表连接在一起： SQL SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS, ORDERS; 上述语句将会产生如下结果： +----+----------+--------+---------------------+| ID | NAME | AMOUNT | DATE | +----+----------+--------+---------------------+ | 1 | Ramesh | 3000 | 2009-10-08 00:00:00 || 1 | Ramesh | 1500 | 2009-10-08 00:00:00 | | 1 | Ramesh | 1560 | 2009-11-20 00:00:00 || 1 | Ramesh | 2060 | 2008-05-20 00:00:00 | | 2 | Khilan | 3000 | 2009-10-08 00:00:00 || 2 | Khilan | 1500 | 2009-10-08 00:00:00 | | 2 | Khilan | 1560 | 2009-11-20 00:00:00 || 2 | Khilan | 2060 | 2008-05-20 00:00:00 | | 3 | kaushik | 3000 | 2009-10-08 00:00:00 || 3 | kaushik | 1500 | 2009-10-08 00:00:00 | | 3 | kaushik | 1560 | 2009-11-20 00:00:00 || 3 | kaushik | 2060 | 2008-05-20 00:00:00 | | 4 | Chaitali | 3000 | 2009-10-08 00:00:00 || 4 | Chaitali | 1500 | 2009-10-08 00:00:00 | | 4 | Chaitali | 1560 | 2009-11-20 00:00:00 || 4 | Chaitali | 2060 | 2008-05-20 00:00:00 | | 5 | Hardik | 3000 | 2009-10-08 00:00:00 || 5 | Hardik | 1500 | 2009-10-08 00:00:00 | | 5 | Hardik | 1560 | 2009-11-20 00:00:00 || 5 | Hardik | 2060 | 2008-05-20 00:00:00 | | 6 | Komal | 3000 | 2009-10-08 00:00:00 || 6 | Komal | 1500 | 2009-10-08 00:00:00 | | 6 | Komal | 1560 | 2009-11-20 00:00:00 || 6 | Komal | 2060 | 2008-05-20 00:00:00 | | 7 | Muffy | 3000 | 2009-10-08 00:00:00 || 7 | Muffy | 1500 | 2009-10-08 00:00:00 | | 7 | Muffy | 1560 | 2009-11-20 00:00:00 || 7 | Muffy | 2060 | 2008-05-20 00:00:00 | +----+----------+--------+---------------------+"},{"title":"SQL 左连接","path":"/wiki/sql/sentence/left.html","content":"SQL 左连接 LEFT JOIN 关键字 SQL左链接LEFT JOIN关键字返回左表（表1）中的所有行，即使在右表（表2）中没有匹配。如果在正确的表中没有匹配，结果是NULL。 SQL LEFT JOIN 语法SELECT column_name(s) FROM table1 LEFT JOIN table2 ON table1.column_name=table2.column_name; 或： SELECT column_name(s) FROM table1 LEFT OUTER JOIN table2 ON table1.column_name=table2.column_name; **注释：**在一些数据库中，LEFT JOIN称为LEFT OUT ER JOIN。 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是 “Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 选自 “Orders” 表的数据： OrderID CustomerID EmployeeID OrderDate ShipperID 10308 2 7 1996-09-18 3 10309 37 3 1996-09-19 1 10310 77 8 1996-09-20 2 SQL LEFT JOIN 实例 以下SQL语句将选择所有客户以及他们可能拥有的任何订单： 示例： SELECT Customers.CustomerName, Orders.OrderIDFROM CustomersLEFT JOIN Orders ON Customers.CustomerID = Orders.CustomerIDORDER BY Customers.CustomerName; **注释：**LEFT JOIN 关键字返回左表（Customers）中的所有行，即使在右边表（Orders）中没有匹配。"},{"title":"SQL LIKE运算符","path":"/wiki/sql/sentence/like.html","content":"SQL LIKE 运算符 在WHERE子句中使用LIKE运算符来搜索列中的指定模式。 有两个通配符与LIKE运算符一起使用： ％ - 百分号表示零个，一个或多个字符 _ - 下划线表示单个字符 **　注意：** MS Access使用问号（?）而不是下划线（_）。 百分号和下划线也可以组合使用！ SQL LIKE 语法SELECT column1, column2, ...FROM table_nameWHERE columnN LIKE pattern; **　提示** ：您还可以使用AND或OR运算符组合任意数量的条件。 下面是一些使用’％’和’_’通配符显示不同LIKE运算符的例子： LIKE 运算符 描述 WHERE CustomerName LIKE ‘a%’ 查找以”a”开头的任何值 WHERE CustomerName LIKE ‘%a’ 查找以”a”结尾的任何值 WHERE CustomerName LIKE ‘%or%’ 在任何位置查找任何具有”or”的值 WHERE CustomerName LIKE ‘_r%’ 在第二个位置查找任何具有”r”的值 WHERE CustomerName LIKE ‘a_%_%’ 查找以”a”开头且长度至少为3个字符的值 WHERE ContactName LIKE ‘a%o’ 找到以”a”开头，以”o”结尾的值 演示数据库在本教程中，我们将使用著名的Northwind示例数据库。 以下是”Customers”表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL LIKE 运算符实例 以下SQL语句选择以”a”开头的CustomerName的所有客户： **　代码示例：** SELECT * FROM CustomersWHERE CustomerName LIKE a%; 以下SQL语句选择客户名称以”a”结尾的所有客户： **　代码示例：** SELECT * FROM CustomersWHERE CustomerName LIKE %a; 以下SQL语句选择客户名称在任何位置都具有”or”的所有客户： **　代码示例：** SELECT * FROM CustomersWHERE CustomerName LIKE %or%; 以下SQL语句选择客户名称在第二位具有”r”的所有客户： **　代码示例：** SELECT * FROM CustomersWHERE CustomerName LIKE _r%; 以下SQL语句选择客户名称以”a”开头且长度至少为3个字符的所有客户： **　代码示例：** SELECT * FROM CustomersWHERE CustomerName LIKE a_%_%; 以下SQL语句选择联系人名称以”a”开头并以”o”结尾的所有客户： **　代码示例：** SELECT * FROM CustomersWHERE ContactName LIKE a%o; 以下SQL语句选择客户名称不以”a”开头的所有客户： **　代码示例：** SELECT * FROM CustomersWHERE CustomerName NOT LIKE a%; 以下SQL语句选择客户名称以”a”开头，以”s”结尾的5位字符的所有客户： **　代码示例：** SELECT * FROM CustomersWHERE CustomerName LIKE a___s;"},{"title":"SQL TOP/LIMIT语句","path":"/wiki/sql/sentence/limit.html","content":"SQL SELECT TOP 子句 SELECT TOP 子句用于指定要返回的记录数量。 SELECT TOP子句在包含数千条记录的大型表上很有用。返回大量记录会影响性能。 **注：**并不是所有的数据库系统都支持SELECT TOP子句。MySQL支持LIMIT子句来选择有限数量的记录，而Oracle使用ROWNUM。 SQL Server MS Access 语法SELECT TOP number|percent column_name(s)FROM table_nameWHERE condition; MySQL 和 Oracle 中的 SQL SELECT TOP 是等价的 MySQL语法：SELECT column_name(s)FROM table_nameWHERE conditionLIMIT number; 实例SELECT *FROM PersonsLIMIT 5; Oracle 语法SELECT column_name(s)FROM table_nameWHERE ROWNUM = number; 示例： SELECT *FROM PersonsWHERE ROWNUM =5; 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是”Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL SELECT TOP 实例 以下SQL语句从”Customers” 表中选择前两条记录： 示例： SELECT TOP 2 * FROM Customers; SQL SELECT TOP PERCENT 实例 以下SQL语句从 “Customers” 表中选择前50%的记录： 示例： SELECT TOP 50 PERCENT * FROM Customers; SQL TOP，LIMIT和ROWNUM示例以下SQL语句从”Customers”表中选择前三个记录： SELECT TOP 3 * FROM Customers; 以下SQL语句显示了使用LIMIT子句的等效示例： SELECT * FROM CustomersLIMIT 3; 以下SQL语句显示了使用ROWNUM的等效示例： SELECT * FROM CustomersWHERE ROWNUM = 3; SQL TOP PERCENT示例以下SQL语句从”Customers”表中选择记录的前50％：SELECT TOP 50 PERCENT * FROM Customers; 添加一个条件 以下SQL语句从”Customers”表中选择国家为”Germany”的前三条记录： SELECT TOP 3 * FROM CustomersWHERE Country=Germany; 以下SQL语句显示了使用LIMIT子句的等效示例： SELECT * FROM CustomersWHERE Country=GermanyLIMIT 3; 以下SQL语句显示了使用ROWNUM的等效示例： SELECT * FROM CustomersWHERE Country=Germany AND ROWNUM = 3; 为什么要LIMIT你的查询结果 LIMIT作为一种简单的分页方法，主要是为了减少数据返回的时间，如果您查询一个非常大的表(例如一个有数十万或数百万行的表)而不使用限制，那么您可能会等待很长时间才能显示所有的结果，所以使用LIMIT可以减少查询数据返回的时间，提高效率。"},{"title":"SQL 按关键字排序","path":"/wiki/sql/sentence/order.html","content":"SQL ORDER BY 关键字 ORDER BY 关键字用于按升序或降序对结果集进行排序。 ORDER BY 关键字默认情况下按升序排序记录。 如果需要按降序对记录进行排序，可以使用DESC关键字。 SQL ORDER BY 语法SELECT column1, column2, ...FROM table_nameORDER BY column1, column2, ... ASC|DESC; 您可以在ORDER BY子句中使用多个列，但要确保用于对该列进行排序的列应该在列表中。 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是 “Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden ORDER BY 实例 下面的 SQL 语句从 “Customers” 表中选取所有客户，并按照 “Country” 列排序： 示例： SELECT * FROM CustomersORDER BY Country; ORDER BY DESC 实例 下面的 SQL 语句从 “Customers” 表中选取所有客户，并按照 “Country” 列降序排序： 实例SELECT * FROM CustomersORDER BY Country DESC; ORDER BY 多列 实例1 下面的 SQL 语句从 “Customers” 表中选取所有客户，并按照 “Country” 和 “CustomerName” 列排序： 示例： SELECT * FROM CustomersORDER BY Country, CustomerName; ORDER BY 多列 实例2 以下SQL语句从”Customers” 表中选择所有客户，按 “Country” 升序排列，并按 “CustomerName” 列降序排列： SELECT * FROM CustomersORDER BY Country ASC, CustomerName DESC;"},{"title":"SQL RBDMS概念","path":"/wiki/sql/sentence/rdbms.html","content":"SQL RDBMS 概念 RDBMS是关系数据库管理系统(Relational Database Management System)的缩写。 RDBMS是SQL的基础，也是所有现代数据库系统(如MS SQL Server、IBMDB2、Oracle、MySQL和MicrosoftAccess)的基础。 关系数据库管理系统(Relational Database Management System，RDBMS)是一种基于E.F.Codd提出的关系模型的数据库管理系统。 什么是表？ RDBMS中的数据存储在称为表的数据库对象中。这个表基本上是一个相关数据条目的集合，它由许多列和行组成。请记住，表是关系数据库中最常见和最简单的数据存储形式。 下面的程序是Customers表的一个示例 +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 什么是字段？ 每个表都被分解成更小的实体，称为字段。Customers表中的字段由ID、姓名、年龄、地址和薪资组成。 字段是表中的列，用于维护有关表中每条记录的特定信息。 什么是记录或者行数据？ 记录也称为数据行，即表中存在的每个单独的条目。例如，上面的Customers表中有7条记录。下面是Customers表中的单行数据或记录。 +----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 |+----+----------+-----+-----------+----------+ 记录是表中的水平实体。 什么是列？ 列是表中的垂直实体，其中包含与表中特定字段关联的所有信息。 例如，Customers表中的一列是Address，它表示位置描述，如下所示： +-----------+| ADDRESS |+-----------+| Ahmedabad || Delhi || Kota || Mumbai || Bhopal || MP || Indore |+----+------+ 什么是空值？ 表中的空值是显示为空的字段中的值，这意味着具有空值的字段是没有值的字段。 非常重要的一点是空值不同于零值或包含空格的字段。具有空值的字段是在创建记录时留空的字段。 SQL约束 约束是在表上的数据列上强制执行的规则。它们用于限制可以进入表中的数据类型。 这确保了数据库中数据的准确性和可靠性。 约束可以是列级别，也可以是表级别。列级约束仅应用于一列，而表级约束则应用于整个表。 以下是sql−中可用的一些最常用的约束 ：保证列中数据不能有 NULL 值 ：提供该列数据未指定时所采用的默认值 ：保证列中的所有数据各不相同 ：唯一标识数据表中的行记录 ：唯一标识其他表中的一条行记录 ：此约束保证列中的所有值满足某一条件 ：用于在数据库中快速创建或检索数据 约束可以在创建表时规定（通过 CREATE TABLE 语句），或者在表创建之后规定（通过 ALTER TABLE 语句）。 数据完整性 每个关系数据库管理系统都存在以下类型的数据完整性： 实体完整性−表中没有重复行。域完整性−通过限制值的类型、格式或范围来强制执行给定列的有效条目。引用完整性−不能删除其他记录使用的行。用户定义的完整性−强制执行一些不属于实体、域或引用完整性的特定业务规则。 数据库规范化 数据库规范化是在数据库中有效地组织数据的过程。这个规范化过程有两个原因： 消除冗余数据，例如，将相同的数据存储在多个表中。 确保数据依赖关系是有意义的。 这两个原因都是值得追求的目标，因为它们减少了数据库消耗的空间量，并确保了数据的逻辑存储。 规范化由一系列指导原则组成，有助于指导您创建良好的数据库结构。 规范化指导原则称为范式，范式的目的是组织数据库结构，使其符合第一范式、第二范式和第三范式的规则。 你可以更长远的去选择第四范式，第五范式，等等，但一般来说，第三范式已经足够了。 第一范式(1NF)第二范式(2NF)第三范式(3NF)"},{"title":"SQL 处理重复数据","path":"/wiki/sql/sentence/repeat.html","content":"SQL 处理重复数据 有时候，数据表中会存在相同的记录。在获取表中记录时，相较于取得重复记录来说，取得唯一的记录显然更有意义。 我们之前讨论过的 SQL DISTINCT 关键字，与 SELECT 语句一起使用可以时，可以达到消除所有重复记录，只返回唯一记录的目的。 语法 利用 DISTINCT 关键字来消除重复记录的基本语法如下所示： SELECT DISTINCT column1, column2,.....columnN FROM table_nameWHERE [condition] 示例： 考虑 CUSTOMERS 表，表中记录如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 首先，让我们先看一下 SELECT 语句是如何返回重复的薪水记录的： SQL SELECT SALARY FROM CUSTOMERS ORDER BY SALARY; 运行上述语句将会得到以下结果，其中 SALARY 为 2000 的记录出现了两次，即来自原始数据表的重复记录： +----------+| SALARY |+----------+| 1500.00 || 2000.00 || 2000.00 || 4500.00 || 6500.00 || 8500.00 || 10000.00 |+----------+ 现在，让我们在上面的 SELECT 查询中使用 DISTINCT 关键字，然后观察将会得到什么结果： SQL SELECT DISTINCT SALARY FROM CUSTOMERS ORDER BY SALARY; 上述语句将会产生如下结果，这一再没有任何重复的条目了： +----------+| SALARY |+----------+| 1500.00 || 2000.00 || 4500.00 || 6500.00 || 8500.00 || 10000.00 |+----------+"},{"title":"SQL 完整外部连接","path":"/wiki/sql/sentence/outer.html","content":"SQL FULL OUTER JOIN 关键字 当左（表1）或右（表2）表记录匹配时，FULL OUTER JOIN关键字将返回所有记录。 **　注意：** FULL OUTER JOIN可能会返回非常大的结果集！ SQL FULL OUTER JOIN 语法SELECT column_name(s)FROM table1FULL OUTER JOIN table2 ON table1.column_name = table2.column_name; 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是”Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 选自 “Orders” 表的数据： OrderID CustomerID EmployeeID OrderDate ShipperID 10308 2 7 1996-09-18 3 10309 3 3 1996-09-19 1 10310 77 8 1996-09-20 2 SQL FULL OUTER JOIN 实例 以下SQL语句选择所有客户和所有订单： SELECT Customers.CustomerName, Orders.OrderIDFROM CustomersFULL OUTER JOIN Orders ON Customers.CustomerID=Orders.CustomerIDORDER BY Customers.CustomerName; 从这套结果中选择的数据如下： CustomerName OrderID Alfreds Futterkiste Ana Trujillo Emparedados y helados 10308 Antonio Moreno Taquería 10309 10310 注意： FULL OUTER JOIN关键字返回左表（Customers）中的所有行，以及右表（Orders）中的所有行。如果 “Customers”中的行中没有”Orders”中的匹配项，或者”Orders”中的行中没有 “Customers”中的匹配项，那么这些行也会列出。"},{"title":"SQL 右连接","path":"/wiki/sql/sentence/right.html","content":"SQL右连接 RIGHT JOIN 关键字 SQL右链接 RIGHT JOIN 关键字返回右表（table2）的所有行，即使在左表（table1）上没有匹配。如果左表没有匹配，则结果为NULL。 SQL RIGHT JOIN 语法SELECT column_name(s)FROM table1RIGHT JOIN table2 ON table1.column_name = table2.column_name; **注释：**在一些数据库中，RIGHT JOIN 称为 RIGHT OUTER JOIN。 演示数据库在本教程中，我们将使用着名的Northwind示例数据库。 以下是”Orders”表中的一个选项： OrderID CustomerID EmployeeID OrderDate ShipperID 10308 2 7 1996-09-18 3 10309 37 3 1996-09-19 1 10310 77 8 1996-09-20 2 并从”Employees” t表中选择： EmployeeID LastName FirstName BirthDate Photo 1 Davolio Nancy 1281968 EmpID1.pic 2 Fuller Andrew 2191952 EmpID2.pic 3 Leverling Janet 8301963 EmpID3.pic SQL RIGHT JOIN 实例 以下SQL语句将返回所有雇员以及他们可能已经放置的任何订单： 示例： SELECT Orders.OrderID, Employees.LastName, Employees.FirstNameFROM OrdersRIGHT JOIN Employees ON Orders.EmployeeID = Employees.EmployeeIDORDER BY Orders.OrderID; **注释：**RIGHT JOIN 关键字返回右表（Employees）的所有行，即使在左表（Orders）中没有匹配。"},{"title":"SQL 自连接","path":"/wiki/sql/sentence/self.html","content":"SQL自连接 自联接是一种常规联接，但表本身是连接的。 Self JOIN语法SELECT column_name(s)FROM table1 T1, table1 T2WHERE condition; 演示数据库 在本教程中，我们将使用着名的Northwind示例数据库。 以下是”Customers”表中的选择： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico SQL Self JOIN示例 以下SQL语句匹配来自同一城市的客户： 示例 SELECT A.CustomerName AS CustomerName1, B.CustomerName AS CustomerName2, A.CityFROM Customers A, Customers BWHERE A.CustomerID B.CustomerIDAND A.City = B.City ORDER BY A.City;"},{"title":"SQL 语句快速参考","path":"/wiki/sql/sentence/refer.html","content":"SQL语句快速参考 SQL 语句 语法 AND OR SELECT column_name(s) FROM table_name WHERE condition AND|OR condition ALTER TABLE ALTER TABLE table_name ADD column_name datatype or ALTER TABLE table_name DROP COLUMN column_name AS (alias) SELECT column_name AS column_alias FROM table_name or SELECT column_name FROM table_name AS table_alias BETWEEN SELECT column_name(s) FROM table_name WHERE column_name BETWEEN value1 AND value2 CREATE DATABASE CREATE DATABASE database_name CREATE TABLE CREATE TABLE table_name ( column_name1 data_type, column_name2 data_type, column_name2 data_type, … ) CREATE INDEX CREATE INDEX index_name ON table_name (column_name) or CREATE UNIQUE INDEX index_name ON table_name (column_name) CREATE VIEW CREATE VIEW view_name AS SELECT column_name(s) FROM table_name WHERE condition DELETE DELETE FROM table_name WHERE some_columnsome_value or DELETE FROM table_name (**Note:**Deletes the entire table!!) DELETE * FROM table_name (**Note:**Deletes the entire table!!) DROP DATABASE DROP DATABASE database_name DROP INDEX DROP INDEX table_name.index_name (SQL Server) DROP INDEX index_name ON table_name (MS Access) DROP INDEX index_name (DB2Oracle) ALTER TABLE table_name DROP INDEX index_name (MySQL) DROP TABLE DROP TABLE table_name GROUP BY SELECT column_name, aggregate_function(column_name) FROM table_name WHERE column_name operator value GROUP BY column_name HAVING SELECT column_name, aggregate_function(column_name) FROM table_name WHERE column_name operator value GROUP BY column_name HAVING aggregate_function(column_name) operator value IN SELECT column_name(s) FROM table_name WHERE column_name IN (value1,value2,..) INSERT INTO INSERT INTO table_name VALUES (value1, value2, value3,….) or INSERT INTO table_name (column1, column2, column3,…) VALUES (value1, value2, value3,….) INNER JOIN SELECT column_name(s) FROM table_name1 INNER JOIN table_name2 ON table_name1.column_nametable_name2.column_name LEFT JOIN SELECT column_name(s) FROM table_name1 LEFT JOIN table_name2 ON table_name1.column_nametable_name2.column_name RIGHT JOIN SELECT column_name(s) FROM table_name1 RIGHT JOIN table_name2 ON table_name1.column_nametable_name2.column_name FULL JOIN SELECT column_name(s) FROM table_name1 FULL JOIN table_name2 ON table_name1.column_nametable_name2.column_name LIKE SELECT column_name(s) FROM table_name WHERE column_nameLIKE pattern ORDER BY SELECT column_name(s) FROM table_name ORDER BY column_name [ASC|DESC] SELECT SELECT column_name(s) FROM table_name SELECT * SELECT * FROM table_name SELECT DISTINCT SELECT DISTINCT column_name(s) FROM table_name SELECT INTO SELECT * INTO new_table_name [IN externaldatabase] FROM old_table_name or SELECT column_name(s) INTO new_table_name [IN externaldatabase] FROM old_table_name SELECT TOP SELECT TOP number|percent column_name(s) FROM table_name TRUNCATE TABLE TRUNCATE TABLE table_name UNION SELECT column_name(s) FROM table_name1 UNION SELECT column_name(s) FROM table_name2 UNION ALL SELECT column_name(s) FROM table_name1 UNION ALL SELECT column_name(s) FROM table_name2 UPDATE UPDATE table_name SET column1value, column2value,… WHERE some_columnsome_value WHERE SELECT column_name(s) FROM table_name WHERE column_name operator value"},{"title":"SQL 使用序列","path":"/wiki/sql/sentence/sequence.html","content":"SQL 使用序列 序列是根据需要产生的一组有序整数：1, 2, 3 … 序列在数据库中经常用到，因为许多应用要求数据表中的的每一行都有一个唯一的值，序列为此提供了一种简单的方法。 本节阐述在 MySQL 中如何使用序列。 使用 AUTO_INCREMENT 列 在 MySQL 中使用序列最简单的方式是，把某列定义为 AUTO_INCREMENT，然后将剩下的事情交由 MySQL 处理： 示例 试一下下面的例子，该例将会创建一张新表，然后再里面插入几条记录，添加记录时并不需要指定记录的 ID，因为该列的值由 MySQL 自动增加。 mysql CREATE TABLE INSECT - ( - id INT UNSIGNED NOT NULL AUTO_INCREMENT, - PRIMARY KEY (id), - name VARCHAR(30) NOT NULL, # type of insect - date DATE NOT NULL, # date collected - origin VARCHAR(30) NOT NULL # where collected);Query OK, 0 rows affected (0.02 sec)mysql INSERT INTO INSECT (id,name,date,origin) VALUES - (NULL,housefly,2001-09-10,kitchen), - (NULL,millipede,2001-09-10,driveway), - (NULL,grasshopper,2001-09-10,front yard);Query OK, 3 rows affected (0.02 sec)Records: 3 Duplicates: 0 Warnings: 0mysql SELECT * FROM INSECT ORDER BY id;+----+-------------+------------+------------+| id | name | date | origin |+----+-------------+------------+------------+| 1 | housefly | 2001-09-10 | kitchen || 2 | millipede | 2001-09-10 | driveway || 3 | grasshopper | 2001-09-10 | front yard |+----+-------------+------------+------------+3 rows in set (0.00 sec) 获取 AUTO_INCREMENT 值 LAST_INSERT_ID() 是一个 SQL 函数，可以用在任何能够执行 SQL 语句地方。另外，Perl 和 PHP 各自提供了其独有的函数，用于获得最后一条记录的 AUTO_INCREMENT 值。 Perl 示例 使用 mysql_insertid 属性来获取 SQL 查询产生的 AUTO_INCREMENT 值。根据执行查询的方式不同，该属性可以通过数据库句柄或者语句句柄来访问。下面的示例通过数据库句柄取得自增值： $dbh-do (INSERT INTO INSECT (name,date,origin)VALUES(moth,2001-09-14,windowsill));my $seq = $dbh-mysql_insertid; PHP 示例 在执行完会产生自增值的查询后，可以通过调用 mysql_insert_id() 来获取此值： mysql_query (INSERT INTO INSECT (name,date,origin)VALUES(moth,2001-09-14,windowsill), $conn_id);$seq = mysql_insert_id ($conn_id); 重新编号现有序列 当你从表中删除了很多记录后，可能会想要对所有的记录重新定序。只要略施小计就能达到此目的，不过如果你的表与其他表之间存在连接的话，请千万小心。 当你觉得不得不对 AUTO_INCREMENT 列重新定序时，从表中删除该列，然后再将其添加回来，就可以达到目的了。下面的示例展示了如何使用这种方法，为 INSECT 表中的 ID 值重新定序： mysql ALTER TABLE INSECT DROP id;mysql ALTER TABLE insect - ADD id INT UNSIGNED NOT NULL AUTO_INCREMENT FIRST, - ADD PRIMARY KEY (id); 从特定值的序列 默认情况下，MySQL 中序列的起始值为 1，不过你可以在创建数据表的时候，指定任意其他值。下面的示例中，MySQL 将序列的起始值设为 100： mysql CREATE TABLE INSECT - ( - id INT UNSIGNED NOT NULL AUTO_INCREMENT = 100, - PRIMARY KEY (id), - name VARCHAR(30) NOT NULL, # type of insect - date DATE NOT NULL, # date collected - origin VARCHAR(30) NOT NULL # where collected); 或者，你也可以先创建数据表，然后使用 ALTER TABLE 来设置序列的起始值： mysql ALTER TABLE t AUTO_INCREMENT = 100;"},{"title":"SQL 各种数据库的数据类型","path":"/wiki/sql/sentence/summary.html","content":"SQL 各种数据库的数据类型 Microsoft Access、MySQL 和 SQL Server 所使用的数据类型和范围。 Microsoft Access 数据类型 数据类型 描述 存储 Text 用于文本或文本与数字的组合。最多 255 个字符。 Memo Memo 用于更大数量的文本。最多存储 65,536 个字符。**注释：**无法对 memo 字段进行排序。不过它们是可搜索的。 Byte 允许 0 到 255 的数字。 1 字节 Integer 允许介于 -32,768 与 32,767 之间的全部数字。 2 字节 Long 允许介于 -2,147,483,648 与 2,147,483,647 之间的全部数字。 4 字节 Single 单精度浮点。处理大多数小数。 4 字节 Double 双精度浮点。处理大多数小数。 8 字节 Currency 用于货币。支持 15 位的元，外加 4 位小数。**提示：**您可以选择使用哪个国家的货币。 8 字节 AutoNumber AutoNumber 字段自动为每条记录分配数字，通常从 1 开始。 4 字节 DateTime 用于日期和时间 8 字节 YesNo 逻辑字段，可以显示为 YesNo、TrueFalse 或 OnOff。在代码中，使用常量 True 和 False （等价于 1 和 0）。**注释：**YesNo 字段中不允许 Null 值 1 比特 Ole Object 可以存储图片、音频、视频或其他 BLOBs（Binary Large OBjects）。 最多 1GB Hyperlink 包含指向其他文件的链接，包括网页。 Lookup Wizard 允许您创建一个可从下拉列表中进行选择的选项列表。 4 字节 MySQL 数据类型 在 MySQL 中，有三种主要的类型：Text（文本）、Number（数字）和 DateTime（日期时间）类型。 **　Text 类型：** 数据类型 描述 CHAR(size) 保存固定长度的字符串（可包含字母、数字以及特殊字符）。在括号中指定字符串的长度。最多 255 个字符。 VARCHAR(size) 保存可变长度的字符串（可包含字母、数字以及特殊字符）。在括号中指定字符串的最大长度。最多 255 个字符。**注释：**如果值的长度大于 255，则被转换为 TEXT 类型。 TINYTEXT 存放最大长度为 255 个字符的字符串。 TEXT 存放最大长度为 65,535 个字符的字符串。 BLOB 用于 BLOBs（Binary Large OBjects）。存放最多 65,535 字节的数据。 MEDIUMTEXT 存放最大长度为 16,777,215 个字符的字符串。 MEDIUMBLOB 用于 BLOBs（Binary Large OBjects）。存放最多 16,777,215 字节的数据。 LONGTEXT 存放最大长度为 4,294,967,295 个字符的字符串。 LONGBLOB 用于 BLOBs (Binary Large OBjects)。存放最多 4,294,967,295 字节的数据。 ENUM(x,y,z,etc.) 允许您输入可能值的列表。可以在 ENUM 列表中列出最大 65535 个值。如果列表中不存在插入的值，则插入空值。 **注释：**这些值是按照您输入的顺序排序的。 可以按照此格式输入可能的值： ENUM(‘X’,’Y’,’Z’) SET 与 ENUM 类似，不同的是，SET 最多只能包含 64 个列表项且 SET 可存储一个以上的选择。 **　Number 类型：** 数据类型 描述 TINYINT(size) -128 到 127 常规。0 到 255 无符号*。在括号中规定最大位数。 SMALLINT(size) -32768 到 32767 常规。0 到 65535 无符号*。在括号中规定最大位数。 MEDIUMINT(size) -8388608 到 8388607 普通。0 to 16777215 无符号*。在括号中规定最大位数。 INT(size) -2147483648 到 2147483647 常规。0 到 4294967295 无符号*。在括号中规定最大位数。 BIGINT(size) -9223372036854775808 到 9223372036854775807 常规。0 到 18446744073709551615 无符号*。在括号中规定最大位数。 FLOAT(size,d) 带有浮动小数点的小数字。在 size 参数中规定最大位数。在 d 参数中规定小数点右侧的最大位数。 DOUBLE(size,d) 带有浮动小数点的大数字。在 size 参数中规定最大位数。在 d 参数中规定小数点右侧的最大位数。 DECIMAL(size,d) 作为字符串存储的 DOUBLE 类型，允许固定的小数点。在 size 参数中规定最大位数。在 d 参数中规定小数点右侧的最大位数。 **注意：**这些整数类型拥有额外的选项 UNSIGNED。通常，整数可以是负数或正数。如果添加 UNSIGNED 属性，那么范围将从 0 开始，而不是某个负数。 **　Date 类型：** 数据类型 描述 DATE() 日期。格式：YYYY-MM-DD **注释：**支持的范围是从 ‘1000-01-01’ 到 ‘9999-12-31’ DATETIME() *日期和时间的组合。格式：YYYY-MM-DD HH:MM:SS **注释：**支持的范围是从 ‘1000-01-01 00:00:00’ 到 ‘9999-12-31 23:59:59’ TIMESTAMP() *时间戳。TIMESTAMP 值使用 Unix 纪元(‘1970-01-01 00:00:00’ UTC) 至今的秒数来存储。格式：YYYY-MM-DD HH:MM:SS **注释：**支持的范围是从 ‘1970-01-01 00:00:01’ UTC 到 ‘2038-01-09 03:14:07’ UTC TIME() 时间。格式：HH:MM:SS **注释：**支持的范围是从 ‘-838:59:59’ 到 ‘838:59:59’ YEAR() 2 位或 4 位格式的年。 **注释：**4 位格式所允许的值：1901 到 2155。2 位格式所允许的值：70 到 69，表示从 1970 到 2069。 **注意：**即便 DATETIME 和 TIMESTAMP 返回相同的格式，它们的工作方式很不同。在 INSERT 或 UPDATE 查询中，TIMESTAMP 自动把自身设置为当前的日期和时间。TIMESTAMP 也接受不同的格式，比如 YYYYMMDDHHMMSS、YYMMDDHHMMSS、YYYYMMDD 或 YYMMDD。 SQL Server 数据类型 **　String 类型：** 数据类型 描述 存储 char(n) 固定长度的字符串。最多 8,000 个字符。 Defined width varchar(n) 可变长度的字符串。最多 8,000 个字符。 2 bytes + number of chars varchar(max) 可变长度的字符串。最多 1,073,741,824 个字符。 2 bytes + number of chars text 可变长度的字符串。最多 2GB 文本数据。 4 bytes + number of chars nchar 固定长度的 Unicode 字符串。最多 4,000 个字符。 Defined width x 2 nvarchar 可变长度的 Unicode 字符串。最多 4,000 个字符。 nvarchar(max) 可变长度的 Unicode 字符串。最多 536,870,912 个字符。 ntext 可变长度的 Unicode 字符串。最多 2GB 文本数据。 bit 允许 0、1 或 NULL binary(n) 固定长度的二进制字符串。最多 8,000 字节。 varbinary 可变长度的二进制字符串。最多 8,000 字节。 varbinary(max) 可变长度的二进制字符串。最多 2GB。 image 可变长度的二进制字符串。最多 2GB。 **　Number 类型：** 数据类型 描述 存储 tinyint 允许从 0 到 255 的所有数字。 1 字节 smallint 允许介于 -32,768 与 32,767 的所有数字。 2 字节 int 允许介于 -2,147,483,648 与 2,147,483,647 的所有数字。 4 字节 bigint 允许介于 -9,223,372,036,854,775,808 与 9,223,372,036,854,775,807 之间的所有数字。 8 字节 decimal(p,s) 固定精度和比例的数字。 允许从 -10^38 +1 到 10^38 -1 之间的数字。 p 参数指示可以存储的最大位数（小数点左侧和右侧）。p 必须是 1 到 38 之间的值。默认是 18。 s 参数指示小数点右侧存储的最大位数。s 必须是 0 到 p 之间的值。默认是 0。 5-17 字节 numeric(p,s) 固定精度和比例的数字。 允许从 -10^38 +1 到 10^38 -1 之间的数字。 p 参数指示可以存储的最大位数（小数点左侧和右侧）。p 必须是 1 到 38 之间的值。默认是 18。 s 参数指示小数点右侧存储的最大位数。s 必须是 0 到 p 之间的值。默认是 0。 5-17 字节 smallmoney 介于 -214,748.3648 与 214,748.3647 之间的货币数据。 4 字节 money 介于 -922,337,203,685,477.5808 与 922,337,203,685,477.5807 之间的货币数据。 8 字节 float(n) 从 -1.79E + 308 到 1.79E + 308 的浮动精度数字数据。 n 参数指示该字段保存 4 字节还是 8 字节。float(24) 保存 4 字节，而 float(53) 保存 8 字节。n 的默认值是 53。 4 或 8 字节 real 从 -3.40E + 38 到 3.40E + 38 的浮动精度数字数据。 4 字节 **　Date 类型：** 数据类型 描述 存储 datetime 从 1753 年 1 月 1 日 到 9999 年 12 月 31 日，精度为 3.33 毫秒。 8 字节 datetime2 从 1753 年 1 月 1 日 到 9999 年 12 月 31 日，精度为 100 纳秒。 6-8 字节 smalldatetime 从 1900 年 1 月 1 日 到 2079 年 6 月 6 日，精度为 1 分钟。 4 字节 date 仅存储日期。从 0001 年 1 月 1 日 到 9999 年 12 月 31 日。 3 bytes time 仅存储时间。精度为 100 纳秒。 3-5 字节 datetimeoffset 与 datetime2 相同，外加时区偏移。 8-10 字节 timestamp 存储唯一的数字，每当创建或修改某行时，该数字会更新。timestamp 值基于内部时钟，不对应真实时间。每个表只能有一个 timestamp 变量。 **　其他数据类型：** 数据类型 描述 sql_variant 存储最多 8,000 字节不同数据类型的数据，除了 text、ntext 以及 timestamp。 uniqueidentifier 存储全局唯一标识符 (GUID)。 xml 存储 XML 格式化数据。最多 2GB。 cursor 存储对用于数据库操作的指针的引用。 table 存储结果集，供稍后处理。"},{"title":"SQL 子查询","path":"/wiki/sql/sentence/subquery.html","content":"SQL 子查询 子查询（Sub Query）或者说内查询（Inner Query），也可以称作嵌套查询（Nested Query），是一种嵌套在其他 SQL 查询的 WHERE 子句中的查询。 子查询用于为主查询返回其所需数据，或者对检索数据进行进一步的限制。 子查询可以在 SELECT、INSERT、UPDATE 和 DELETE 语句中，同 、、、、、IN、BETWEEN 等运算符一起使用。 使用子查询必须遵循以下几个规则： 子查询必须括在圆括号中。 子查询的 SELECT 子句中只能有一个列，除非主查询中有多个列，用于与子查询选中的列相比较。 子查询不能使用 ORDER BY，不过主查询可以。在子查询中，GROUP BY 可以起到同 ORDER BY 相同的作用。 返回多行数据的子查询只能同多值操作符一起使用，比如 IN 操作符。 SELECT 列表中不能包含任何对 BLOB、ARRAY、CLOB 或者 NCLOB 类型值的引用。 子查询不能直接用在聚合函数中。 BETWEEN 操作符不能同子查询一起使用，但是 BETWEEN 操作符可以用在子查询中。 SELECT 语句中的子查询 通常情况下子查询都与 SELECT 语句一起使用，其基本语法如下所示： SELECT column_name [, column_name ]FROM table1 [, table2 ]WHERE column_name OPERATOR (SELECT column_name [, column_name ] FROM table1 [, table2 ] [WHERE]) 示例： 考虑 CUSTOMERS 表，表中记录如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 35 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 现在，让我们试一下在 SELECT 语句中进行子查询： SQL SELECT * FROM CUSTOMERS WHERE ID IN (SELECT ID FROM CUSTOMERS WHERE SALARY 4500) ; 上述语句的执行结果如下所示： +----+----------+-----+---------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+---------+----------+| 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+---------+----------+ INSERT 语句中的子查询： 子查询还可以用在 INSERT 语句中。INSERT 语句可以将子查询返回的数据插入到其他表中。子查询中选取的数据可以被任何字符、日期或者数值函数所修饰。 其基本语法如下所示： INSERT INTO table_name [ (column1 [, column2 ]) ] SELECT [ *|column1 [, column2 ] FROM table1 [, table2 ] [ WHERE VALUE OPERATOR ] 示例： 考虑与 CUSTOMERS 表拥有相似结构的 CUSTOMERS_BKP 表。现在要将 CUSTOMER 表中所有的数据复制到 CUSTOMERS_BKP 表中，代码如下： SQL INSERT INTO CUSTOMERS_BKP SELECT * FROM CUSTOMERS WHERE ID IN (SELECT ID FROM CUSTOMERS) ; UPDATE 语句中的子查询： 子查询可以用在 UPDATE 语句中。当子查询同 UPDATE 一起使用的时候，既可以更新单个列，也可更新多个列。 其基本语法如下： UPDATE tableSET column_name = new_value[ WHERE OPERATOR [ VALUE ] (SELECT COLUMN_NAME FROM TABLE_NAME) [ WHERE) ] 示例： 假设我们有一份 CUSTOMERS_BKP 表作为 CUSTOMERS 表的备份。 下面的示例将 CUSTOMERS 表中所有 AGE 大于或者等于 27 的客户的 SALARY 字段都变为了原来的 0.25 倍： SQL UPDATE CUSTOMERS SET SALARY = SALARY * 0.25 WHERE AGE IN (SELECT AGE FROM CUSTOMERS_BKP WHERE AGE = 27 ); 这将影响两行数据，随后 CUSTOMERS 表中的记录将如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 35 | Ahmedabad | 125.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 2125.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ DELETE 语句中的子查询： 如同前面提到的其他语句一样，子查询还可以同 DELETE 语句一起使用。 其基本语法如下所示： DELETE FROM TABLE_NAME[ WHERE OPERATOR [ VALUE ] (SELECT COLUMN_NAME FROM TABLE_NAME) [ WHERE) ] 示例： 假设我们有一份 CUSTOMERS_BKP 表作为 CUSTOMERS 表的备份。 下面的示例将从 CUSTOMERS 表中删除所有 AGE 大于或者等于 27 的记录： SQL DELETE FROM CUSTOMERS WHERE AGE IN (SELECT AGE FROM CUSTOMERS_BKP WHERE AGE 27 ); 这将影响两行数据，随后 CUSTOMERS 表中的记录将如下所示： +----+----------+-----+---------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+---------+----------+| 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+---------+----------+"},{"title":"SQL SELECT INTO语句","path":"/wiki/sql/sentence/selectinto.html","content":"SQL SELECT INTO 语句 使用 SQL，您可以将信息从一个表中复制到另一个表中。 SELECT INTO 语句从一个表中复制数据，然后将数据插入到另一个新表中。 SQL SELECT INTO 语法我们可以把所有的列都复制到新表中： SELECT *INTO newtable [IN externaldb]FROM table1; 或者只复制希望的列插入到新表中： SELECT column_name(s)INTO newtable [IN externaldb]FROM table1; **提示：**将使用SELECT语句中定义的列名和类型创建新表。您可以使用AS子句来应用一个新名称。 SQL SELECT INTO 实例 创建 Customers 的备份复件： SELECT *INTO CustomersBackup2013FROM Customers; 请使用 IN 子句来复制表到另一个数据库中： SELECT *INTO CustomersBackup2013 IN Backup.mdbFROM Customers; 只复制一些列插入到新表中： SELECT CustomerName,ContactNameINTO CustomersBackup2013FROM Customers; 只复制德国的客户插入到新表中： SELECT *INTO CustomersBackup2013FROM CustomersWHERE Country=Germany; 复制多个表中的数据插入到新表中： SELECT Customers.CustomerName, Orders.OrderIDINTO CustomersOrderBackup2013FROM CustomersLEFT JOIN OrdersON Customers.CustomerID=Orders.CustomerID; **　提示：**SELECT INTO 语句可以用于在另一种模式下创建一个新的空表。只需添加WHERE子句，使查询返回时没有数据： SELECT *INTO newtableFROM table1WHERE 1=0;"},{"title":"SQL TRUNCATE TABLE 命令","path":"/wiki/sql/sentence/truncate.html","content":"SQL TRUNCATE TABLE 命令 SQL TRUNCATE TABLE 命令用于删除现有数据表中的所有数据。 你也可以使用 DROP TABLE 命令来删除整个数据表，不过 DROP TABLE 命令不但会删除表中所有数据，还会将整个表结构从数据库中移除。如果想要重新向表中存储数据的话，必须重建该数据表。 语法 **　TRUNCATE TABLE** 的基本语法如下所示： TRUNCATE TABLE table_name; 示例： 考虑 CUSTOMERS 表，表中的记录如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 下面的示例展示了 TRUNCATE 命令的用法： TRUNCATE TABLE CUSTOMERS; 现在，CUSTOMERS 表已经被清空了，SELECT 语句的输出应当如下所示： SQL SELECT * FROM CUSTOMERS;Empty set (0.00 sec)"},{"title":"SQL UNION运算符","path":"/wiki/sql/sentence/union.html","content":"SQL UNION 运算符 UNION运算符用于组合两个或更多SELECT语句的结果集，而不返回任何重复的行。 UNION中的每个SELECT语句必须具有相同的列数 这些列也必须具有相似的数据类型 每个SELECT语句中的列也必须以相同的顺序排列 每个SELECT语句必须有相同数目的列表达式 但是每个SELECT语句的长度不必相同 SQL UNION 语法1SELECT column_name(s) FROM table1UNIONSELECT column_name(s) FROM table2; **注释：**默认情况下，UNION 运算符选择一个不同的值。如果允许重复值，请使用 UNION ALL。 SQL UNION 语法2SELECT column_name(s) FROM table1[WHERE condition]UNIONSELECT column_name(s) FROM table2[WHERE condition]; 给定的条件可以是基于您的需求的任何给定表达式。 SQL UNION ALL 语法1UNION All运算符用于组合两个SELECT语句(包括重复行)的结果。 适用于UNION子句的相同规则将适用于UNION All操作符。 SELECT column_name(s) FROM table1UNION ALLSELECT column_name(s) FROM table2; **注释：**UNION结果集中的列名总是等于UNION中第一个SELECT语句中的列名。 SQL UNION ALL 语法2SELECT column_name(s) FROM table1[WHERE condition]UNION ALLSELECT column_name(s) FROM table2[WHERE condition]; 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是”Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 选自 “Suppliers” 表的数据： SupplierID SupplierName ContactName Address City PostalCode Country 1 Exotic Liquid Charlotte Cooper 49 Gilbert St. Londona EC1 4SD UK 2 New Orleans Cajun Delights Shelley Burke P.O. Box 78934 New Orleans 70117 USA 3 Grandma Kelly’s Homestead Regina Murphy 707 Oxford Rd. Ann Arbor 48104 USA SQL UNION 实例下面的 SQL 语句从 “Customers” 和 “Suppliers” 表中选取所有不同的城市（只有不同的值）： 示例： SELECT City FROM CustomersUNIONSELECT City FROM SuppliersORDER BY City; **注释：**不能用 UNION 来列出两个表中的所有城市。如果一些客户和供应商来自同一个城市，每个城市将只被列入一个列表。UNION将只选择不同的值。请使用UNION ALL选择重复值! SQL UNION ALL 实例 以下SQL语句使用 UNION ALL 从 “Customers”和”Suppliers” 表中选择所有城市（也是重复的值）： 示例： SELECT City FROM CustomersUNION ALLSELECT City FROM SuppliersORDER BY City; 带有 WHERE 的 SQL UNION ALL 以下SQL语句使用UNIONALL从”Customers”和 “Suppliers” 表中选择所有德国城市（也是重复数值）： 示例： SELECT City, Country FROM CustomersWHERE Country=GermanyUNION ALLSELECT City, Country FROM SuppliersWHERE Country=GermanyORDER BY City; SQL UNION与WHERE 以下SQL语句从”客户”和”供应商”中选择所有不同的德国城市（只有不同的值）： SELECT City, Country FROM CustomersWHERE Country=GermanyUNIONSELECT City, Country FROM SuppliersWHERE Country=GermanyORDER BY City; 另一个UNION示例 以下SQL语句列出了所有客户和供应商： SELECT Customer As Type, ContactName, City, CountryFROM CustomersUNIONSELECT Supplier, ContactName, City, CountryFROM Suppliers; 还有另外两个子句(即运算符)，它们类似于UNION子句： SQL INTERSECT子句用于组合两个SELECT语句，但只返回与第二个SELECT语句中的一行相同的第一个SELECT语句中的行。 SQL EXCEPT子句用于组合两个SELECT语句，并返回第一个SELECT语句中没有由第二个SELECT语句返回的行。"},{"title":"SQL UNION子句","path":"/wiki/sql/sentence/unionziju.html","content":"SQL UNION 子句 SQL UNION 子句运算符用于将两个或者更多的 SELECT 语句的运算结果组合起来。 在使用 UNION 的时候，每个 SELECT 语句必须有相同数量的选中列、相同数量的列表达式、相同的数据类型，并且它们出现的次序要一致，不过长度不一定要相同。 语法**　UNION** 子句的基本语法如下所示： SELECT column1 [, column2 ]FROM table1 [, table2 ][WHERE condition]UNIONSELECT column1 [, column2 ]FROM table1 [, table2 ][WHERE condition] 这里的条件可以是任何根据你的需要而设的条件。 示例 考虑如下两张表，（a）CUSTOMERS 表： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ （b）另一张表是 ORDERS 表，如下所示： +-----+---------------------+-------------+--------+|OID | DATE | CUSTOMER_ID | AMOUNT | +-----+---------------------+-------------+--------+ | 102 | 2009-10-08 00:00:00 | 3 | 3000 || 100 | 2009-10-08 00:00:00 | 3 | 1500 | | 101 | 2009-11-20 00:00:00 | 2 | 1560 || 103 | 2008-05-20 00:00:00 | 4 | 2060 | +-----+---------------------+-------------+--------+ 现在，让我们用 SELECT 语句将这两张表连接起来： SQL SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS LEFT JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_IDUNION SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS RIGHT JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_ID; 结果如下所示： +------+----------+--------+---------------------+| ID | NAME | AMOUNT | DATE | +------+----------+--------+---------------------+ | 1 | Ramesh | NULL | NULL || 2 | Khilan | 1560 | 2009-11-20 00:00:00 | | 3 | kaushik | 3000 | 2009-10-08 00:00:00 || 3 | kaushik | 1500 | 2009-10-08 00:00:00 | | 4 | Chaitali | 2060 | 2008-05-20 00:00:00 || 5 | Hardik | NULL | NULL | | 6 | Komal | NULL | NULL || 7 | Muffy | NULL | NULL | +------+----------+--------+---------------------+ UNION ALL 子句： UNION ALL 运算符用于将两个 SELECT 语句的结果组合在一起，重复行也包含在内。 UNION ALL 运算符所遵从的规则与 UNION 一致。 语法：**　UNION ALL**的基本语法如下： SELECT column1 [, column2 ]FROM table1 [, table2 ][WHERE condition]UNION ALLSELECT column1 [, column2 ]FROM table1 [, table2 ][WHERE condition] 示例：考虑如下两张表，（a）CUSTOMERS 表： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ （b）另一张表是 ORDERS 表，如下所示： +-----+---------------------+-------------+--------+|OID | DATE | CUSTOMER_ID | AMOUNT | +-----+---------------------+-------------+--------+ | 102 | 2009-10-08 00:00:00 | 3 | 3000 || 100 | 2009-10-08 00:00:00 | 3 | 1500 | | 101 | 2009-11-20 00:00:00 | 2 | 1560 || 103 | 2008-05-20 00:00:00 | 4 | 2060 | +-----+---------------------+-------------+--------+ 现在，让我们用 SELECT 语句将这两张表连接起来： SQL SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS LEFT JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_IDUNION ALL SELECT ID, NAME, AMOUNT, DATE FROM CUSTOMERS RIGHT JOIN ORDERS ON CUSTOMERS.ID = ORDERS.CUSTOMER_ID; 结果如下所示： +------+----------+--------+---------------------+| ID | NAME | AMOUNT | DATE | +------+----------+--------+---------------------+ | 1 | Ramesh | NULL | NULL || 2 | Khilan | 1560 | 2009-11-20 00:00:00 | | 3 | kaushik | 3000 | 2009-10-08 00:00:00 || 3 | kaushik | 1500 | 2009-10-08 00:00:00 | | 4 | Chaitali | 2060 | 2008-05-20 00:00:00 || 5 | Hardik | NULL | NULL | | 6 | Komal | NULL | NULL || 7 | Muffy | NULL | NULL | | 3 | kaushik | 3000 | 2009-10-08 00:00:00 || 3 | kaushik | 1500 | 2009-10-08 00:00:00 | | 2 | Khilan | 1560 | 2009-11-20 00:00:00 || 4 | Chaitali | 2060 | 2008-05-20 00:00:00 | +------+----------+--------+---------------------+ 另外，还有两个子句（亦即运算法）与 UNION 子句非常相像： SQL INTERSECT 子句：用于组合两个 SELECT 语句，但是只返回两个 SELECT 语句的结果中都有的行。 SQL EXCEPT 子句：组合两个 SELECT 语句，并将第一个 SELECT 语句的结果中存在，但是第二个 SELECT 语句的结果中不存在的行返回。"},{"title":"SQL 临时表","path":"/wiki/sql/sentence/temp.html","content":"SQL 临时表 某些关系型数据库管理系统支持临时表。临时表是一项很棒的特性，能够让你像操作普通的 SQL 数据表一样，使用 SELECT、UPDATE 和 JOIN 等功能来存储或者操作中间结果。 临时表有时候对于保存临时数据非常有用。有关临时表你需要知道的最重要的一点是，它们会在当前的终端会话结束后被删除。 临时表自 MySQL 3.23 起受到支持。如果你的 MySQL 版本比 3.23 还老，那么你就不能使用临时表了，不过你可以使用堆表（heap table）。 如先前所言，临时表只在会话期间存在。如果你在 PHP 脚本中操作数据库，那么临时表将在脚本执行完毕时被自动销毁。如果你是通过 MySQL 的客户端程序连接到 MySQL 数据库服务器的，那么临时表将会存在到你关闭客户端或者手动将其删除。 示例 下面的示例向你展示了如何使用临时表： mysql CREATE TEMPORARY TABLE SALESSUMMARY ( - product_name VARCHAR(50) NOT NULL - , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00 - , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00 - , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0);Query OK, 0 rows affected (0.00 sec)mysql INSERT INTO SALESSUMMARY - (product_name, total_sales, avg_unit_price, total_units_sold) - VALUES - (cucumber, 100.25, 90, 2);mysql SELECT * FROM SALESSUMMARY;+--------------+-------------+----------------+------------------+| product_name | total_sales | avg_unit_price | total_units_sold |+--------------+-------------+----------------+------------------+| cucumber | 100.25 | 90.00 | 2 |+--------------+-------------+----------------+------------------+1 row in set (0.00 sec) 当你下达 SHOW TABLES 命令的时候，临时表是不会出现在结果列表当中的。现在，如果你退出 MySQL 会话，然后再执行 SELECT 命令的话，你将不能从数据库中取回任何数据，你的临时表也已经不复存在了。 删除临时表 默认情况下，所有的临时表都由 MySQL 在数据库连接关闭时删除。不过，有时候你还是会想要在会话期间将其删除，此时你需要使用 DROP TABLE 命令来达到目的。 下面是删除临时表的示例： mysql CREATE TEMPORARY TABLE SALESSUMMARY ( - product_name VARCHAR(50) NOT NULL - , total_sales DECIMAL(12,2) NOT NULL DEFAULT 0.00 - , avg_unit_price DECIMAL(7,2) NOT NULL DEFAULT 0.00 - , total_units_sold INT UNSIGNED NOT NULL DEFAULT 0);Query OK, 0 rows affected (0.00 sec)mysql INSERT INTO SALESSUMMARY - (product_name, total_sales, avg_unit_price, total_units_sold) - VALUES - (cucumber, 100.25, 90, 2);mysql SELECT * FROM SALESSUMMARY;+--------------+-------------+----------------+------------------+| product_name | total_sales | avg_unit_price | total_units_sold |+--------------+-------------+----------------+------------------+| cucumber | 100.25 | 90.00 | 2 |+--------------+-------------+----------------+------------------+1 row in set (0.00 sec)mysql DROP TABLE SALESSUMMARY;mysql SELECT * FROM SALESSUMMARY;ERROR 1146: Table TUTORIALS.SALESSUMMARY doesnt exist"},{"title":"SQL 更新","path":"/wiki/sql/sentence/update.html","content":"SQL UPDATE 语句 UPDATE 语句用于更新表中已存在的记录。 还可以使用AND或OR运算符组合多个条件。 SQL UPDATE 语法具有WHERE子句的UPDATE查询的基本语法如下所示： UPDATE table_nameSET column1 = value1, column2 = value2, ...WHERE condition; 请注意 更新表中的记录时要小心！ 要注意SQL UPDATE 语句中的 WHERE 子句！ WHERE子句指定哪些记录需要更新。如果省略WHERE子句，所有记录都将更新！ 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。 以下是 “Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL UPDATE 实例 以下SQL语句为第一个客户（CustomerID 1）更新了”ContactName”和”City”： 示例： UPDATE CustomersSET ContactName = Alfred Schmidt, City= FrankfurtWHERE CustomerID = 1; 现在，选自 “Customers” 表的数据如下所示： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Alfred Schmidt Obere Str. 57 Frankfurt 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden 更新多个记录 WHERE子句决定了将要更新的记录数量。 以下SQL语句将把国家地区为”Mexico”的所有记录的联系人姓名更新为”Juan”： UPDATE CustomersSET ContactName=JuanWHERE Country=Mexico; “Customers”表中的选择现在看起来像这样： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Alfred Schmidt Obere Str. 57 Frankfurt 12209 Germany 2 Ana Trujillo Emparedados y helados Juan Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Juan Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden Update 警告！ 更新记录时要小心。如果您省略WHERE子句，所有记录将被更新！ UPDATE CustomersSET ContactName=Juan; “Customers” 表将如下所示： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Juan Obere Str. 57 Frankfurt 12209 Germany 2 Ana Trujillo Emparedados y helados Juan Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Juan Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Juan 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Juan Berguvsvägen 8 Luleå S-958 22"},{"title":"SQL USE语句","path":"/wiki/sql/sentence/use.html","content":"SQL 选择数据库 USE语句 当SQL Schema中有多个数据库时，在开始操作之前，需要选择一个执行所有操作的数据库。 SQL USE语句用于选择SQL架构中的任何现有数据库。 句法USE语句的基本语法如下所示 : USE DatabaseName; 数据库名称在RDBMS中必须是唯一的。 实例 您可以查看可用的数据库，如下所示： SQL SHOW DATABASES;+--------------------+| Database |+--------------------+| information_schema || AMROOD || TUTORIALSPOINT || mysql || orig || test |+--------------------+6 rows in set (0.00 sec) 现在，如果您想使用AMROOD数据库，那么您可以执行以下SQL命令并开始使用AMROOD数据库。 SQL USE AMROOD;"},{"title":"SQL 使用视图","path":"/wiki/sql/sentence/useview.html","content":"SQL 使用视图 视图无非就是存储在数据库中并具有名字的 SQL 语句，或者说是以预定义的 SQL 查询的形式存在的数据表的成分。 视图可以包含表中的所有列，或者仅包含选定的列。视图可以创建自一个或者多个表，这取决于创建该视图的 SQL 语句的写法。 视图，一种虚拟的表，允许用户执行以下操作： 以用户或者某些类型的用户感觉自然或者直观的方式来组织数据； 限制对数据的访问，从而使得用户仅能够看到或者修改（某些情况下）他们需要的数据； 从多个表中汇总数据，以产生报表。 创建视图 在 SQL 中，视图是基于 SQL 语句的结果集的可视化表。 数据库视图由 CREATE VIEW 语句创建。视图可以创建自单个表、多个表或者其他视图。 视图中的字段是一个或多个数据库中真实表中的字段。 在使用时视图可以被视为一个”虚拟表”。 要创建视图的话，用户必须有适当的系统权限。具体需要何种权限随数据库系统实现的不同而不同。 CREATE VIEW 语句的基本语法如下所示： CREATE VIEW view_name ASSELECT column1, column2.....FROM table_nameWHERE [condition]; 和普通的 SQL SELECT 查询一样，你可以在上面的 SELECT 语句中包含多个数据表。 注释：视图总是显示最新数据！每当用户查询视图时，数据库引擎就使用视图的 SQL 语句重新构建数据。 SQL CREATE VIEW 示例 示例一考虑 CUSTOMERS 表，表中的记录如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 下面是由 CUSTOMERS 表创建视图的例子。该视图包含来自 CUSTOMERS 表的顾客的名字（name）和年龄（age）： SQL CREATE VIEW CUSTOMERS_VIEW ASSELECT name, ageFROM CUSTOMERS; 现在，你就可以像查询普通的数据表一样查询 CUSTOMERS_VIEW 了： SQL SELECT * FROM CUSTOMERS_VIEW; 上述语句将会产生如下运行结果： +----------+-----+| name | age |+----------+-----+| Ramesh | 32 || Khilan | 25 || kaushik | 23 || Chaitali | 25 || Hardik | 27 || Komal | 22 || Muffy | 24 |+----------+-----+ 示例２下面是由 CUSTOMERS 表创建视图的例子。该视图包含来自 CUSTOMERS 表中年龄（age）为25的顾客的ADDRESS信息： SQL CREATE VIEW CUSTOMERS_ADDRESS ASSELECT ADDRESSFROM CUSTOMERS;WHERE AGE=25; 我们可以像这样查询上面这个 CUSTOMERS_ADDRESS 视图： SQL SELECT * FROM CUSTOMERS_ADDRESS; 我们也可以向查询添加条件。现在，我们仅仅需要查看 “Delhi” 的数据： SELECT * FROM CUSTOMERS_ADDRESSWHERE ADDRESS=Delhi; WITH CHECK OPTION WITH CHECK OPTION 是 CREATE VIEW 语句的一个可选项。 WITH CHECK OPTION 用于保证所有的 UPDATE 和 INSERT 语句都满足视图定义中的条件。 如果不能满足这些条件，UPDATE 或 INSERT 就会返回错误。 下面的例子创建的也是 CUSTOMERS_VIEW 视图，不过这次 WITH CHECK OPTION 是打开的： CREATE VIEW CUSTOMERS_VIEW ASSELECT name, ageFROM CUSTOMERSWHERE age IS NOT NULLWITH CHECK OPTION; 这里 WITH CHECK OPTION 使得视图拒绝任何 AGE 字段为 NULL 的条目，因为视图的定义中，AGE 字段不能为空。 更新视图 在SQL视图上也可以使用修改数据的DML语句，如 INSERT、UPDATE和DELETE。 视图可以在特定的情况下更新： SELECT 子句不能包含 DISTINCT 关键字 SELECT 子句不能包含任何汇总函数（summary functions） SELECT 子句不能包含任何集合函数（set functions） SELECT 子句不能包含任何集合运算符（set operators） SELECT 子句不能包含 ORDER BY 子句 视图不能包含连接操作符 视图不能包含伪列或表达式 FROM 子句中不能有多个数据表 WHERE 子句不能包含子查询（subquery） 查询语句中不能有 GROUP BY 或者 HAVING 计算得出的列不能更新 视图必须包含原始数据表中所有的 NOT NULL 列，从而使 INSERT 查询生效。 如果视图满足以上所有的条件，该视图就可以被更新。下面的例子中，Ramesh 的年龄被更新了： SQL UPDATE CUSTOMERS_VIEW SET AGE = 35 WHERE name=Ramesh; 最终更新的还是原始数据表，只是其结果反应在了视图上。现在查询原始数据表，SELECT 语句将会产生以下结果： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 35 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 向视图中插入新行 可以向视图中插入新行，其规则同（使用 UPDATE 命令）更新视图所遵循的规则相同。 这里我们不能向 CUSTOMERS_VIEW 视图中添加新行，因为该视图没有包含原始数据表中所有 NOT NULL 的列。否则的话，你就可以像在数据表中插入新行一样，向视图中插入新行。 句法： INSERT INTO view_nameVALUES (value1, value2, value3, ...); 删除视图中的行 视图中的数据行可以被删除。删除数据行与更新视图和向视图中插入新行遵循相同的规则。 下面的例子将删除 CUSTOMERS_VIEW 视图中 AGE22 的数据行： SQL DELETE FROM CUSTOMERS_VIEW WHERE age = 22; 该语句最终会将原始数据表中对应的数据行删除，只不过其结果反应在了视图上。现在查询原始数据表，SELECT 语句将会产生以下结果： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 35 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 删除视图 很明显，当我们不再需要某个视图的时候，需要有一种方式可以让我们将其删除。删除视图的语法非常简单，如下所示： DROP VIEW view_name; 下面的例子展示了如何从 CUSTOMERS 表中删除 CUSTOMERS_VIEW 视图： DROP VIEW CUSTOMERS_VIEW;"},{"title":"SQL NULL值处理","path":"/wiki/sql/sentence/valuenull.html","content":"SQL NULL 值 NULL 空值代表丢失的未知数据。 默认情况下，表列可以保存 NULL 值。 本章解释 IS NULL 和 IS NOT NULL 操作符。 SQL NULL 值 如果表中的列是可选的，那么我们可以插入一个新记录或更新一个现有记录，而无需向列添加一个值。这意味着该字段将存储为 NULL 。 NULL 值的处理与其他值不同。 NULL 为未知或不适当值的占位符。 **注释：**无法比较 NULL 和 0；它们是不等价的。 SQL 的 NULL 值处理 请看下面的 “Persons” 表： P_Id LastName FirstName Address City 1 Hansen Ola Sandnes 2 Svendson Tove Borgvn 23 Sandnes 3 Pettersen Kari Stavanger 如果 “Persons” 表 “Address” 一栏是可选的。这意味着，如果在 “Address” 列中插入一个没有值的记录，则 “Address” 列将用 NULL 值保存。 那么如何测试null的值呢？ 您不能使用比较操作符测试 NULL 值，例如、或。 我们必须使用 IS NULL 和 IS NOT NULL 操作符。 SQL IS NULL 我们如何才能选择 “Address” 列中有 NULL 值的记录？ 我们必须使用 IS NULL 操作符： SELECT LastName,FirstName,Address FROM PersonsWHERE Address IS NULL 结果集如下所示： LastName FirstName Address Hansen Ola Pettersen Kari **提示：**总是使用 IS NULL 来查找 NULL 值。 SQL IS NOT NULL 我们如何才能选择 “Address” 列中没有 NULL 值的记录？ 我们必须使用 IS NOT NULL 操作符： SELECT LastName,FirstName,Address FROM PersonsWHERE Address IS NOT NULL 结果集如下所示： LastName FirstName Address Svendson Tove Borgvn 23 在下一节中，我们将了解 ISNULL()、NVL()、IFNULL() 和 COALESCE() 函数。"},{"title":"SQL VIEW语句","path":"/wiki/sql/sentence/view.html","content":"SQL 视图（Views） 视图是可视化的表。 本章讲解如何创建、更新和删除视图。 SQL CREATE VIEW 语句 在 SQL 中，视图是基于 SQL 语句的结果集的可视化表。 视图包含行和列，就像真正的表一样。视图中的字段是一个或多个数据库中真实表中的字段。 您可以添加 SQL 函数，在哪里添加，并将语句连接到视图，或者您可以呈现数据，就像数据来自单个表一样。 SQL CREATE VIEW 语法CREATE VIEW view_name AS SELECT column_name(s) FROM table_name WHERE condition **　注释：**视图总是显示最新数据！每当用户查询视图时，数据库引擎就使用视图的 SQL 语句重新构建数据。 SQL CREATE VIEW 实例 示例数据库 Northwind 默认安装了一些视图。 “Current Product List”(当前产品列表)视图从”Products”表中列出了所有正在使用的产品（未停产的产品）。这个视图使用下面的 SQL 创建： CREATE VIEW [Current Product List] AS SELECT ProductID,ProductName FROM Products WHERE Discontinued=No 我们可以像这样查询上面这个视图： SELECT * FROM [Current Product List] Northwind 样本数据库的另一个视图会选取 “Products” 表中所有单位价格高于平均单位价格的产品： CREATE VIEW [Products Above Average Price] AS SELECT ProductName,UnitPrice FROM Products WHERE UnitPrice(SELECT AVG(UnitPrice) FROM Products) 我们可以像这样查询上面这个视图： SELECT * FROM [Products Above Average Price] Northwind 样本数据库的另一个视图会计算在 1997 年每个种类的销售总数。请注意，这个视图会从另一个名为 “Product Sales for 1997” 的视图那里选取数据： CREATE VIEW [Category Sales For 1997] AS SELECT DISTINCT CategoryName,Sum(ProductSales) AS CategorySales FROM [Product Sales for 1997] GROUP BY CategoryName 我们可以像这样查询上面这个视图： SELECT * FROM [Category Sales For 1997] 我们也可以向查询添加条件。现在，我们仅仅需要查看 “Beverages” 类的销售总数： SELECT * FROM [Category Sales For 1997] WHERE CategoryName=Beverages SQL 更新视图 您可以使用下面的语法来更新视图： SQL CREATE OR REPLACE VIEW 语法CREATE OR REPLACE VIEW view_name AS SELECT column_name(s) FROM table_name WHERE condition 现在，我们希望向 “Current Product List” 视图添加 “Category” 列。我们将通过下列 SQL 更新视图： CREATE OR REPLACE VIEW [Current Product List] AS SELECT ProductID,ProductName,Category FROM Products WHERE Discontinued=No SQL 撤销视图 您可以通过 DROP VIEW 命令来删除视图。 SQL DROP VIEW 语法DROP VIEW view_name"},{"title":"SQL 通配符","path":"/wiki/sql/sentence/wild.html","content":"SQL 通配符 我们已经讨论过 SQL 的 LIKE 操作符了，它可以利用通配符来对两个相似的值作比较。 SQL 支持以下两个通配符与 LIKE 操作符一起使用： |——–|————————————————————-| | 通配符 | 描述 | | 百分号（%） | 匹配一个或者多个字符。注意：MS Access 使用星号（*）作为匹配一个或者多个字符的通配符，而不是百分号（%）。 | | 下划线（_） | 匹配一个字符。注意：MS Access 使用问号（?），而不是下划线，来匹配任一字符。 | 百分号代表零个、一个或者多个字符。下划线代表单一的字符。这些符号可以组合在一起使用。 语法“%” 和 “_” 的基本语法如下所示： SELECT FROM table_nameWHERE column LIKE XXXX%or SELECT FROM table_nameWHERE column LIKE %XXXX%orSELECT FROM table_nameWHERE column LIKE XXXX_orSELECT FROM table_nameWHERE column LIKE _XXXXorSELECT FROM table_nameWHERE column LIKE _XXXX_ 你可以用 AND 或 OR 操作符将多个条件合并在一起。这里，XXXX 可以为任何数值或者字符串。 示例 |—————————|————————–| | 语句 | 描述 | | WHERE SALARY LIKE ‘200%’ | 找出任何以 200 开头的值。 | | WHERE SALARY LIKE ‘%200%’ | 找出任何存在 200 的值。 | | WHERE SALARY LIKE ‘00%’ | 找出任何第二个位置和第三个位置为 0 的值。 | | WHERE SALARY LIKE ‘2%_%’ | 找出任何以 2 开始，并且长度至少为 3 的值。 | | WHERE SALARY LIKE ‘%2’ | 找出任何以 2 结尾的值。 | | WHERE SALARY LIKE ‘_2%3’ | 找出任何第二个位置为 2，并且以 3 结束的值。 | | WHERE SALARY LIKE ‘2___3’ | 找出任何以 2 开始，以 3 结束的五位数。 | 让我们来看一个真实的例子，考虑拥有如下记录的 CUSTOMERS 表： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 下面的示例将会找到 CUSTOMER 表中所有 SALARY 以 200 开头的记录，并显示出来： SQL SELECT * FROM CUSTOMERSWHERE SALARY LIKE 200%; 结果如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 3 | kaushik | 23 | Kota | 2000.00 |+----+----------+-----+-----------+----------+"},{"title":"SQL Wildcards通配符","path":"/wiki/sql/sentence/wildcards.html","content":"SQL Wildcards 通配符 通配符用于替换字符串中的任何其他字符。 通配符与 运算符一起使用。在 WHERE 子句中使用LIKE运算符来搜索列中的指定模式。 有两个通配符与 LIKE 运算符一起使用： ％ - 百分号表示零个，一个或多个字符 _ - 下划线表示单个字符 **　注意：** MS Access 使用星号(*）通配符而不是百分比符号(%)通配符。 MS Access 使用问号（?）而不是下划线（_）。 在MS Access和SQL Server中，你也可以使用： [ charlist ] - 定义要匹配的字符的集合和范围 [^ charlist ]或[！charlist ] - 定义不匹配字符的集合和范围 通配符也可以组合使用！ 下面是一些使用’％‘和’_‘通配符显示不同LIKE运算符的例子： LIKE运算符 描述 WHERE CustomerName LIKE ‘a%’ 查找以”a”开头的任何值 WHERE CustomerName LIKE ‘%a’ 查找以”a”结尾的任何值 WHERE CustomerName LIKE ‘%or%’ 在任何位置查找任何具有”or”的值 WHERE CustomerName LIKE ‘_r%’ 在第二个位置查找任何具有”r”的值 WHERE CustomerName LIKE ‘a_%_%’ 查找以”a”开头并且长度至少为3个字符的值 WHERE ContactName LIKE ‘a%o’ 查找以”a”开始并以”o”结尾的任何值 演示数据库 在本教程中，我们将使用著名的 Northwind 示例数据库。 以下是 “Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden 使用 SQL % 通配符 以下 SQL 语句选择所有客户 City 以字母”ber”开头： 示例： SELECT * FROM CustomersWHERE City LIKE ber%; 以下 SQL 语句选择 City 中包含”es”模式的所有客户： 示例： SELECT * FROM CustomersWHERE City LIKE %es%; 使用 SQL _ 通配符 以下 SQL 语句选择 City 以任意字符开头，然后是”erlin”的所有客户： 示例： SELECT * FROM CustomersWHERE City LIKE _erlin; 以下 SQL 语句选择 City 开头为”L”，后面是任意字符，后面是”n”，后面是任意字符，加”on”的所有客户： 示例： SELECT * FROM CustomersWHERE City LIKE L_n_on; 使用 SQL [charlist] 通配符 以下 SQL 语句选择所有客户 City 以”b”、”s”或”p”开头： 示例： SELECT * FROM CustomersWHERE City LIKE [bsp]%; 以下 SQL 语句选择”City”以”a”、”b”或”c”开头的所有客户： 示例： SELECT * FROM CustomersWHERE City LIKE [a-c]%; 以下 SQL 语句选择所有客户 City 不以”b”、”s”或”p”开头： 示例： SELECT * FROM CustomersWHERE City LIKE [!bsp]%; 使用[！charlist]通配符 以下两个 SQL 语句选择所有客户的城市不以”b”，”s”或”p”开头： 代码示例： SELECT * FROM CustomersWHERE City LIKE [!bsp]%; 要么： 代码示例： SELECT * FROM CustomersWHERE City NOT LIKE [bsp]%;"},{"title":"SQL 语法","path":"/wiki/sql/sentence/yufa.html","content":"SQL 语法规则 SQL语句总是以关键字开始，如SELECT、INSERT、UPDATE、DELETE、DROP、CREATE。 SQL语句以分号结尾。 SQL不区分大小写，意味着update与UPDATE相同。 数据库表 数据库通常包含一个或多个表。每个表都用一个名称标识（例如，”Customers”或”Orders”）。该表包含带有数据（行）的记录。　在本教程中，我们将使用著名的Northwind示例数据库（包括MSAccess和MSSQLServer）。 下面是选自 “Customers” 表的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden 上面的表包含五条记录（每一条对应一个客户）和七个列（CustomerID、CustomerName、ContactName、Address、City、PostalCode 和 Country）。 SQL 语句 您需要在数据库上执行的大部分操作都是使用SQL语句完成的。 以下SQL语句选择”Customers”表中的所有记录： 实例SELECT * FROM Customers; 在本教程中，我们将向您解释各种不同的SQL语句。 请记住… SQL 对大小写不敏感：SELECT 与 select 是相同的。 在本教程中，我们将以大写形式编写所有SQL关键字。 SQL 语句后面的分号？ 一些数据库系统需要在每个SQL语句的末尾使用分号。 分号是分离数据库系统中每个SQL语句的标准方法，这样您就可以在对服务器的同一请求中执行多个SQL语句。 在本教程中，我们将在每个SQL语句的末尾使用分号。 一些最重要的 SQL 命令 SELECT - 从数据库中提取数据 UPDATE - 更新数据库中的数据 DELETE - 从数据库中删除数据 INSERT INTO - 向数据库中插入新数据 CREATE DATABASE - 创建新数据库 ALTER DATABASE - 修改数据库 CREATE TABLE - 创建新表 ALTER TABLE - 变更（改变）数据库表 DROP TABLE - 删除表 CREATE INDEX - 创建索引（搜索键） DROP INDEX - 删除索引 SELECT语句句法： SELECT column_name(s) FROM table_name SELECT语句和WHERE子句句法： SELECT [*] FROM [TableName] WHERE [condition1] SELECT语句与WHERE和或子句[句法： SELECT [*] FROM [TableName] WHERE [condition1] [AND [OR]] [condition2]... SELECT语句与ORDER BY句法： SELECT column_name()FROM table_nameORDER BY column_name() ASC or DESC SELECT DISTINCT(区分)子句句法： SELECT DISTINCT column1, column2....columnNFROM table_name; SELECT IN子句句法： SELECT column1, column2....columnNFROM table_nameWHERE column_name IN (val-1, val-2,...val-N); SELECT LIKE (类)子句句法： SELECT column1, column2....columnNFROM table_nameWHERE column_name LIKE PATTERN ; SELECT COUNT(计数)子句句法： SELECT COUNT(column_name)FROM table_nameWHERE CONDITION; SELECT与HAVING子句句法： SELECT SUM(column_name)FROM table_nameWHERE CONDITIONGROUP BY column_nameHAVING (arithematic function condition); INSERT INTO语句句法： INSERT INTO table_name (column, column1, column2, column3, ...)VALUES (value, value1, value2, value3 ...) UPDATE语句句法： UPDATE table_nameSET column=value, column1=value1,...WHERE someColumn=someValue DELETE语句句法： DELETE FROM tableNameWHERE someColumn = someValue CREATE 语句句法： CREATE TABLE table_name(column1 datatype,column2 datatype,column3 datatype,.....columnN datatype,PRIMARY KEY( one or more columns )); DROP 语句句法： DROP TABLE table_name; CREATE INDEX语句句法： CREATE UNIQUE INDEX index_nameON table_name ( column1, column2,...columnN); DROP INDEX语句句法： ALTER TABLE table_nameDROP INDEX index_name; DESC语句句法： DESC table_name; TRUNCATE 截断表语句句法： TRUNCATE TABLE table_name; ALTER TABLE语句句法： sql ALTER TABLE table_name ADD|DROP|MODIFY column_name data_ype; ALTER TABLE语句(对表名重命名)句法： ALTER TABLE table_name RENAME TO new_table_name; Use语句句法： USE database_name; COMMIT语句句法： COMMIT; ROLLBACK语句句法： ROLLBACK;"},{"title":"SQL 运算符","path":"/wiki/sql/sentence/yunsf.html","content":"SQL 运算符 运算符是保留字或主要用于 SQL 语句的 中的字符，用于执行操作，例如：比较和算术运算。 这些运算符用于指定 SQL 语句中的条件，并用作语句中多个条件的连词。 常见运算符有以下几种： 算术运算符 比较运算符 逻辑运算符 否定条件运算符 SQL 算术运算符 假设变量 a 的值是：10，变量 b 的值是：20，以下为各运算符执行结果： 运算符 描述 例子 + 加法，执行加法运算。 a + b 得到 30 - 减法，执行减法运算。 a - b 得到 -10 * 乘法，执行乘法运算。 a * b 得到 200 用左操作数除以右操作数。 b a 得到 2 % 用左操作数除以右操作数并返回余数。 b % a 得到 0 SQL 比较运算符 假设变量 a 的值是：10，变量 b 的值是：20，以下为各运算符执行结果： 运算符 描述 例子 检查两个操作数的值是否相等，如果是，则条件为真(true)。 (a b) is false. ! 检查两个操作数的值是否相等，如果值不相等则条件为真(true)。 (a ! b) is true. 检查两个操作数的值是否相等，如果值不相等则条件为真(true)。 (a b) is true. 检查左操作数的值是否大于右操作数的值，如果是，则条件为真(true)。 (a b) is false. 检查左操作数的值是否小于右操作数的值，如果是，则条件为真(true)。 (a b) is true. 检查左操作数的值是否大于或等于右操作数的值，如果是，则条件为真(true)。 (a b) is false 检查左操作数的值是否小于或等于右操作数的值，如果是，则条件为真(true)。 (a b) is true. ! 检查左操作数的值是否不小于右操作数的值，如果是，则条件变为真(true)。 (a ! b) is false. ! 检查左操作数的值是否不大于右操作数的值，如果是，则条件变为真(true)。 (a ! b) is true. SQL 逻辑运算符： 这是在 SQL 所有的逻辑运算符的列表。 运算符 描述 ALL ALL运算符用于将值与另一个值集中的所有值进行比较。 AND AND运算符允许在SQL语句的WHERE子句中指定多个条件。 ANY ANY运算符用于根据条件将值与列表中的任何适用值进行比较。 BETWEEN BETWEEN运算符用于搜索在给定最小值和最大值内的值。 EXISTS EXISTS运算符用于搜索指定表中是否存在满足特定条件的行。 IN运算符用于将值与已指定的文字值列表进行比较。 LIKE LIKE运算符用于使用通配符运算符将值与类似值进行比较。 NOT NOT运算符反转使用它的逻辑运算符的含义。 例如：NOT EXISTS, NOT BETWEEN, NOT IN等等，这是一个否定运算符。 OR OR运算符用于组合SQL语句的WHERE子句中的多个条件。 IS NULL IS NULL运算符用于将值与NULL值进行比较。 UNIQUE UNIQUE运算符搜索指定表的每一行的唯一性(无重复项)。"},{"title":"SQL 查询子句","path":"/wiki/sql/sentence/ziju.html","content":"SQL WHERE 子句 WHERE 子句用于过滤记录。 WHERE 子句用于提取满足指定标准的记录。 SQL WHERE 语法SELECT column1, column2, ...FROM table_nameWHERE condition; 注意： WHERE子句不仅用于SELECT语法，还用于UPDATE，DELETE语法等！ WHERE子句可以与以下类型的SQL语句一起使用： UPDATE DELETE UPDATE语句： UPDATE table_nameSET column_1 = [new value]WHERE condition; DELETE语句： DELETE FROM table_name WHERE condition; 演示数据库 在本教程中，我们将使用著名的Northwind示例数据库。　以下是 “Customers” 表中的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden WHERE 子句实例 以下SQL语句从”Customers”表中选择其国家为”Mexico”的所有客户： 示例: SELECT * FROM Customers WHERE Country=Mexico; 你也可以使用OR运算符的查询子句： 示例: SELECT * FROM Customers WHERE Country=Mexico OR PostalCode=05021; 文本字段与数值字段 SQL在文本值周围使用单引号（大多数数据库系统也接受双引号）。 如果是数值字段，则不要使用引号。 示例: SELECT * FROM Customers WHERE CustomerID=1; WHERE 子句中的运算符 WHERE子句中可以使用以下运算符： 运算符 描述 等于 不等于。 注意 ：在某些版本的SQL中，这个操作符可能写成! 大于 小于 大于等于 小于等于 BETWEEN 在某个范围内 LIKE 搜索某种模式 IN 为列指定多个可能的值"},{"title":"SQL 选择","path":"/wiki/sql/sentence/xuanze.html","content":"SQL SELECT 语法 SELECT 语法用于从数据库中选择数据。 返回的数据存储在结果表中，称为结果集。 基本语法：SELECT和FROM在任何SQL查询语句中都：SELECT和FROM他们必须按顺序排列。SELECT指示要查看哪些列，FROM标识它们所在的表。 SQL SELECT 语法如下所示： SELECT column1, column2, ...FROM table_name; 这里，column1，column2，…是要从中选择数据的表的字段名称。如果要选择表中可用的所有字段，请使用以下语法： SELECT * FROM table_name; 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是罗斯文示例数据库中”Customers”表的一个选择： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SELECT Column 实例 我们将为以下三种用例提供实例 1、检索一列2、检索多列3、检索所有列 我们将用上述的”Customers”表来说明三种用例的使用。 SELECT 检索一列下面的 SQL 语句从 “Customers” 表中选取 “City” 列： 实例SELECT City FROM Customers; SELECT 检索多列下面的 SQL 语句从 “Customers” 表中选取 “CustomerName” 和 “City” 列： 实例SELECT CustomerName, City FROM Customers; **注意：**这两个列名在查询中用逗号分隔。每当您选择多个列时，它们必须用逗号分隔，但最后一列名称之后不能添加逗号。 SELECT * 实例 - 检索所有列下面的 SQL 语句从 “Customers” 表中选取所有列： 实例SELECT * FROM Customers; 如果要选择表中的所有列，则可以使用 * 而不需要把所有列名罗列查询。 结果集中的导航 大多数数据库软件系统都允许使用编程函数在结果集中进行导航，例如：Move-To-First-Record、Get-Record-Content、Move-To-Next-Record 等等。 本教程中不包括与这些编程函数类似的功能。要了解如何通过函数调用访问数据，请访问我们的 或者 。"},{"title":"SQL COUNT() 函数","path":"/wiki/sql/function/count.html","content":"COUNT() 函数COUNT() 函数返回匹配指定条件的行数。 SQL COUNT(column_name) 语法COUNT(column_name) 函数返回指定列的值的数目（NULL 不计入）： SELECT COUNT(column_name) FROM table_name; SQL COUNT(*) 语法COUNT(*) 函数返回表中的记录数： SELECT COUNT(*) FROM table_name; SQL COUNT(DISTINCT column_name) 语法COUNT(DISTINCT column_name) 函数返回指定列的不同值的数目： SELECT COUNT(DISTINCT column_name) FROM table_name; 注释：COUNT(DISTINCT) 适用于 ORACLE 和 Microsoft SQL Server，但是无法用于 Microsoft Access。 演示数据库在本教程中，我们将使用 ngrok 样本数据库。 下面是选自 “access_log” 表的数据： +-----+---------+-------+------------+| aid | site_id | count | date |+-----+---------+-------+------------+| 1 | 1 | 45 | 2016-05-10 || 2 | 3 | 100 | 2016-05-13 || 3 | 1 | 230 | 2016-05-14 || 4 | 2 | 10 | 2016-05-14 || 5 | 5 | 205 | 2016-05-14 || 6 | 4 | 13 | 2016-05-15 || 7 | 3 | 220 | 2016-05-15 || 8 | 5 | 545 | 2016-05-16 || 9 | 3 | 201 | 2016-05-17 |+-----+---------+-------+------------+ SQL COUNT(column_name) 实例下面的 SQL 语句计算 “access_log” 表中 “site_id”3 的总访问量： 示例 SELECT COUNT(count) AS nums FROM access_logWHERE site_id=3; SQL COUNT(*) 实例下面的 SQL 语句计算 “access_log” 表中总记录数： 示例 SELECT COUNT(*) AS nums FROM access_log; 执行以上 SQL 输出结果如下： SQL COUNT(DISTINCT column_name) 实例mn-name-实例)下面的 SQL 语句计算 “access_log” 表中不同 site_id 的记录数： 示例 SELECT COUNT(DISTINCT site_id) AS nums FROM access_log;"},{"title":"SQL AVG() 函数","path":"/wiki/sql/function/avg.html","content":"SQL AVG() 函数 AVG() 函数AVG() 函数返回数字列的平均值。 AVG() 语法SELECT AVG(column_name)FROM table_nameWHERE condition; 演示数据库 在本教程中，我们将使用著名的 Northwind 样本数据库。 下面是选自 “Products” 表的数据： ProductID ProductName SupplierID CategoryID Unit Price 1 Chais 1 1 10 boxes x 20 bags 18 2 Chang 1 1 24 - 12 oz bottles 19 3 Aniseed Syrup 1 2 12 - 550 ml bottles 10 4 Chef Anton’s Cajun Seasoning 2 2 48 - 6 oz jars 22 5 Chef Anton’s Gumbo Mix 2 2 36 boxes 21.35 SQL AVG() 实例 以下SQL语句查找所有产品的平均价格： 示例 SELECT AVG(Price)FROM Products; 下面的 SQL 语句选择价格高于平均价格的 “ProductName” 和 “Price” 记录： 示例 SELECT ProductName, Price FROM ProductsWHERE Price(SELECT AVG(Price) FROM Products);"},{"title":"SQL 日期函数","path":"/wiki/sql/function/datetime.html","content":"SQL 日期函数 下面的列表中是 SQL 中所有与日期和时间相关的重要函数。你所用的 RDBMS 可能会支持更多其他的函数。下面的列表基于 MySQL 关系型数据库管理系统。 |—————————————-|—————————————————–| | 名称 | 描述 | | ADDDATE() | 增加日期 | | ADDTIME() | 增加时间 | | CONVERT_TZ() | 将当前时区更改为另一时区 | | CURDATE() | 返回当前日期 | | CURRENT_DATE(), CURRENT_DATE | CURDATE() 的别名 | | CURRENT_TIME(), CURRENT_TIME | CURTIME() 的别名 | | CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP | NOW() 的别名 | | CURTIME() | 返回当前时间 | | DATE_ADD() | 将两个日期相加 | | DATE_FORMAT() | 按照指定格式格式化日期 | | DATE_SUB() | 将两个日期相减 | | DATE() | 从 date 或者 datetime 表达式中提取出日期部分 | | DATEDIFF() | 将两个日期相减 | | DAY() | DAYOFMONTH() 的别名 | | DAYNAME() | 返回某天在用星期中的名称 | | DAYOFMONTH() | 返回某天是当月的第几天 （1-31） | | DAYOFWEEK() | 返回某天是该星期的第几天 | | DAYOFYEAR() | 返回某天是一年中的第几天（1-366） | | EXTRACT | 提取日期中的某一部分 | | FROM_DAYS() | 将天数转换为日期 | | FROM_UNIXTIME() | 将某个日期格式化为 UNIX 时间戳 | | HOUR() | 提取小时 | | LAST_DAY | 返回参数日期所在月份的最后一天 | | LOCALTIME(), LOCALTIME | NOW() 的别名 | | LOCALTIMESTAMP, LOCALTIMESTAMP() | NOW() 的别名 | | MAKEDATE() | 利用年份和某天在该年所处的天数来创建日期 | | MAKETIME | MAKETIME() | | MICROSECOND() | 由参数返回微秒 | | MINUTE() | 由参数返回分钟 | | MONTH() | 返回日期参数的月份 | | MONTHNAME() | 返回月份的名字 | | NOW() | 返回当前日期和时间 | | PERIOD_ADD() | 向年月格式的日期数据之间添加一段时间 | | PERIOD_DIFF() | 返回两个年月格式的日期数据之间的月份数 | | QUARTER() | 返回日期参数所在的季度 | | SEC_TO_TIME() | 将秒数转换为 ‘HH:MM:SS’ 格式 | | SECOND() | 返回参数中的秒数 (0-59) | | STR_TO_DATE() | 将字符串转换为日期数据 | | SUBDATE() | 以三个参数调用的时候是 DATE_SUB() 的同义词 | | SUBTIME() | 减去时间 | | SYSDATE() | 返回函数执行的时的时刻 | | TIME_FORMAT() | 格式化时间 | | TIME_TO_SEC() | 将时间参数转换为秒数 | | TIME() | 返回参数表达式中的时间部分 | | TIMEDIFF() | 将两个时间相减 | | TIMESTAMP() | 只有一个参数时，该函数返回 date 或者 datetime 表达式。当有两个参数时，将两个参数相加。 | | TIMESTAMPADD() | 在 datetime 表达式上加上一段时间 | | TIMESTAMPDIFF() | 在 datetime 表达式上减去一段时间 | | TO_DAYS() | 将日期参数转换为天数 | | UNIX_TIMESTAMP() | 返回 UNIX 时间戳 | | UTC_DATE() | 返回当前 UTC 日期 | | UTC_TIME() | 返回当前 UTC 时间 | | UTC_TIMESTAMP() | 返回当前 UTC 日期和时间 | | WEEK() | 返回参数的星期数 | | WEEKDAY() | 返回日期参数时一个星期中的第几天 | | WEEKOFYEAR() | 返回日期参数是日历上的第几周 (1-53) | | YEAR() | 返回日期参数中的年份 | | YEARWEEK() | 返回年份和星期 | ADDDATE(date, INTERVAL expr unit), ADDDATE(expr, days) 如果调用时第二个参数为 INTERVAL 形式的话，ADDDATE() 就是 DATE_ADD() 的同义词。同样的情况下，SUBDATE() 是 DATE_SUB() 的同义词。有关 INTERVAL 单位参数的信息，见有关 DATE_ADD() 的讨论。 mysql SELECT DATE_ADD(1998-01-02, INTERVAL 31 DAY);+---------------------------------------------------------+| DATE_ADD(1998-01-02, INTERVAL 31 DAY) |+---------------------------------------------------------+| 1998-02-02 |+---------------------------------------------------------+1 row in set (0.00 sec)mysql SELECT ADDDATE(1998-01-02, INTERVAL 31 DAY);+---------------------------------------------------------+| ADDDATE(1998-01-02, INTERVAL 31 DAY) |+---------------------------------------------------------+| 1998-02-02 |+---------------------------------------------------------+1 row in set (0.00 sec) 如果调用时第二个参数为天数形式的话，则 MySQL 会将其作为整数加到 expr 上。 mysql SELECT ADDDATE(1998-01-02, 31);+---------------------------------------------------------+| DATE_ADD(1998-01-02, INTERVAL 31 DAY) |+---------------------------------------------------------+| 1998-02-02 |+---------------------------------------------------------+1 row in set (0.00 sec) ADDTIME(expr1,expr2) ADDTIME() 将 expr2 加到 expr1 上，并返回结果。expr1 为 time 或者 datetime 表达式，expr2 为 time 表达式。 mysql SELECT ADDTIME(1997-12-31 23:59:59.999999,1 1:1:1.000002);+---------------------------------------------------------+| DATE_ADD(1997-12-31 23:59:59.999999,1 1:1:1.000002) |+---------------------------------------------------------+| 1998-01-02 01:01:01.000001 |+---------------------------------------------------------+1 row in set (0.00 sec) CONVERT_TZ(dt,from_tz,to_tz) 该函数将 datetime 类型的值 dt 的时区从 from_dt 转换为 to_dt，并返回结果。如果参数无效，则函数返回 NULL。 mysql SELECT CONVERT_TZ(2004-01-01 12:00:00,GMT,MET);+---------------------------------------------------------+| CONVERT_TZ(2004-01-01 12:00:00,GMT,MET) |+---------------------------------------------------------+| 2004-01-01 13:00:00 |+---------------------------------------------------------+1 row in set (0.00 sec)mysql SELECT CONVERT_TZ(2004-01-01 12:00:00,+00:00,+10:00);+---------------------------------------------------------+| CONVERT_TZ(2004-01-01 12:00:00,+00:00,+10:00) |+---------------------------------------------------------+| 2004-01-01 22:00:00 |+---------------------------------------------------------+1 row in set (0.00 sec) CURDATE() 以 ‘YYYY-MM-DD’（字符串） 或者 YYYYMMDD（数值） 的形式返回当前日期， 具体形式取决于函数处于字符串还是数值型的上下文环境中。 mysql SELECT CURDATE();+---------------------------------------------------------+| CURDATE() |+---------------------------------------------------------+| 1997-12-15 |+---------------------------------------------------------+1 row in set (0.00 sec)mysql SELECT CURDATE() + 0;+---------------------------------------------------------+| CURDATE() + 0 |+---------------------------------------------------------+| 19971215 |+---------------------------------------------------------+1 row in set (0.00 sec) CURRENT_DATE and CURRENT_DATE() CURRENT_DATE 和 CURRENT_DATE() 是 CURDATE() 的别名。 CURTIME() 以 ‘HH:MM:SS’（字符串） 或者 HHMMSS（数值） 的形式返回当前时间， 具体形式取决于函数处于字符串还是数值型的上下文环境中。该函数按照当前时区来表示返回值。 mysql SELECT CURTIME();+---------------------------------------------------------+| CURTIME() |+---------------------------------------------------------+| 23:50:26 |+---------------------------------------------------------+1 row in set (0.00 sec)mysql SELECT CURTIME() + 0;+---------------------------------------------------------+| CURTIME() + 0 |+---------------------------------------------------------+| 235026 |+---------------------------------------------------------+1 row in set (0.00 sec) CURRENT_TIME and CURRENT_TIME() CURRENT_TIME 和 CURRENT_TIME() 是 CURTIME() 的别名。 CURRENT_TIMESTAMP and CURRENT_TIMESTAMP() CURRENT_TIMESTAMP 和 CURRENT_TIMESTAMP() 是 NOW() 的别名。 DATE(expr) 提取 date 表达式或者 datetime 表达式中的日期部分。 mysql SELECT DATE(2003-12-31 01:02:03);+---------------------------------------------------------+| DATE(2003-12-31 01:02:03) |+---------------------------------------------------------+| 2003-12-31 |+---------------------------------------------------------+1 row in set (0.00 sec) DATEDIFF(expr1,expr2) DATEDIFF() 返回 expr1 和 expr2 的差，以天数的形式表示。expr1 和 expr2 应为 date 或者 datetime 表达式。只有参数的日期部分参与了计算。 mysql SELECT DATEDIFF(1997-12-31 23:59:59,1997-12-30);+---------------------------------------------------------+| DATEDIFF(1997-12-31 23:59:59,1997-12-30) |+---------------------------------------------------------+| 1 |+---------------------------------------------------------+1 row in set (0.00 sec) DATE_ADD(date,INTERVAL expr unit), DATE_SUB(date,INTERVAL expr unit) 这些函数进行有关日期的算术运算。date 是一个 DATETIME 或者 DATE 类型的值，指明了起始时间。expr 表达式则是 date 要增加或者减去的时间间隔。expr 是一个字符串，可以以 ‘-‘ 开始来表示负时间区间。 unit 是一个关键词，指明了expr 的单位。 INTERVAL 关键字和 unit（单位）指示符不区分大小写。 下表列出了对于每种单位，expr 应有的形式。 |——————–|————| | unit 值 | expr 应有的格式 | | MICROSECOND | 微秒 | | SECOND | 秒 | | MINUTE | 分钟 | | HOUR | 小时 | | DAY | 天 | | WEEK | 星期 | | MONTH | 月 | | QUARTER | 季度 | | YEAR | 年 | | SECOND_MICROSECOND | ‘秒.微秒’ | | MINUTE_MICROSECOND | ‘分.微秒’ | | MINUTE_SECOND | ‘分:秒’ | | HOUR_MICROSECOND | ‘小时.微秒’ | | HOUR_SECOND | ‘时:分:秒’ | | HOUR_MINUTE | ‘时:分’ | | DAY_MICROSECOND | ‘天.微秒’ | | DAY_SECOND | ‘天 时:分:秒’ | | DAY_MINUTE | ‘天 时:分’ | | DAY_HOUR | ‘天 时’ | | YEAR_MONTH | ‘年-月’ | QUARTER 和 WEEK 自 MySQL 5.0.0 起受到支持。 mysql SELECT DATE_ADD(1997-12-31 23:59:59, - INTERVAL 1:1 MINUTE_SECOND);+---------------------------------------------------------+| DATE_ADD(1997-12-31 23:59:59, INTERVAL... |+---------------------------------------------------------+| 1998-01-01 00:01:00 |+---------------------------------------------------------+1 row in set (0.00 sec)mysql SELECT DATE_ADD(1999-01-01, INTERVAL 1 HOUR);+---------------------------------------------------------+| DATE_ADD(1999-01-01, INTERVAL 1 HOUR) |+---------------------------------------------------------+| 1999-01-01 01:00:00 |+---------------------------------------------------------+1 row in set (0.00 sec) DATE_FORMAT(date,format) 根据格式字符串对日期值进行格式化。 下面这些占位符可以用在格式字符串中，’%’ 必须出现在特定的格式字符之前。 |—–|——————————————| | 占位符 | 描述 | | %a | 简写的星期名称（Sun..Sat） | | %b | 简写的月份名称 （Jan..Dec） | | %c | 月份，以数值形式表示（0..12） | | %D | 月份中的日期，带有英文后缀（0th，1st，2nd，3rd 等等） | | %d | 月份中的日期，以数值表示 (00..31) | | %e | 月份中的日期，以数值表示 (0..31) | | %f | 微秒（000000..999999） | | %H | 小时(00..23) | | %h | 小时(01..12) | | %I | 小时(01..12) | | %i | 分钟,以数值表示(00..59) | | %j | 一年中的第几天（001..366） | | %k | 小时（0..23） | | %l | 小时（1..12） | | %M | 月份的名称（January..December） | | %m | 月份，以数值形式表示（00..12） | | %p | AM 或者 PM | | %r | 时间，12 小时制(hh:mm:ss followed by AM or PM) | | %S | 秒(00..59) | | %s | 秒(00..59) | | %T | 时间，24小时制（hh:mm:ss） | | %U | 星期（00..53），此处星期日为一周的第一天 | | %u | 星期（00..53），此处星期一为一周的第一天 | | %V | 星期（01..53），此处星期日为一周的第一天；与 %X 一起使用。 | | %v | 星期（01..53），此处星期一为一周的第一天；与 %x 一起使用。 | | %W | 一周中日期的名称（Sunday..Saturday） | | %w | 一周中的第几天（0Sunday..6Saturday） | | %X | 以星期日为第一天的周所处的年份，四位数字表示；同 %V 一起使用。 | | %x | 以星期一为第一天的周所处的年份，四位数字表示；同 %v 一起使用。 | | %Y | 年份，四位数字表示。 | | %y | 年份，两位数字表示。 | | %% | % 字面值 | | %x | x，针对任何以上没有列出的情况。 | mysql SELECT DATE_FORMAT(1997-10-04 22:23:00, %W %M %Y);+---------------------------------------------------------+| DATE_FORMAT(1997-10-04 22:23:00, %W %M %Y) |+---------------------------------------------------------+| Saturday October 1997 |+---------------------------------------------------------+1 row in set (0.00 sec)mysql SELECT DATE_FORMAT(1997-10-04 22:23:00 - %H %k %I %r %T %S %w);+---------------------------------------------------------+| DATE_FORMAT(1997-10-04 22:23:00....... |+---------------------------------------------------------+| 22 22 10 10:23:00 PM 22:23:00 00 6 |+---------------------------------------------------------+1 row in set (0.00 sec) DATE_SUB(date,INTERVAL expr unit) 同 DATE_ADD() 函数相似。 DAY(date) DAY() 是 DAYOFMONTH() 的别名。 DAYNAME(date) 返回 date 在星期中的名称。 mysql SELECT DAYNAME(1998-02-05);+---------------------------------------------------------+| DAYNAME(1998-02-05) |+---------------------------------------------------------+| Thursday |+---------------------------------------------------------+1 row in set (0.00 sec) DAYOFMONTH(date) 返回 date 是当月的第几天，范围为 0 到 31。 mysql SELECT DAYOFMONTH(1998-02-03);+---------------------------------------------------------+| DAYOFMONTH(1998-02-03) |+---------------------------------------------------------+| 3 |+---------------------------------------------------------+1 row in set (0.00 sec) DAYOFWEEK(date) 返回 date 是其所在星期的第几天(1 Sunday, 2 Monday,.., 7 Saturday)，这里一星期中日期的名称与数字的对应关系符合 ODBC 标准。 mysql SELECT DAYOFWEEK(1998-02-03);+---------------------------------------------------------+|DAYOFWEEK(1998-02-03) |+---------------------------------------------------------+| 3 |+---------------------------------------------------------+1 row in set (0.00 sec) DAYOFYEAR(date) 返回 date 是当年的第几天，范围为 1 到 366。 mysql SELECT DAYOFYEAR(1998-02-03);+---------------------------------------------------------+| DAYOFYEAR(1998-02-03) |+---------------------------------------------------------+| 34 |+---------------------------------------------------------+1 row in set (0.00 sec) EXTRACT(unit FROM date) EXTRACT() 与 DATE_ADD() 和 DATE_SUB() 使用相同的表示单位的占位符，其作用是提取日期值中相应的组成部分，而不是进行日期运算。 mysql SELECT EXTRACT(YEAR FROM 1999-07-02);+---------------------------------------------------------+| EXTRACT(YEAR FROM 1999-07-02) |+---------------------------------------------------------+| 1999 |+---------------------------------------------------------+1 row in set (0.00 sec)mysql SELECT EXTRACT(YEAR_MONTH FROM 1999-07-02 01:02:03);+---------------------------------------------------------+| EXTRACT(YEAR_MONTH FROM 1999-07-02 01:02:03) |+---------------------------------------------------------+| 199907 |+---------------------------------------------------------+1 row in set (0.00 sec) FROM_DAYS(N) 给出天数 N，返回 DATE 值。 mysql SELECT FROM_DAYS(729669);+---------------------------------------------------------+| FROM_DAYS(729669) |+---------------------------------------------------------+| 1997-10-07 |+---------------------------------------------------------+1 row in set (0.00 sec) 在使用 FROM_DAYS() 处理比较老的日期的时候应当特别小心，该函数不适用于格里高利历诞生（1582）之前的日期。 FROM_UNIXTIME(unix_timestamp), FROM_UNIXTIME(unix_timestamp,format) 返回 UNIX 时间戳对应的日期值，根据函数所处的上下文环境不同，返回值得格式也不同，字符串上下文返回格式为 ‘YYYY-MM-DD HH:MM:SS’，数值型上下文返回格式则为 YYYYMMDDHHMMSS。返回值的时区为系统当前时区。UNIX 时间戳是一种系统内部时间表示，例如 UNIX_TIMESTAMP() 的返回值。 如果给定格式的话，返回结果将会根据格式字符串进行格式化，其规则同 DATE_FORMAT() 函数。 mysql SELECT FROM_UNIXTIME(875996580);+---------------------------------------------------------+| FROM_UNIXTIME(875996580) |+---------------------------------------------------------+| 1997-10-04 22:23:00 |+---------------------------------------------------------+1 row in set (0.00 sec) HOUR(time) 返回时间值的小时部分。对于一天中的时间来说，返回值的范围为 0 到 23。不过，TIME 类型的值可以大得多，所以 HOUR 函数可以返回比 23 大的值。 mysql SELECT HOUR(10:05:03);+---------------------------------------------------------+| HOUR(10:05:03) |+---------------------------------------------------------+| 10 |+---------------------------------------------------------+1 row in set (0.00 sec) LAST_DAY(date) 返回 date 或者 datetime 值所在月份的最后一天。如果参数无效的话，返回　NULL。 mysql SELECT LAST_DAY(2003-02-05);+---------------------------------------------------------+| LAST_DAY(2003-02-05) |+---------------------------------------------------------+| 2003-02-28 |+---------------------------------------------------------+1 row in set (0.00 sec) LOCALTIME and LOCALTIME() LOCALTIME 和 LOCALTIME() 是 NOW() 的别名。 LOCALTIMESTAMP and LOCALTIMESTAMP() LOCALTIMESTAMP 和 LOCALTIMESTAMP() 是 NOW() 的别名。 MAKEDATE(year,dayofyear) 给定年份和（某天在一年中）的天数，返回对应的日期值。天数必须大于 0，否则返回值为 NULL。 mysql SELECT MAKEDATE(2001,31), MAKEDATE(2001,32);+---------------------------------------------------------+| MAKEDATE(2001,31), MAKEDATE(2001,32) |+---------------------------------------------------------+| 2001-01-31, 2001-02-01 |+---------------------------------------------------------+1 row in set (0.00 sec) MAKETIME(hour,minute,second) 根据参数给出的时、分、秒，返回对应的时间值。 mysql SELECT MAKETIME(12,15,30);+---------------------------------------------------------+| MAKETIME(12,15,30) |+---------------------------------------------------------+| 12:15:30 |+---------------------------------------------------------+1 row in set (0.00 sec) MICROSECOND(expr) 根据 time 或者 datetime 表达式 expr，返回微秒数，结果在 0 到 999999 之间。 mysql SELECT MICROSECOND(12:00:00.123456);+---------------------------------------------------------+| MICROSECOND(12:00:00.123456) |+---------------------------------------------------------+| 123456 |+---------------------------------------------------------+1 row in set (0.00 sec) MINUTE(time) 返回时间型值中的分钟部分，范围为 0 到 59。 mysql SELECT MINUTE(98-02-03 10:05:03);+---------------------------------------------------------+| MINUTE(98-02-03 10:05:03) |+---------------------------------------------------------+| 5 |+---------------------------------------------------------+1 row in set (0.00 sec) MONTH(date) 返回日期型值中的月份，范围为 0 到 12。 mysql SELECT MONTH(1998-02-03)+---------------------------------------------------------+| MONTH(1998-02-03) |+---------------------------------------------------------+| 2 |+---------------------------------------------------------+1 row in set (0.00 sec) MONTHNAME(date) 返回日期型值所处月份的全名。 mysql SELECT MONTHNAME(1998-02-05);+---------------------------------------------------------+| MONTHNAME(1998-02-05) |+---------------------------------------------------------+| February |+---------------------------------------------------------+1 row in set (0.00 sec) NOW() 返回当前的日期和时间，结果的格式为 ‘YYYY-MM-DD HH:MM:SS’ 或者 YYYYMMDDHHMMSS，如果函数上下文环境为字符型，则返回前者，否则如果函数处于数值型的上下文环境，则返回后者。返回值的时区为系统当前时区。 mysql SELECT NOW();+---------------------------------------------------------+| NOW() |+---------------------------------------------------------+| 1997-12-15 23:50:26 |+---------------------------------------------------------+1 row in set (0.00 sec) PERIOD_ADD(P,N) 在时间 P（格式为 YYMM 或者 YYYYMM）上加上 N 个月，结果格式为 YYYYMM。注意，时间参数 P 并不是日期型值。 mysql SELECT PERIOD_ADD(9801,2);+---------------------------------------------------------+| PERIOD_ADD(9801,2) |+---------------------------------------------------------+| 199803 |+---------------------------------------------------------+1 row in set (0.00 sec) PERIOD_DIFF(P1,P2) 返回时间 P1 和 P2 之间相差的月份。 P1 和 P2 的格式应为 YYMM 或者 YYYYMM。注意I，P1 和 P2 不是日期型值。 mysql SELECT PERIOD_DIFF(9802,199703);+---------------------------------------------------------+| PERIOD_DIFF(9802,199703) |+---------------------------------------------------------+| 11 |+---------------------------------------------------------+1 row in set (0.00 sec) QUARTER(date) 返回日期型值 date 所处的季度值，范围为 1 到 4。 mysql SELECT QUARTER(98-04-01);+---------------------------------------------------------+| QUARTER(98-04-01) |+---------------------------------------------------------+| 2 |+---------------------------------------------------------+1 row in set (0.00 sec) SECOND(time) 返回时间型值中秒的部分，范围为 0 到 59。 mysql SELECT SECOND(10:05:03);+---------------------------------------------------------+| SECOND(10:05:03) |+---------------------------------------------------------+| 3 |+---------------------------------------------------------+1 row in set (0.00 sec) SEC_TO_TIME(seconds) 将参数中的秒数转换为时分秒的格式 ‘HH:MM:SS’ 或者 HHMMSS，如果函数所处的上下文为字符串型，则返回前者，否则如果上下文环境为数值型，则返回后者。 STR_TO_DATE(str,format) 这是 DATE_FORMATE() 函数的逆函数，其参数为表示时间和日期的字符串 str 和一个格式字符串 format。如果格式字符串中既有日期又有时间，则 STR_TO_DATE() 返回 DATETIME() 型的值，否则返回日期型（DATE）或者时间型（TIME）的值。 mysql SELECT STR_TO_DATE(04/31/2004, %m/%d/%Y);+---------------------------------------------------------+| STR_TO_DATE(04/31/2004, %m/%d/%Y) |+---------------------------------------------------------+| 2004-04-31 |+---------------------------------------------------------+1 row in set (0.00 sec) SUBDATE(date,INTERVAL expr unit) and SUBDATE(expr,days) 当第二个参数为 INTERVAL 形式时，SUBDATE() 就是 DATE_SUB() 的别名。INTERVAL 参数中单位的信息，请见有关 DATE_ADD() 的讨论。 mysql SELECT DATE_SUB(1998-01-02, INTERVAL 31 DAY);+---------------------------------------------------------+| DATE_SUB(1998-01-02, INTERVAL 31 DAY) |+---------------------------------------------------------+| 1997-12-02 |+---------------------------------------------------------+1 row in set (0.00 sec)mysql SELECT SUBDATE(1998-01-02, INTERVAL 31 DAY);+---------------------------------------------------------+| SUBDATE(1998-01-02, INTERVAL 31 DAY) |+---------------------------------------------------------+| 1997-12-02 |+---------------------------------------------------------+1 row in set (0.00 sec) SUBTIME(expr1,expr2) SUBTIME() 返回 expr1-expr2，结果的格式与 expr1 相同。expr1 是一个时间型（time）或者 datetime 型的表达式，expr2 是时间型值。 SYSDATE() 返回当前的日期和时间，格式为 ‘YYYY-MM-DD HH:MM:SS’ 或 YYYYMMDDHHMMSS，如果函数所处的上下文环境为字符串，则返回前者，否则如果上下文环境为数值型，则返回后者。 sql mysql SELECT SYSDATE();+---------------------------------------------------------+| SYSDATE() |+---------------------------------------------------------+| 2006-04-12 13:47:44 |+---------------------------------------------------------+1 row in set (0.00 sec) TIME(expr) 提取时间型或者 datetime 型表达式 expr 中的时间部分，返回结果为字符串。 mysql SELECT TIME(2003-12-31 01:02:03);+---------------------------------------------------------+| TIME(2003-12-31 01:02:03) |+---------------------------------------------------------+| 01:02:03 |+---------------------------------------------------------+1 row in set (0.00 sec) TIMEDIFF(expr1,expr2) TIMEDIFF() 返回 expr1-expr2，结果为时间型值。expr1 和 expr2 可以为时间型或者 datetime 型表达式，不过二者必须为相同类型。 mysql SELECT TIMEDIFF(1997-12-31 23:59:59.000001, - 1997-12-30 01:01:01.000002);+---------------------------------------------------------+| TIMEDIFF(1997-12-31 23:59:59.000001..... |+---------------------------------------------------------+| 46:58:57.999999 |+---------------------------------------------------------+1 row in set (0.00 sec) TIMESTAMP(expr), TIMESTAMP(expr1,expr2) 只有一个参数的时候，该函数由日期型或者 datetime 型表达式返回一个 datetime 型值。有两个参数的时候，该函数将 expr2 加到日期型或 datetime 型值 expr1 上，并返回 datetime 型的结果。 mysql SELECT TIMESTAMP(2003-12-31);+---------------------------------------------------------+| TIMESTAMP(2003-12-31) |+---------------------------------------------------------+| 2003-12-31 00:00:00 |+---------------------------------------------------------+1 row in set (0.00 sec) TIMESTAMPADD(unit,interval,datetime_expr) 将整数型的表达式 interval 加到日期型或者 datetime 型表达式 datetime_expr 上。单位由 unit 参数给出，其取值应为以下几种中的一种：FRAC_SECOND、SECOND、MINUTE、HOUR、DAY、WEEK、MONTH、QUARTER 或者 YEAR。 单位 unit 可以为上述关键字中的一个，也可以添加一个 SQLTSI 前缀，例如 DAY 和 SQL_TSI_DAY 都是合法的。 sql mysql SELECT TIMESTAMPADD(MINUTE,1,2003-01-02);+---------------------------------------------------------+| TIMESTAMPADD(MINUTE,1,2003-01-02) |+---------------------------------------------------------+| 2003-01-02 00:01:00 |+---------------------------------------------------------+1 row in set (0.00 sec) TIMESTAMPDIFF(unit,datetime_expr1,datetime_expr2) 返回日期型或者 datetime 型表达式 datetime_expr1 和 datetime_expr2 的差。结果的单位由 unit 参数给出，unit 的取值规定同 TIMESTAMPADD() 函数。 mysql SELECT TIMESTAMPDIFF(MONTH,2003-02-01,2003-05-01);+---------------------------------------------------------+| TIMESTAMPDIFF(MONTH,2003-02-01,2003-05-01) |+---------------------------------------------------------+| 3 |+---------------------------------------------------------+1 row in set (0.00 sec) TIME_FORMAT(time,format) 该函数使用起来类似 DATE_FORMAT() 函数，但是格式字符串 format 中只能有与小时、分钟和秒有关的那些占位符。 如果时间型值的小时部分大于 23，则 %H 和 %k 格式占位符将会产生一个大于通常的 0-23 的值，其他与小时有关的占位符则会返回小时值除以 12 后的余数（modulo 12）。 mysql SELECT TIME_FORMAT(100:00:00, %H %k %h %I %l);+---------------------------------------------------------+| TIME_FORMAT(100:00:00, %H %k %h %I %l) |+---------------------------------------------------------+| 100 100 04 04 4 |+---------------------------------------------------------+1 row in set (0.00 sec) TIME_TO_SEC(time) 将时间型值转换为秒。 mysql SELECT TIME_TO_SEC(22:23:00);+---------------------------------------------------------+| TIME_TO_SEC(22:23:00) |+---------------------------------------------------------+| 80580 |+---------------------------------------------------------+1 row in set (0.00 sec)、 TO_DAYS(date) 给定日期型值 date，返回天数（自公元 0 年以来的天数）。 mysql SELECT TO_DAYS(950501);+---------------------------------------------------------+| TO_DAYS(950501) |+---------------------------------------------------------+| 728779 |+---------------------------------------------------------+1 row in set (0.00 sec) UNIX_TIMESTAMP(), UNIX_TIMESTAMP(date) 不带任何参数时，该函数返回一个 unsigned integer 型的 UNIX 时间戳（自 ‘1970-01-01 00:00:00’ UTC 以来的秒数）。如果有一个参数 date 的话，该函数返回自 ‘1970-01-01 00:00:00’ UTC 至 date 的秒数。date 可以是日期型的字符串、DATETIME 型的字符串、时间戳或者 YYMMDD 或 YYYYMMDD 格式的数字。 mysql SELECT UNIX_TIMESTAMP();+---------------------------------------------------------+| UNIX_TIMESTAMP() |+---------------------------------------------------------+| 882226357 |+---------------------------------------------------------+1 row in set (0.00 sec)mysql SELECT UNIX_TIMESTAMP(1997-10-04 22:23:00);+---------------------------------------------------------+| UNIX_TIMESTAMP(1997-10-04 22:23:00) |+---------------------------------------------------------+| 875996580 |+---------------------------------------------------------+1 row in set (0.00 sec) UTC_DATE, UTC_DATE() 返回当前 UTC 日期，格式为 ‘YYYY-MM-DD’ 或者 YYYYMMDD，如果函数所处的上下文环境为字符串，则返回前者，否则如果上下文环境为数值型的，则返回后者。 mysql SELECT UTC_DATE(), UTC_DATE() + 0;+---------------------------------------------------------+| UTC_DATE(), UTC_DATE() + 0 |+---------------------------------------------------------+| 2003-08-14, 20030814 |+---------------------------------------------------------+1 row in set (0.00 sec) UTC_TIME, UTC_TIME() 返回当前 UTC 时间，格式为 ‘HH:MM:SS’ 或者 HHMMSS，如果函数所处的上下文环境为字符串，则返回前者，否则如果上下文环境为数值型的，则返回后者。 mysql SELECT UTC_TIMESTAMP(), UTC_TIMESTAMP() + 0;+---------------------------------------------------------+| UTC_TIMESTAMP(), UTC_TIMESTAMP() + 0 |+---------------------------------------------------------+| 2003-08-14 18:08:04, 20030814180804 |+---------------------------------------------------------+1 row in set (0.00 sec) WEEK(date[,mode]) 该函数将返回 date 所在的周是当年的第几周。两个参数的 WEEK() 函数的使你能够指明一周起始于周日还是周一，以及返回值的范围应该是 0 到 53，还是 1 到 53。如果 mode 参数被忽略，则将使用 default_week_format 系统变量。 |——|——–|——|————| | Mode | 一周的第一天 | 范围 | 周 1 是第一周 | | 0 | Sunday | 0-53 | 该年包括一个星期天 | | 1 | Monday | 0-53 | 该年包含超过 3 天 | | 2 | Sunday | 1-53 | 该年包括一个星期天 | | 3 | Monday | 1-53 | 该年包含超过 3 天 | | 4 | Sunday | 0-53 | 该年包含超过 3 天 | | 5 | Monday | 0-53 | 该年包括一个星期一 | | 6 | Sunday | 1-53 | 该年包含超过 3 天 | | 7 | Monday | 1-53 | 该年包括一个星期一 | mysql SELECT WEEK(1998-02-20);+---------------------------------------------------------+| WEEK(1998-02-20) |+---------------------------------------------------------+| 7 |+---------------------------------------------------------+1 row in set (0.00 sec) WEEKDAY(date) 返回 date 是其所在星期的第几天 (0 Monday, 1 Tuesday, . 6 Sunday)。 mysql SELECT WEEKDAY(1998-02-03 22:23:00);+---------------------------------------------------------+| WEEKDAY(1998-02-03 22:23:00) |+---------------------------------------------------------+| 1 |+---------------------------------------------------------+1 row in set (0.00 sec) WEEKOFYEAR(date) 返回 date 所在的周是当年的第几周，范围从 1 到 53. WEEKOFYEAR() 是一个兼容性函数，其功能同 WEEK(date, 3)相同。 mysql SELECT WEEKOFYEAR(1998-02-20);+---------------------------------------------------------+| WEEKOFYEAR(1998-02-20) |+---------------------------------------------------------+| 8 |+---------------------------------------------------------+1 row in set (0.00 sec) YEAR(date) 返回 date 的年份部分，范围为 1000 到 9999，对于日期 0 则返回 0。 mysql SELECT YEAR(98-02-03);+---------------------------------------------------------+| YEAR(98-02-03) |+---------------------------------------------------------+| 1998 |+---------------------------------------------------------+1 row in set (0.00 sec) YEARWEEK(date), YEARWEEK(date,mode) 返回 date 所在的年份和周数。mode 参数意义与 WEEK() 函数的完全一样。对于一年中的第一周和最后一周来说，结果中的年份可能会和 date 参数中的年份不同。 mysql SELECT YEARWEEK(1987-01-01);+---------------------------------------------------------+| YEAR(98-02-03)YEARWEEK(1987-01-01) |+---------------------------------------------------------+| 198653 |+---------------------------------------------------------+1 row in set (0.00 sec) 注意，这里的周数同 WEEK() 返回的不同，因为 WEEK() 函数的返回值在给定年份的的上下文环境中得出。"},{"title":"SQL SUM() 函数","path":"/wiki/sql/function/sum.html","content":"SQL SUM() 函数 SUM() 函数返回数字列的总和。 SQL SUM() 语法SELECT SUM(column_name)FROM table_nameWHERE condition; 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “OrderDetails” 表的数据： OrderDetailID OrderID ProductID Quantity 1 10248 11 12 2 10248 42 10 3 10248 72 5 4 10249 14 9 5 10249 51 40 SQL SUM() 实例 下面的 SQL 语句查找 “OrderDetails” 表的 “Quantity” 字段的总数： 示例 SELECT SUM(Quantity)FROM OrderDetails;"},{"title":"SQL FIELD()函数","path":"/wiki/sql/function/field.html","content":"SQL FIELD()函数 SQL FIELD()函数实例代码教程 FIELD()函数返回的索引（从1开始的位置）的str在str1，str2，str3，…列表中。如果str没有找到，则返回0。　就是用第一个参数str，跟后面的N个字符串参数中寻找，如果寻找到一模一样的字符串，则返回其索引位置 FIELD(str,str1,str2,str3,…) 返回的索引（从1开始的位置）的str在str1，str2，str3，…列表中。如果str没有找到，则返回0。 例子在第2个位置找到了字符串”ej” SQL SELECT FIELD(ej, Hej, ej, Heja, hej, foo); +---------------------------------------------------------+ | FIELD(ej, Hej, ej, Heja, hej, foo) | +---------------------------------------------------------+ | 2 | +---------------------------------------------------------+ 1 row in set (0.00 sec)"},{"title":"SQL CONCAT()函数","path":"/wiki/sql/function/concat.html","content":"SQL CONCAT 函数 **　CONCAT** 函数用于将两个字符串连接为一个字符串，试一下下面这个例子： SQL SELECT CONCAT(FIRST , SECOND);+----------------------------+| CONCAT(FIRST , SECOND) |+----------------------------+| FIRST SECOND |+----------------------------+1 row in set (0.00 sec) 要对 CONCAT 函数有更为深入的了解，请考虑 employee_tbl 表，表中记录如下所示： SQL SELECT * FROM employee_tbl;+------+------+------------+--------------------+| id | name | work_date | daily_typing_pages |+------+------+------------+--------------------+| 1 | John | 2007-01-24 | 250 || 2 | Ram | 2007-05-27 | 220 || 3 | Jack | 2007-05-06 | 170 || 3 | Jack | 2007-04-06 | 100 || 4 | Jill | 2007-04-06 | 220 || 5 | Zara | 2007-06-06 | 300 || 5 | Zara | 2007-02-06 | 350 |+------+------+------------+--------------------+7 rows in set (0.00 sec) 现在，假设你想要将上表中所有的姓名（name）、id和工作日（work_date）连接在一起，那么可以通过如下的命令来达到目的： SQL SELECT CONCAT(id, name, work_date) - FROM employee_tbl;+-----------------------------+| CONCAT(id, name, work_date) |+-----------------------------+| 1John2007-01-24 || 2Ram2007-05-27 || 3Jack2007-05-06 || 3Jack2007-04-06 || 4Jill2007-04-06 || 5Zara2007-06-06 || 5Zara2007-02-06 |+-----------------------------+7 rows in set (0.00 sec)"},{"title":"SQL 字母大小写转换函数","path":"/wiki/sql/function/case.html","content":"SQL 字母大小写转换函数 SQL 字母大小写转换函数包含了UPPER(s)、UCASE(s)、LOWER(s)和LCASE(s)函数。 1、LOWER(s)函数和LCASE(s)函数LOWER(s)或者LCASE(s)函数可以将字符串s中的字母字符全部转换成小写字母。 **　实例：** 使用LOWER函数或者LCASE函数将字符串中所有字母字符转换为小写。SQL语句如下： SELECT LOWER(WWW.ngrok.cn),LCASE(ngrok.CN); 执行结果如下： 2、UPPER(s)函数和UCASE(s)函数UPPER(s)或UCASE(s)函数可以将字符串s中的字母字符全部转换成大写字母。**　实例：**　使用UPPER函数或者UCASE函数将字符串中的所有字母字符转换为大写。SQL语句如下： SELECT UPPER(www.ngrok.cn),UCASE(ngrok);"},{"title":"SQL FIRST()函数","path":"/wiki/sql/function/first.html","content":"SQL FIRST() 函数 FIRST() 函数返回指定的列中第一个记录的值。 SQL FIRST() 语法SELECT FIRST(column_name) FROM table_name; **注释：**只有 MS Access 支持 FIRST() 函数。 SQL Server、MySQL 和 Oracle 中的 SQL FIRST() 工作区 SQL Server 语法示例 SELECT TOP 1 column_nameFROM table_nameORDER BY column_name ASC; 示例 SELECT TOP 1 CustomerName FROM Customers ORDER BY CustomerID ASC; MySQL 语法示例 SELECT column_name FROM table_name ORDER BY column_name ASC LIMIT 1; 示例 SELECT CustomerName FROM Customers ORDER BY CustomerID ASC LIMIT 1; Oracle 语法SELECT column_name FROM table_name ORDER BY column_name ASC WHERE ROWNUM =1; 实例SELECT CustomerName FROM Customers ORDER BY CustomerID ASC WHERE ROWNUM =1; 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “Customers” 表的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL FIRST() 实例 下面的 SQL 语句选取 “Customers” 表的 “CustomerName” 列中第一个记录的值： 示例 SELECT FIRST(CustomerName) AS FirstCustomer FROM Customers;"},{"title":"SQL FORMAT()函数","path":"/wiki/sql/function/format.html","content":"SQL FORMAT() 函数 FORMAT() 函数用于对字段的显示进行格式化。 SQL FORMAT() 语法SELECT FORMAT(column_name,format) FROM table_name; 参数 描述 column_name 必需。要格式化的字段。 format 必需。规定格式。 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “Products” 表的数据： ProductID ProductName SupplierID CategoryID Unit Price 1 Chais 1 1 10 boxes x 20 bags 18 2 Chang 1 1 24 - 12 oz bottles 19 3 Aniseed Syrup 1 2 12 - 550 ml bottles 10 4 Chef Anton’s Cajun Seasoning 2 2 48 - 6 oz jars 21.35 5 Chef Anton’s Gumbo Mix 2 2 36 boxes 25 SQL FORMAT() 实例 下面的 SQL 语句从 “Products” 表中选取产品名称以及当天（格式化为 YYYY-MM-DD）的价格： 示例 SELECT ProductName, Price, FORMAT(Now(),YYYY-MM-DD) AS PerDateFROM Products;"},{"title":"SQL GROUP BY()函数","path":"/wiki/sql/function/groupby.html","content":"SQL GROUP BY 语句 Aggregate 函数常常需要添加 GROUP BY 语句。 GROUP BY语句通常与集合函数（COUNT，MAX，MIN，SUM，AVG）一起使用，以按一个或多个列对结果集进行分组。 GROUP BY 语句 GROUP BY 语句用于结合 Aggregate 函数，根据一个或多个列对结果集进行分组。 SQL GROUP BY 语法SELECT column_name(s)FROM table_nameWHERE conditionGROUP BY column_name(s)ORDER BY column_name(s); 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “Customers”表的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL GROUP BY示例 以下SQL语句列出了每个国家地区的客户数量： SELECT COUNT(CustomerID), CountryFROM CustomersGROUP BY Country; 以下SQL语句列出每个国家的客户数量，从高到低排序： SELECT COUNT(CustomerID), CountryFROM CustomersGROUP BY CountryORDER BY COUNT(CustomerID) DESC; 演示数据库 以下是罗斯文示例数据库中”订单”表的一个选择： OrderID CustomerID EmployeeID OrderDate ShipperID 10248 90 5 1996-07-04 3 10249 81 6 1996-07-05 1 10250 34 4 1996-07-08 2 并从”Shippers”表中选择： ShipperID ShipperName 1 Speedy Express 2 United Package 3 Federal Shipping GROUP BY使用JOIN示例 以下SQL语句列出了每个发货人发送的订单数量： SELECT Shippers.ShipperName, COUNT(Orders.OrderID) AS NumberOfOrders FROM OrdersLEFT JOIN Shippers ON Orders.ShipperID = Shippers.ShipperIDGROUP BY ShipperName;"},{"title":"SQL HAVING函数","path":"/wiki/sql/function/having.html","content":"SQL HAVING 子句 在 SQL 中增加 HAVING 子句原因是，WHERE 关键字无法与 Aggregate 函数一起使用。 HAVING子句已添加到SQL中，因为WHERE关键字不能用于聚合函数。 SQL HAVING 语法SELECT column_name(s)FROM table_nameWHERE conditionGROUP BY column_name(s)HAVING conditionORDER BY column_name(s); 演示数据库 以下是罗斯文示例数据库中”Customers”表的选择： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL HAVING示例 以下SQL语句列出了每个国家地区的客户数量。只包括超过5位客户的国家地区： SELECT COUNT(CustomerID), CountryFROM CustomersGROUP BY CountryHAVING COUNT(CustomerID) 5; 以下SQL语句列出每个国家的客户数量，从高到低排序（仅包括拥有超过5名客户的国家地区）： SELECT COUNT(CustomerID), CountryFROM CustomersGROUP BY CountryHAVING COUNT(CustomerID) 5ORDER BY COUNT(CustomerID) DESC; 演示数据库 以下是罗斯文示例数据库中”Orders”表的一个选择： OrderID CustomerID EmployeeID OrderDate ShipperID 10248 90 5 1996-07-04 3 10249 81 6 1996-07-05 1 10250 34 4 1996-07-08 2 并从”Employees”表中选择： EmployeeID LastName FirstName BirthDate Photo Notes 1 Davolio Nancy 1968-12-08 EmpID1.pic Education includes a BA…. 2 Fuller Andrew 1952-02-19 EmpID2.pic Andrew received his BTS…. 3 Leverling Janet 1963-08-30 EmpID3.pic Janet has a BS degree…. 更多HAVING示例 以下SQL语句列出已注册超过10个订单的员工： SELECT Employees.LastName, COUNT(Orders.OrderID) AS NumberOfOrdersFROM OrdersINNER JOIN Employees ON Orders.EmployeeID = Employees.EmployeeIDGROUP BY LastNameHAVING COUNT(Orders.OrderID) 10; 以下SQL语句列出员工”Davolio”或”Fuller”是否已注册超过25个订单： SELECT Employees.LastName, COUNT(Orders.OrderID) AS NumberOfOrdersFROM OrdersINNER JOIN Employees ON Orders.EmployeeID = Employees.EmployeeIDWHERE LastName = Davolio OR LastName = FullerGROUP BY LastNameHAVING COUNT(Orders.OrderID) 25;"},{"title":"SQL LAST()函数","path":"/wiki/sql/function/last.html","content":"SQL LAST() 函数 LAST() 函数返回指定的列中最后一个记录的值。 SQL LAST() 语法SELECT LAST(column_name) FROM table_name; **注释：**只有 MS Access 支持 LAST() 函数。 SQL Server、MySQL 和 Oracle 中的 SQL LAST() 工作区 SQL Server 语法示例 SELECT TOP 1 column_nameFROM table_nameORDER BY column_name DESC; 示例 SELECT TOP 1 CustomerName FROM Customers ORDER BY CustomerID DESC; MySQL 语法示例 SELECT column_name FROM table_name ORDER BY column_name DESC LIMIT 1; 示例 SELECT CustomerName FROM Customers ORDER BY CustomerID DESC LIMIT 1; Oracle 语法示例 SELECT column_name FROM table_name ORDER BY column_name DESC WHERE ROWNUM =1; 示例 SELECT CustomerName FROM Customers ORDER BY CustomerID DESC WHERE ROWNUM =1; 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “Customers” 表的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL LAST() Example 下面的 SQL 语句选取 “Customers” 表的 “CustomerName” 列中最后一个记录的值： 示例 SELECT LAST(CustomerName) AS LastCustomer FROM Customers;"},{"title":"SQL LCASE()函数","path":"/wiki/sql/function/lcase.html","content":"SQL LCASE() 函数 LCASE() 函数把字段的值转换为小写。 SQL LCASE() 语法SELECT LCASE(column_name) FROM table_name; 用于 SQL Server 的语法SELECT LOWER(column_name) FROM table_name; 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “Customers” 表的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL LCASE() 实例 下面的 SQL 语句从 “Customers” 表中选取 “CustomerName” 和 “City” 列，并把 “CustomerName” 列的值转换为小写： 示例 SELECT LCASE(CustomerName) AS Customer, CityFROM Customers;"},{"title":"SQL LEN()函数","path":"/wiki/sql/function/len.html","content":"SQL LEN() 函数 LEN() 函数返回文本字段中值的长度。 SQL LEN() 语法SELECT LEN(column_name) FROM table_name; 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “Customers” 表的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL LEN() 实例 下面的 SQL 语句从 “Customers” 表中选取 “CustomerName” 和 “Address” 列中值的长度： 示例 SELECT CustomerName,LEN(Address) as LengthOfAddressFROM Customers;"},{"title":"SQL LOWER()函数","path":"/wiki/sql/function/lower.html","content":"SQL LOWER()函数 SQL lower()字母大小写转换函数，将字母转成小写 - 返回根据当前字符集映射所有字符改变为小写，即返回小写的字符串。 LOWER(str)返回根据当前字符集映射所有字符改变为小写，即返回小写的字符串。 SQL SELECT LOWER(ngrok); +---------------------------------------------------------+ | LOWER(ngrok) | +---------------------------------------------------------+ | ngrok | +---------------------------------------------------------+ 1 row in set (0.00 sec)"},{"title":"SQL MID()函数","path":"/wiki/sql/function/mid.html","content":"SQL MID() 函数 MID() 函数用于从文本字段中提取字符。 SQL MID() 语法SELECT MID(column_name,start[,length]) FROM table_name; 参数 描述 column_name 必需。要提取字符的字段。 start 必需。规定开始位置（起始值是 1）。 length 可选。要返回的字符数。如果省略，则 MID() 函数返回剩余文本。 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “Customers” 表的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL MID() 实例 下面的 SQL 语句从 “Customers” 表的 “City” 列中提取前 4 个字符： 示例 SELECT MID(City,1,4) AS ShortCityFROM Customers;"},{"title":"SQL NOW()函数","path":"/wiki/sql/function/now.html","content":"SQL NOW() 函数 NOW() 函数返回当前系统的日期和时间。 SQL NOW() 语法SELECT NOW() FROM table_name; 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “Products” 表的数据： ProductID ProductName SupplierID CategoryID Unit Price 1 Chais 1 1 10 boxes x 20 bags 18 2 Chang 1 1 24 - 12 oz bottles 19 3 Aniseed Syrup 1 2 12 - 550 ml bottles 10 4 Chef Anton’s Cajun Seasoning 2 2 48 - 6 oz jars 21.35 5 Chef Anton’s Gumbo Mix 2 2 36 boxes 25 SQL NOW() 实例下面的 SQL 语句从 “Products” 表中选取产品名称以及当天的价格： 示例 SELECT ProductName, Price, Now() AS PerDateFROM Products;"},{"title":"SQL NULL()函数","path":"/wiki/sql/function/null.html","content":"SQL NULL 函数 SQL ISNULL()、NVL()、IFNULL() 和 COALESCE() 函数请看下面的 “Products” 表： P_Id ProductName UnitPrice UnitsInStock UnitsOnOrder 1 Jarlsberg 10.45 16 15 2 Mascarpone 32.56 23 3 Gorgonzola 15.67 9 20 假如 “UnitsOnOrder” 是可选的，而且可以包含 NULL 值。 我们使用下面的 SELECT 语句： SELECT ProductName,UnitPrice*(UnitsInStock+UnitsOnOrder) FROM Products 在上面的实例中，如果有 “UnitsOnOrder” 值是 NULL，那么结果是 NULL。 微软的 ISNULL() 函数用于规定如何处理 NULL 值。 NVL()、IFNULL() 和 COALESCE() 函数也可以达到相同的结果。 在这里，我们希望 NULL 值为 0。 下面，如果 “UnitsOnOrder” 是 NULL，则不会影响计算，因为如果值是 NULL 则 ISNULL() 返回 0： SQL Server MS AccessSELECT ProductName,UnitPrice*(UnitsInStock+ISNULL(UnitsOnOrder,0)) FROM Products OracleOracle 没有 ISNULL() 函数。不过，我们可以使用 NVL() 函数达到相同的结果： SELECT ProductName,UnitPrice*(UnitsInStock+NVL(UnitsOnOrder,0)) FROM Products MySQLMySQL 也拥有类似 ISNULL() 的函数。不过它的工作方式与微软的 ISNULL() 函数有点不同。 在 MySQL 中，我们可以使用 IFNULL() 函数，如下所示： SELECT ProductName,UnitPrice*(UnitsInStock+IFNULL(UnitsOnOrder,0)) FROM Products 或者我们可以使用 COALESCE() 函数，如下所示： SELECT ProductName,UnitPrice*(UnitsInStock+COALESCE(UnitsOnOrder,0)) FROM Products"},{"title":"SQL RAND()函数","path":"/wiki/sql/function/rand.html","content":"SQL RAND 函数 SQL 有一个 RAND 函数，用于产生 0 至 1 之间的随机数： SQL SELECT RAND( ), RAND( ), RAND( );+------------------+-----------------+------------------+| RAND( ) | RAND( ) | RAND( ) |+------------------+-----------------+------------------+| 0.45464584925645 | 0.1824410643265 | 0.54826780459682 |+------------------+-----------------+------------------+1 row in set (0.00 sec) 当以某个整数值作为参数来调用的时候，RAND() 会将该值作为随机数发生器的种子。对于每一个给定的种子，RAND() 函数都会产生一列可以复现的数字： SQL SELECT RAND(1), RAND( ), RAND( );+------------------+------------------+------------------+| RAND(1 ) | RAND( ) | RAND( ) |+------------------+------------------+------------------+| 0.18109050223705 | 0.75023211143001 | 0.20788908117254 |+------------------+------------------+------------------+1 row in set (0.00 sec) 你可以使用 ORDER BY RAND() 来对一组记录进行随机化排列，如下所示： SQL SELECT * FROM employee_tbl;+------+------+------------+--------------------+| id | name | work_date | daily_typing_pages |+------+------+------------+--------------------+| 1 | John | 2007-01-24 | 250 || 2 | Ram | 2007-05-27 | 220 || 3 | Jack | 2007-05-06 | 170 || 3 | Jack | 2007-04-06 | 100 || 4 | Jill | 2007-04-06 | 220 || 5 | Zara | 2007-06-06 | 300 || 5 | Zara | 2007-02-06 | 350 |+------+------+------------+--------------------+7 rows in set (0.00 sec) 现在，试试下面的命令： SQL SELECT * FROM employee_tbl ORDER BY RAND();+------+------+------------+--------------------+| id | name | work_date | daily_typing_pages |+------+------+------------+--------------------+| 5 | Zara | 2007-06-06 | 300 || 3 | Jack | 2007-04-06 | 100 || 3 | Jack | 2007-05-06 | 170 || 2 | Ram | 2007-05-27 | 220 || 4 | Jill | 2007-04-06 | 220 || 5 | Zara | 2007-02-06 | 350 || 1 | John | 2007-01-24 | 250 |+------+------+------------+--------------------+7 rows in set (0.01 sec)SQL SELECT * FROM employee_tbl ORDER BY RAND();+------+------+------------+--------------------+| id | name | work_date | daily_typing_pages |+------+------+------------+--------------------+| 5 | Zara | 2007-02-06 | 350 || 2 | Ram | 2007-05-27 | 220 || 3 | Jack | 2007-04-06 | 100 || 1 | John | 2007-01-24 | 250 || 4 | Jill | 2007-04-06 | 220 || 3 | Jack | 2007-05-06 | 170 || 5 | Zara | 2007-06-06 | 300 |+------+------+------------+--------------------+7 rows in set (0.00 sec)"},{"title":"SQL REPLACE()函数","path":"/wiki/sql/function/replace.html","content":"SQL REPLACE()字符串替换函数 实例把数据库表 article中的所有title字段里的 ngrok字符串替换成hello。 update `article` set title=replace(title,ngrok,hello); replace函数定义replace(original-string，search-string，replace-string) 参数 original-string： 被搜索的字符串。可为任意长度。 search-string： 要搜索并被 replace-string 替换的字符串。该字符串的长度不应超过 255 个字节。如果 search-string 是空字符串，则按原样返回原始字符串。 replace-string： 该字符串用于替换 search-string。可为任意长度。如果 replace-string 是空字符串，则删除出现的所有 search-string。 说明用字符串表达式3替换字符串表达式1中出现的所有字符串表达式2的匹配项。返回新的字符串。　如果有某个参数为 NULL，此函数返回 NULL。"},{"title":"SQL ROUND()函数","path":"/wiki/sql/function/round.html","content":"SQL ROUND() 函数 ROUND() 函数用于把数值字段舍入为指定的小数位数。 SQL ROUND() 语法SELECT ROUND(column_name,decimals) FROM table_name; 参数 描述 column_name 必需。要舍入的字段。 decimals 必需。规定要返回的小数位数。 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “Products” 表的数据： ProductID ProductName SupplierID CategoryID Unit Price 1 Chais 1 1 10 boxes x 20 bags 18 2 Chang 1 1 24 - 12 oz bottles 19 3 Aniseed Syrup 1 2 12 - 550 ml bottles 10 4 Chef Anton’s Cajun Seasoning 2 2 48 - 6 oz jars 21.35 5 Chef Anton’s Gumbo Mix 2 2 36 boxes 25 SQL ROUND() 实例 下面的 SQL 语句从 “Products” 表中选取产品名称和价格舍入为最接近的整数 (提取前 4 个字符)： 示例 SELECT ProductName, ROUND(Price,0) AS RoundedPriceFROM Products;"},{"title":"SQL SQRT()函数","path":"/wiki/sql/function/sqrt.html","content":"SQL SQRT 函数 **　SQRT** 函数用于计算得出任何数值的平方根。你可以像下面这样使用 SELECT 语句计算任何数值的平方根： SQL select SQRT(16);+----------+| SQRT(16) |+----------+| 4.000000 |+----------+1 row in set (0.00 sec) 你在这里看到的是浮点数，因为 SQL 以浮点数类型来进行平方根的计算。 你还可以使用 SQRT 函数来计算表中记录的平方根。要获得对 SQRT 函数更深入的了解，请考虑 employee_tbl 表，表中记录如下所示： SQL SELECT * FROM employee_tbl;+------+------+------------+--------------------+| id | name | work_date | daily_typing_pages |+------+------+------------+--------------------+| 1 | John | 2007-01-24 | 250 || 2 | Ram | 2007-05-27 | 220 || 3 | Jack | 2007-05-06 | 170 || 3 | Jack | 2007-04-06 | 100 || 4 | Jill | 2007-04-06 | 220 || 5 | Zara | 2007-06-06 | 300 || 5 | Zara | 2007-02-06 | 350 |+------+------+------------+--------------------+7 rows in set (0.00 sec) 现在，假设你想要获取每个记录中 daily_typing_pages 的平方根，那么你可以用如下命令来达到目的： SQL SELECT name, SQRT(daily_typing_pages) - FROM employee_tbl;+------+--------------------------+| name | SQRT(daily_typing_pages) |+------+--------------------------+| John | 15.811388 || Ram | 14.832397 || Jack | 13.038405 || Jack | 10.000000 || Jill | 14.832397 || Zara | 17.320508 || Zara | 18.708287 |+------+--------------------------+7 rows in set (0.00 sec)"},{"title":"SQL TRIM()函数","path":"/wiki/sql/function/trim.html","content":"SQL TRIM()函数去除字符串头尾空格 SQL 中的 TRIM 函数是用来移除掉一个字串中的字头或字尾。最常见的用途是移除字首或字尾的空白。这个函数在不同的资料库中有不同的名称： MySQL: TRIM( ), RTRIM( ), LTRIM( ) Oracle: RTRIM( ), LTRIM( ) SQL Server: RTRIM( ), LTRIM( ) 各种 trim 函数的语法如下： TRIM ( [ [位置] [要移除的字串] FROM ] 字串) : [位置] 的可能值为 LEADING (起头), TRAILING (结尾), or BOTH (起头及结尾)。 这个函数将把 [要移除的字串] 从字串的起头、结尾，或是起头及结尾移除。如果我们没有列出 [要移除的字串] 是什么的话，那空白就会被移除。 LTRIM(字串) : 将所有字串起头的空白移除。 RTRIM(字串) : 将所有字串结尾的空白移除。 例1 TRIM()SELECT TRIM( Sample ); 结果: Sample 例2 LTRIM()SELECT LTRIM( Sample ); 结果: Sample 例3 RTRIM()SELECT RTRIM( Sample ); 结果: Sample"},{"title":"SQL UCASE()函数","path":"/wiki/sql/function/ucase.html","content":"SQL UCASE() 函数 UCASE() 函数把字段的值转换为大写。 SQL UCASE() 语法SELECT UCASE(column_name) FROM table_name; 用于 SQL Server 的语法SELECT UPPER(column_name) FROM table_name; 演示数据库 在本教程中，我们将使用众所周知的 Northwind 样本数据库。 下面是选自 “Customers” 表的数据： CustomerID CustomerName ContactName Address City PostalCode Country 1 Alfreds Futterkiste Maria Anders Obere Str. 57 Berlin 12209 Germany 2 Ana Trujillo Emparedados y helados Ana Trujillo Avda. de la Constitución 2222 México D.F. 05021 Mexico 3 Antonio Moreno Taquería Antonio Moreno Mataderos 2312 México D.F. 05023 Mexico 4 Around the Horn Thomas Hardy 120 Hanover Sq. London WA1 1DP UK 5 Berglunds snabbköp Christina Berglund Berguvsvägen 8 Luleå S-958 22 Sweden SQL UCASE() 实例 下面的 SQL 语句从 “Customers” 表中选取 “CustomerName” 和 “City” 列，并把 “CustomerName” 列的值转换为大写： 示例 SELECT UCASE(CustomerName) AS Customer, CityFROM Customers;"},{"title":"SQL UPPER()函数","path":"/wiki/sql/function/upper.html","content":"SQL UPPER()函数 SQL upper()函数字母大小写转换函数，将字母转成大写 - 返回字符串str，根据当前字符集映射的所有字符更改为大写。 UPPER(str)返回字符串str，根据当前字符集映射的所有字符更改为大写。 SQL SELECT UPPER(Allah-hus-ngrok); +---------------------------------------------------------+ | UPPER(Allah-hus-ngrok) | +---------------------------------------------------------+ | ALLAH-HUS-ngrok | +---------------------------------------------------------+ 1 row in set (0.00 sec)"},{"title":"SQL HAVING 子句","path":"/wiki/sql/sentence/hav.html","content":"SQL HAVING 子句 HAVING 子句使你能够指定过滤条件，从而控制查询结果中哪些组可以出现在最终结果里面。 WHERE 子句对被选择的列施加条件，而 HAVING 子句则对 GROUP BY 子句所产生的组施加条件。 语法下面可以看到 HAVING 子句在 SEL ECT 查询中的位置： SELECTFROMWHEREGROUP BYHAVINGORDER BY 在 SELECT 查询中，HAVING 子句必须紧随 GROUP BY 子句，并出现在 ORDER BY 子句（如果有的话）之前。带有 HAVING 子句的 SELECT 语句的语法如下所示： SELECT column1, column2 FROM table1, table2WHERE [ conditions ]GROUP BY column1, column2HAVING [ conditions ]ORDER BY column1, column2 示例 考虑 CUSTOMERS 表，表中的记录如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | 4500.00 || 7 | Muffy | 24 | Indore | 10000.00 |+----+----------+-----+-----------+----------+ 下面是一个有关 HAVING 子句使用的实例，该实例将会筛选出出现次数大于或等于 2 的所有记录。 SQL SELECT ID, NAME, AGE, ADDRESS, SALARYFROM CUSTOMERSGROUP BY ageHAVING COUNT(age) = 2; 其执行结果如下所示： +----+----------+-----+---------+---------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+---------+---------+| 2 | Khilan | 25 | Delhi | 1500.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 |+----+----------+-----+---------+---------+ SQL HAVING 实例现在我们想要查找总访问量大于 200 的网站。 我们使用下面的 SQL 语句： 示例 SELECT Websites.name, Websites.url, SUM(access_log.count) AS nums FROM (access_log INNER JOIN Websites ON access_log.site_id=Websites.id) GROUP BY Websites.name HAVING SUM(access_log.count) 200; 执行以上 SQL 输出结果如下： 现在我们想要查找总访问量大于 200 的网站，并且 alexa 排名小于 200。 我们在 SQL 语句中增加一个普通的 WHERE 子句： 示例 SELECT Websites.name, SUM(access_log.count) AS nums FROM Websites INNER JOIN access_log ON Websites.id=access_log.site_id WHERE Websites.alexa 200 GROUP BY Websites.name HAVING SUM(access_log.count) 200;"},{"title":"SQL 空值","path":"/wiki/sql/sentence/kongzhi.html","content":"什么是SQL NULL值？ SQL 中，NULL 用于表示缺失的值。数据表中的 NULL 值表示该值所处的字段为空。 具有NULL值的字段是没有值的字段。 如果表中的字段是可选的，则可以插入新记录或更新记录而不向该字段添加值。然后，该字段将被保存为NULL值。 值为 NULL 的字段没有值。尤其要明白的是，NULL 值与 0 或者包含空白（spaces）的字段是不同的。 注意：理解NULL值与零值或包含空格的字段不同是非常重要的。具有NULL值的字段是在记录创建期间留空的字段！ 如何测试NULL值？ 使用比较运算符（例如，或）来测试NULL值是不可行的。 我们将不得不使用IS NULL和IS NOT NULL运算符。 IS NULL语法SELECT column_namesFROM table_nameWHERE column_name IS NULL; IS NOT NULL语法SELECT column_namesFROM table_nameWHERE column_name IS NOT NULL; 演示数据库 假设我们有以下的”人员”表： ID LastName FirstName Address City 1 Doe John 542 W. 27th Street New York 2 Bloggs Joe London 3 Roe Jane New York 4 Smith John 110 Bishopsgate London 假设”人员”表中的”Address”列是可选的。如果插入的记录没有”Address”值，则”Address”列将以空值保存。 IS NULL运算符 以下SQL语句使用IS NULL运算符来列出所有没有地址的人员： SELECT LastName, FirstName, Address FROM PersonsWHERE Address IS NULL; 结果集将如下所示： LastName FirstName Address Bloggs Joe Roe Jane 提示：始终使用IS NULL来查找空值。 IS NOT NULL运算符 以下SQL语句使用IS NOT NULL运算符来列出所有具有地址的人员： SELECT LastName, FirstName, Address FROM PersonsWHERE Address IS NOT NULL; 结果集将如下所示： LastName FirstName Address Doe John 542 W. 27th Street Smith John 110 Bishopsgate 语法： 创建表的时候，NULL 的基本语法如下： SQL CREATE TABLE CUSTOMERS( ID INT NOT NULL, NAME VARCHAR (20) NOT NULL, AGE INT NOT NULL, ADDRESS CHAR (25) , SALARY DECIMAL (18, 2), PRIMARY KEY (ID)); 这里，NOT NULL表示对于给定列，必须按照其数据类型明确赋值。有两列并没有使用 NOT NULL 来限定，也就是说这些列可以为 NULL。 值为 NULL 的字段是在记录创建的过程中留空的字段。 示例： NULL 值会给选取数据带来麻烦。不过，因为 NULL 和其他任何值作比较，其结果总是未知的，所以含有 NULL 的记录不会包含在最终结果里面。 必须使用 IS NULL 或者 IS NOT NULL 来检测某个字段是否为 NULL。 考虑下面的 CUSTOMERS 数据表，里面包含的记录如下所示： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 || 6 | Komal | 22 | MP | || 7 | Muffy | 24 | Indore | |+----+----------+-----+-----------+----------+ 下面是 IS NOT NULL 运算符的用法： SQL SELECT ID, NAME, AGE, ADDRESS, SALARY FROM CUSTOMERS WHERE SALARY IS NOT NULL; 上面语句的运行结果如下： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 1 | Ramesh | 32 | Ahmedabad | 2000.00 || 2 | Khilan | 25 | Delhi | 1500.00 || 3 | kaushik | 23 | Kota | 2000.00 || 4 | Chaitali | 25 | Mumbai | 6500.00 || 5 | Hardik | 27 | Bhopal | 8500.00 |+----+----------+-----+-----------+----------+ 下面是 IS NULL 运算符的用法： SQL SELECT ID, NAME, AGE, ADDRESS, SALARY FROM CUSTOMERS WHERE SALARY IS NULL; 其运行结果如下： +----+----------+-----+-----------+----------+| ID | NAME | AGE | ADDRESS | SALARY |+----+----------+-----+-----------+----------+| 6 | Komal | 22 | MP | || 7 | Muffy | 24 | Indore | |+----+----------+-----+-----------+----------+"},{"title":"全面解析SQL存储过程","path":"/wiki/sql/summary/storage.html","content":"全面解析SQL存储过程 存储过程(Stored Procedure),是一组为了完成特定功能的SQL 语句，类似一门程序设计语言，也包括了数据类型、流程控制、输入和输出和它自己的函数库。存储过程可以说是一个记录集，它是由一些T-SQL语句组成的代码块，这些T-SQL语句代码像一个方法一样实现一些功能（对单表或多表的增删改查），然后再给这个代码块取一个名字，在用到这个功能的时候调用他就行了。不过SQL存储过程对于一些初学者来说还是比较抽象难理解的，因此本文将由浅至深地剖析SQL存储过程，帮助你学习它。 存储过程的优点 存储过程只在创造时进行编译，以后每次执行存储过程都不需再重新编译，而一般SQL语句每执行一次就编译一次,所以使用存储过程可提高数据库执行速度，效率要比T-SQL语句高。 当对数据库进行复杂操作时，可将此复杂操作用存储过程封装起来与数据库提供的事务处理结合一起使用。 一个存储过程在程序在网络中交互时可以替代大堆的T-SQL语句，所以也能降低网络的通信量，提高通信速率。 存储过程可以重复使用,可减少数据库开发人员的工作量。 安全性高,可设定只有某些用户才具有对指定存储过程的使用权 存储过程基本语法--------------创建存储过程-----------------CREATE PROC [ EDURE ] procedure_name [ ; number ] [ @parameter data_type [ VARYING ] [ = default ] [ OUTPUT ] ] [ ,...n ][ WITH RECOMPILE | ENCRYPTION | RECOMPILE , ENCRYPTION ][ FOR REPLICATION ]AS sql_statement [ ...n ]--------------调用存储过程-----------------EXECUTE Procedure_name --存储过程如果有参数，后面加参数格式为：@参数名=value，也可直接为参数值value--------------删除存储过程-----------------drop procedure procedure_name --在存储过程中能调用另外一个存储过程，而不能删除另外一个存储过程 创建存储过程的参数 procedure_name ：存储过程的名称，在前面加#为局部临时存储过程，加##为全局临时存储过程。 number：是可选的整数，用来对同名的过程分组，以便用一条 DROP PROCEDURE 语句即可将同组的过程一起除去。例如，名为 orders 的应用程序使用的过程可以命名为 orderproc;1、orderproc;2 等。DROP PROCEDURE orderproc 语句将除去整个组。如果名称中包含定界标识符，则数字不应包含在标识符中，只应在 procedure_name 前后使用适当的定界符。 @parameter：存储过程的参数。可以有一个或多个。用户必须在执行过程时提供每个所声明参数的值（除非定义了该参数的默认值）。存储过程最多可以有 2100 个参数。使用 @ 符号作为第一个字符来指定参数名称。参数名称必须符合标识符的规则。每个过程的参数仅用于该过程本身；相同的参数名称可以用在其它过程中。默认情况下，参数只能代替常量，而不能用于代替表名、列名或其它数据库对象的名称。有关更多信息，请参见 EXECUTE。 data_type：参数的数据类型。所有数据类型（包括 text、ntext 和 image）均可以用作存储过程的参数。不过，cursor 数据类型只能用于 OUTPUT 参数。如果指定的数据类型为 cursor，也必须同时指定 VARYING 和 OUTPUT 关键字。有关 SQL Server 提供的数据类型及其语法的更多信息，请参见数据类型。说明对于可以是 cursor 数据类型的输出参数，没有最大数目的限制。 VARYING：指定作为输出参数支持的结果集（由存储过程动态构造，内容可以变化）。仅适用于游标参数。 default： 参数的默认值。如果定义了默认值，不必指定该参数的值即可执行过程。默认值必须是常量或 NULL。如果过程将对该参数使用 LIKE 关键字，那么默认值中可以包含通配符（%、_、[] 和 [^]）。 OUTPUT：表明参数是返回参数。该选项的值可以返回给 EXEC[UTE]。使用 OUTPUT 参数可将信息返回给调用过程。Text、ntext 和 image 参数可用作 OUTPUT 参数。使用 OUTPUT 关键字的输出参数可以是游标占位符。 RECOMPILE: 表明 SQL Server 不会缓存该过程的计划，该过程将在运行时重新编译。在使用非典型值或临时值而不希望覆盖缓存在内存中的执行计划时，请使用 RECOMPILE 选项。 ENCRYPTION: 表示 SQL Server 加密 syscomments 表中包含 CREATE PROCEDURE 语句文本的条目。使用 ENCRYPTION 可防止将过程作为 SQL Server 复制的一部分发布。 说明在升级过程中，SQL Server 利用存储在 syscomments 中的加密注释来重新创建加密过程。 FOR REPLICATION:指定不能在订阅服务器上执行为复制创建的存储过程。.使用 FOR REPLICATION 选项创建的存储过程可用作存储过程筛选，且只能在复制过程中执行。本选项不能和 WITH RECOMPILE 选项一起使用。 AS:指定过程要执行的操作。 sql_statement:过程中要包含的任意数目和类型的 Transact-SQL 语句。但有一些限制。 实例操作学习 下面通过表Student来具体了解一下存储过程，因为是要了解存储过程的简单用法，所以例子很简单。 无参数存储过程选出Student表中的所有信息 create proc StuProcas //此处 as 不可以省略不写begin //begin 和 end 是一对，不可以只写其中一个，但可以都不写select S#,Sname,Sage,Ssex from studentendgo 有参数存储过程**　全局变量** 全局变量也称为外部变量，是在函数的外部定义的，它的作用域为从变量定义处开始，到本程序文件的末尾。 选出指定姓名的学生信息: create proc StuProc@sname varchar(100) as beginselect S#,Sname,Sage,Ssex from student where sname=@snameendgoexec StuProc 赵雷 //执行语句 上面是在外部给变量赋值，也可以在内部直接给变量设置默认值 create proc StuProc@sname varchar(100)=赵雷as beginselect S#,Sname,Sage,Ssex from student where sname=@snameendgoexec StuProc 也可以把变量的内容输出，使用output create proc StuProc@sname varchar(100),@IsRight int output //传出参数as if exists (select S#,Sname,Sage,Ssex from student where sname=@sname)set @IsRight =1elseset @IsRight=0godeclare @IsRight int exec StuProc 赵雷 , @IsRight outputselect @IsRight 以上是全局变量，下面来了解局部变量 **　局部变量** 局部变量也称为内部变量。局部变量是在函数内作定义说明的。其作用域仅限于函数内部，离开该函数后再使用这种变量是非法的。 **　局部变量的定义** 必须先用Declare命令定以后才可以使用，declare **　局部变量的赋值方法** set{@变量名表达式}或者select **　局部变量的显示** create proc StuProcas declare @sname varchar(100)set @sname=赵雷select S#,Sname,Sage,Ssex from student where sname=@snamegoexec StuProc 那如果是要把局部变量的数据显示出来怎么办呢？ create proc StuProcas declare @sname varchar(100)set @sname=(select Sname from student where S#=01)select @snamegoexec StuProc 更详细的实例操作学习 比如，在SQL Server查询编辑器窗口中用CREATE PROCEDURE语句创建存储过程PROC_InsertEmployee，用于实现向员工信息表（tb_Employee）中添加信息，同时生成自动编号。其SQL语句如下： IF EXISTS (SELECT name FROM sysobjects WHERE name = Proc_InsertEmployee AND type = P) DROP PROCEDURE Proc_InsertEmployee GO CREATE PROCEDURE Proc_InsertEmployee @PName nvarchar(50), @PSex nvarchar(4), @PAge int, @PWage money AS begin declare @PID nvarchar(50) select @PID=Max(员工编号) from tb_Employee if(@PID is null) set @PID=P1001 else set @PID=P+cast(cast(substring(@PID,2,4) as int)+1 as nvarchar(50)) begin insert into tb_Employee values(@PID,@PName,@PSex,@PAge,@PWage) end end go 存储过程的修改创建完存储过程之后，如果需要重新修改存储过程的功能及参数，可以在SQL Server 2005中通过以下两种方法进行修改：一种是用Microsoft SQL Server Mangement修改存储过程；另外一种是用T-SQL语句修改存储过程。 **　使用Microsoft SQL Server Mangement修改存储过程，步骤如下：**　（1）在SQL Server Management Studio的”对象资源管理器”中，选择要修改存储过程所在的数据库（如：db_18），然后在该数据库下，选择”可编程性”。　（2）打开”存储过程”文件夹，右键单击要修改的存储过程（如：PROC_SEINFO），在弹出的快捷菜单中选择”修改”命令，将会出现查询编辑器窗口。用户可以在此窗口中编辑T-SQL代码，完成编辑后，单击工具栏中的”执行（X）”按钮，执行修改代码。用户可以在查询编辑器下方的Message窗口中看到执行结果信息。 **　使用Transact-SQL修改存储过程：**　使用ALTER PROCEDURE语句修改存储过程，它不会影响存储过程的权限设定，也不会更改存储过程的名称。 语法： ALTER PROC [ EDURE ] procedure_name [ ; number ] [ @parameter data_type [ VARYING ] [ = default ] [ OUTPUT ] ] [ ,...n ] [ WITH RECOMPILE | ENCRYPTION | RECOMPILE , ENCRYPTION ] [ FOR REPLICATION ] AS sql_statement [ ...n ] 参数说明procedure_name：是要更改的存储过程的名称。 交叉链接：关于ALTER PROCEDURE语句的其他参数与CREATE PROCEDURE语句相同，可参见上面的”创建存储过程的参数”。 例如，修改存储过程PROC_SEINFO，用于查询年龄大于35的员工信息。SQL语句如下： ALTER PROCEDURE [dbo].[PROC_SEINFO] AS BEGIN SELECT * FROM tb_Employee where 员工年龄35 END 存储过程的删除**　使用Microsoft SQL Server Mangement删除存储过程，步骤如下：** （1）在SQL Server Management Studio的”对象资源管理器”中，选择要删除存储过程所在的数据库（如：db_student），然后在该数据库下选择”可编程性”。 （2）打开”存储过程”文件夹，右键单击要删除的存储过程（如：PROC_SEINFO），在弹出的快捷菜单中选择”删除”命令。 （3）单击”确定”按钮，即可删除所选定的存储过程。 **注意：**删除数据表后，并不会删除相关联的存储过程，只是其存储过程无法执行。 **　使用T-SQL删除存储过程：** DROP PROCEDURE语句用于从当前数据库中删除一个或多个存储过程或过程组。 语法： DROP PROCEDURE procedure [ ,...n ] 参数说明： Procedure：是要删除的存储过程或存储过程组的名称。过程名称必须符合标识符规则。可以选择是否指定过程所有者名称，但不能指定服务器名称和数据库名称。 n：是表示可以指定多个过程的占位符。 例如删除PROC_SEINFO存储过程的SQL语句如下。 DROP PROCEDURE PROC_SEINFO 例如，删除多个存储过程proc10、proc20和proc30。 DROP PROCEDURE proc10, proc20, proc30 例如，删除存储过程组procs（其中包含存储过程proc1、proc2、proc3）。 DROP PROCEDURE procs **注意：**SQL语句DROP不能删除存储过程组中的单个存储过程。 应用存储过程验证用户登录身份：目前，验证用户登录身份的方法有多种，而通过调用存储过程来实现用户身份验证是目前最好的解决方案之一。因为存储过程在创建时即在服务器上进行编译，所以执行起来比单个SQL语句要快得多。 本例是通过调用存储过程来验证用户登录的用户名和密码是否正确。运行本实例，在”用户名”和”密码”文本框中输入相应的用户名和密码，单击”登录”按钮即可。 程序开发步骤： （1）新建一个网站，将其命名为”index”，默认主页名为Default.aspx。 （2）Default.aspx页面涉及到的控件如表1所示。 （3）主要程序代码如下。　打开SQL Server Management Studio，并连接到SQL Server2005中的数据库。单击工具栏中” “按钮，新建查询编辑器。在该查询编辑器中，创建验证登录用户身份的存储过程PROC_EXISTS，具体的SQL语句如下： CREATE PROC PROC_EXISTS ( @UserName NVARCHAR(20), @PassWord NVARCHAR(20), @ReturnValue int OUTPUT ) AS IF EXISTS(select * from tb_member where userName=@UserName AND passWord=@PassWord) set @ReturnValue= 100 ELSE set @ReturnValue= -100 GO 在”登录”按钮的Click事件下，执行验证登录用户身份的存储过程，如果输入的用户名和密码正确，则弹出对话框提示用户登录成功，代码如下： protected void btnLogin_Click(object sender, EventArgs e) //连接数据库 myConn = new SqlConnection(ConfigurationManager.AppSettings[ConnectionString].ToString()); myCmd = new SqlCommand(PROC_EXISTS, myConn); //调用存储过程，判断用户是否存在 myCmd.CommandType = CommandType.StoredProcedure; //为存储过程的参数赋值 SqlParameter userName=new SqlParameter(@UserName, SqlDbType.NVarChar, 20); userName.Value=this.txtName.Text.Trim(); myCmd.Parameters.Add(userName); SqlParameter passWord=new SqlParameter(@PassWord, SqlDbType.NVarChar, 20); passWord.Value = this.txtPassword.Text.Trim(); myCmd.Parameters.Add(passWord); //指出该参数是存储过程的OUTPUT参数 SqlParameter ReturnValue = new SqlParameter(@ReturnValue,SqlDbType.Int ,4); ReturnValue.Direction = ParameterDirection.Output; myCmd.Parameters.Add(ReturnValue); try myConn.Open(); myCmd.ExecuteNonQuery(); if (int.Parse(ReturnValue.Value.ToString()) == 100) Response.Write(scriptalert(您是合法用户，登录成功！)/script); return; else Response.Write(scriptalert(您输入的用户名和密码不正确，请重新输入！)/script); return; catch(Exception ex) Response.Write(ex.Message.ToString()); finally myConn.Close(); myConn.Dispose(); myCmd.Dispose();"},{"title":"关于SQL学习过程","path":"/wiki/sql/summary/study.html","content":"我们已经学习了 SQL，下一步学习什么呢？ SQL 学习过程本 SQL 教程已经向您讲解了用来访问和处理数据库系统的标准计算机语言。 我们已经学习了如何使用 SQL 在数据库中执行查询、获取数据、插入新的记录、删除记录以及更新记录。 我们已经学习了如何通过 SQL 创建数据库、表、索引，以及如何撤销它们。 我们已经学习了 SQL 中最重要的 Aggregate 函数。 SQL 是一种与数据库系统协同工作的标准语言，这些数据库系统包括 MS SQL Server、IBM DB2、Oracle、MySQL 和 MS Access 等等。 关于SQL 主机选择 如果您想要您的网站存储数据在数据库并从数据库显示数据，您的 Web 服务器必须能使用 SQL 语言访问数据库系统。 如果您的 Web 服务器托管在互联网服务提供商（ISP，全称 Internet Service Provider），您必须寻找 SQL 主机计划。 最常见的 SQL 主机数据库是 MySQL、MS SQL Server 和 MS Access。 您可以在 Windows 和 LinuxUNIX 操作系统上运行 SQL 主机数据库。 下面是操作系统上对应运行的数据库系统的概览。 MS SQL Server只在 Windows OS 上运行。 MySQL在 Windows, Mac OS X 和 LinuxUNIX 操作系统上运行。 MS Access （只建议用于小型网站）只在 Windows OS 上运行。"},{"title":"SQL语句大全分类整理","path":"/wiki/sql/appendix/appendix.html","content":"详尽的SQL语句大全分类整理 Structured Query Language 即结构化查询语言，简称 SQL。SQL 是一种特殊目的的编程语言，是一种数据库查询和程序设计语言，用于存取数据以及查询、更新和管理关系数据库系统；同时也是数据库脚本文件的扩展名。SQL 语句的种类还和数量都很多，其中的很多语句也是经常要用到的，下面就把常用的 SQL 语句分类整理一下，并且还可以打包下载，希望能对你有所帮助。 先献上下载地址： 一、基础篇 1、说明：创建数据库CREATE DATABASE database-name 2、说明：删除数据库drop database dbname 3、说明：备份sql server— 创建 备份数据的 device USE masterEXEC sp_addumpdevice disk, testBack, c:\\mssql7backup\\MyNwind_1.dat — 开始 备份 BACKUP DATABASE pubs TO testBack 4、说明：创建新表create table tabname(col1 type1 [not null] [primary key],col2 type2 [not null],..) 根据已有的表创建新表：　A：create table tab_new like tab_old (使用旧表创建新表)　B ：create table tab_new as select col1,col2… from tab_old definition only 5、说明：删除新表drop table tabname 6、说明：增加一个列Alter table tabname add column col type **注：**列增加后将不能删除。DB2中列加上后数据类型也不能改变，唯一能改变的是增加varchar类型的长度。 7、说明：添加主键Alter table tabname add primary key(col) 删除主键： Alter table tabname drop primary key(col) 8、说明：创建索引create [unique] index idxname on tabname(col....) 删除索引： DROP INDEX index_name ON table_name **注：**索引是不可更改的，想更改必须删除重新建。 9、说明：创建视图create view viewname as select statement 删除视图： drop view viewname 10、说明：几个简单的sql语句 选择： select * from table1 where 范围 插入： insert into table1(field1,field2) values(value1,value2) 删除： delete from table1 where 范围 更新： update table1 set field1=value1 where 范围 查找： select * from table1 where field1 like %value1% —like 的语法很精妙，请查资料! 排序： select * from table1 order by field1,field2 [desc] 总数： select count as totalcount from table1 求和： select sum(field1) as sumvalue from table1 平均： select avg(field1) as avgvalue from table1 最大： select max(field1) as maxvalue from table1 最小： select min(field1) as minvalue from table1 11、说明：几个高级查询运算词**　A： UNION 运算符**　UNION 运算符通过组合其他两个结果表（例如 TABLE1 和 TABLE2）并消去表中任何重复行而派生出一个结果表。当 ALL 随 UNION一起使用时（即 UNION ALL），不消除重复行。两种情况下，派生表的每一行不是来自 TABLE1 就是来自 TABLE2。 **　B： EXCEPT 运算符** EXCEPT 运算符通过包括所有在 TABLE1 中但不在 TABLE2 中的行并消除所有重复行而派生出一个结果表。当 ALL 随 EXCEPT 一起使用时 (EXCEPT ALL)，不消除重复行。 **　C： INTERSECT 运算符** INTERSECT 运算符通过只包括 TABLE1 和 TABLE2 中都有的行并消除所有重复行而派生出一个结果表。当 ALL 随 INTERSECT 一起使用时 (INTERSECT ALL)，不消除重复行。 **注：**使用运算词的几个查询结果行必须是一致的。 12、说明：使用外连接**　A、left （outer） join：**　左外连接（左连接）：结果集几包括连接表的匹配行，也包括左连接表的所有行。　SQL: select a.a, a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a b.c **　B：right （outer） join:** 右外连接(右连接)：结果集既包括连接表的匹配连接行，也包括右连接表的所有行。 **　C：fullcross （outer） join：**　全外连接：不仅包括符号连接表的匹配行，还包括两个连接表中的所有记录。 13、分组:Group by:一张表，一旦分组 完成后，查询后只能得到组相关的信息。　组相关的信息：（统计信息） count,sum,max,min,avg 分组的标准)　在SQLServer中分组时：不能以 text,ntext,image类型的字段作为分组依据　在selecte统计函数中的字段，不能和普通的字段放在一起； 14、对数据库进行操作分离数据库： sp_detach_db; 附加数据库：sp_attach_db 后接表明，附加需要完整的路径名 15、如何修改数据库的名称sp_renamedb old_name, new_name 二、提升篇 1、说明：复制表(只复制结构,源表名：a 新表名：b) (Access可用) **　方法一：**（仅用于SQlServer） select * into b from a where 11 **　方法二：** select top 0 * into b from a 2、说明：拷贝表(拷贝数据,源表名：a 目标表名：b) (Access可用) insert into b(a, b, c) select d,e,f from a; 3、说明：跨数据库之间表的拷贝(具体数据使用绝对路径) (Access可用) insert into b(a, b, c) select d,e,f from b in 具体数据库 where 条件 例子： ..from b in Server.MapPath(.)\\data.mdb where.. 4、说明：子查询(表名1：a 表名2：b) select a,b,c from a where a IN (select d from b ) 或者: select a,b,c from a where a IN (1,2,3) 5、说明：显示文章、提交人和最后回复时间select a.title,a.username,b.adddate from table a,(select max(adddate) adddate from table where table.title=a.title) b 6、说明：外连接查询(表名1：a 表名2：b) select a.a, a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a = b.c 7、说明：在线视图查询(表名1：a ) select * from (SELECT a,b,c FROM a) T where t.a 1; 8、说明：between的用法between限制查询数据范围时包括了边界值,not between不包括 select * from table1 where time between time1 and time2 select a,b,c, from table1 where a not between 数值1 and 数值2 9、说明：in 的使用方法select * from table1 where a [not] in (值1,值2,值4,值6) 10、说明：两张关联表删除主表中已经在副表中没有的信息delete from table1 where not exists ( select * from table2 where table1.field1=table2.field1 ) 11、说明：四表联查问题select * from a left inner join b on a.a=b.b right inner join c on a.a=c.c inner join d on a.a=d.d where ...... 12、说明：日程安排提前五分钟提醒select * from 日程安排 where datediff(minute,f开始时间,getdate())5 13、说明：一条sql 语句搞定数据库分页select top 10 b.* from (select top 20 主键字段,排序字段 from 表名 order by 排序字段 desc) a,表名 b where b.主键字段 = a.主键字段 order by a.排序字段 **　具体实现：**　关于数据库分页： declare @start int,@end int@sql nvarchar(600)set @sql=select top+str(@end-@start+1)++from T where rid not in(select top+str(@str-1)+Rid from T where Rid-1)exec sp_executesql @sql **注意：**在top后不能直接跟一个变量，所以在实际应用中只有这样的进行特殊的处理。Rid为一个标识列，如果top后还有具体的字段，这样做是非常有好处的。因为这样可以避免 top的字段如果是逻辑索引的，查询的结果后实际表中的不一致（逻辑索引中的数据有可能和数据表中的不一致，而查询时如果处在索引则首先查询索引） 14、说明：查询前10条记录select top 10 * form table1 where 范围 15、说明：数据选择选择在每一组b值相同的数据中对应的a最大的记录的所有信息(类似这样的用法可以用于论坛每月排行榜,每月热销产品分析,按科目成绩排名,等等.) select a,b,c from tablename ta where a=(select max(a) from tablename tb where tb.b=ta.b) 16、说明：派生表包括所有在 TableA 中但不在 TableB和TableC 中的行并消除所有重复行而派生出一个结果表 (select a from tableA ) except (select a from tableB) except (select a from tableC) 17、说明：随机取出10条数据select top 10 * from tablename order by newid() 18、说明：随机选择记录select newid() 19、说明：删除重复记录**　1、** delete from tablename where id not in (select max(id) from tablename group by col1,col2,...) **　2、** select distinct * into temp from tablename delete from tablename insert into tablename select * from temp **评价：**这种操作牵连大量的数据的移动，这种做法不适合大容量但数据操作 3、 例如：在一个外部表中导入数据，由于某些原因第一次只导入了一部分，但很难判断具体位置，这样只有在下一次全部导入，这样也就产生好多重复的字段，怎样删除重复字段 alter table tablename --添加一个自增列 add column_b int identity(1,1) delete from tablename where column_b not in( select max(column_b) from tablename group by column1,column2,...) alter table tablename drop column column_b 20、说明：列出数据库里所有的表名select name from sysobjects where type=U // U代表用户 21、说明：列出表里的所有的列名select name from syscolumns where id=object_id(TableName) 22、说明：列示case列示type、vender、pcs字段，以type字段排列，case可以方便地实现多重选择，类似select 中的case。 select type,sum(case vender when A then pcs else 0 end),sum(case vender when C then pcs else 0 end),sum(case vender when B then pcs else 0 end) FROM tablename group by type 显示结果： type vender pcs电脑 A 1 电脑 A 1 光盘 B 2 光盘 A 2 手机 B 3 手机 C 3 23、说明：初始化表table1TRUNCATE TABLE table1 24、说明：选择从10到15的记录select top 5 * from (select top 15 * from table order by id asc) table_别名 order by id desc 三、技巧篇 1、SQL组合语句11，12的使用，在SQL语句组合时用的较多 **　“where 1** 1” 是表示选择全部 “where 12” 全部不选，　如： if @strWhere != beginset @strSQL = select count(*) as Total from [ + @tblName + ] where + @strWhere endelse beginset @strSQL = select count(*) as Total from [ + @tblName + ] end 我们可以直接写成： 错误！未找到目录项。set @strSQL = select count(*) as Total from [ + @tblName + ] where 1=1 安定+ @strWhere 2、收缩数据库--重建索引DBCC REINDEXDBCC INDEXDEFRAG--收缩数据和日志DBCC SHRINKDBDBCC SHRINKFILE 3、压缩数据库dbcc shrinkdatabase(dbname) 4、转移数据库给新用户以已存在用户权限exec sp_change_users_login update_one,newname,oldnamego 5、检查备份集RESTORE VERIFYONLY from disk=E:\\dvbbs.bak 6、修复数据库ALTER DATABASE [dvbbs] SET SINGLE_USERGODBCC CHECKDB(dvbbs,repair_allow_data_loss) WITH TABLOCKGOALTER DATABASE [dvbbs] SET MULTI_USERGO 7、日志清除SET NOCOUNT ONDECLARE @LogicalFileName sysname,@MaxMinutes INT,@NewSize INT USE tablename -- 要操作的数据库名SELECT @LogicalFileName = tablename_log, -- 日志文件名 @MaxMinutes = 10, -- Limit on time allowed to wrap log.@NewSize = 1 -- 你想设定的日志文件的大小(M)Setup / initializeDECLARE @OriginalSize intSELECT @OriginalSize = size FROM sysfilesWHERE name = @LogicalFileNameSELECT Original Size of + db_name() + LOG is + CONVERT(VARCHAR(30),@OriginalSize) + 8K pages or + CONVERT(VARCHAR(30),(@OriginalSize*8/1024)) + MBFROM sysfilesWHERE name = @LogicalFileNameCREATE TABLE DummyTrans(DummyColumn char (8000) not null) DECLARE @Counter INT,@StartTime DATETIME,@TruncLog VARCHAR(255)SELECT @StartTime = GETDATE(),@TruncLog = BACKUP LOG + db_name() + WITH TRUNCATE_ONLYDBCC SHRINKFILE (@LogicalFileName, @NewSize)EXEC (@TruncLog)-- Wrap the log if necessary.WHILE @MaxMinutes DATEDIFF (mi, @StartTime, GETDATE()) -- time has not expiredAND @OriginalSize = (SELECT size FROM sysfiles WHERE name = @LogicalFileName) AND (@OriginalSize * 8 /1024) @NewSize BEGIN -- Outer loop.SELECT @Counter = 0WHILE ((@Counter @OriginalSize / 16) AND (@Counter 50000))BEGIN -- updateINSERT DummyTrans VALUES (Fill Log) DELETE DummyTransSELECT @Counter = @Counter + 1ENDEXEC (@TruncLog) ENDSELECT Final Size of + db_name() + LOG is +CONVERT(VARCHAR(30),size) + 8K pages or + CONVERT(VARCHAR(30),(size*8/1024)) + MBFROM sysfiles WHERE name = @LogicalFileNameDROP TABLE DummyTransSET NOCOUNT OFF 8、说明：更改某个表exec sp_changeobjectowner tablename,dbo 9、存储更改全部表CREATE PROCEDURE dbo.User_ChangeObjectOwnerBatch@OldOwner as NVARCHAR(128),@NewOwner as NVARCHAR(128)ASDECLARE @Name as NVARCHAR(128)DECLARE @Owner as NVARCHAR(128)DECLARE @OwnerName as NVARCHAR(128)DECLARE curObject CURSOR FOR select Name = name,Owner = user_name(uid)from sysobjectswhere user_name(uid)=@OldOwnerorder by nameOPEN curObjectFETCH NEXT FROM curObject INTO @Name, @OwnerWHILE(@@FETCH_STATUS=0)BEGIN if @Owner=@OldOwner beginset @OwnerName = @OldOwner + . + rtrim(@Name)exec sp_changeobjectowner @OwnerName, @NewOwnerend-- select @name,@NewOwner,@OldOwnerFETCH NEXT FROM curObject INTO @Name, @OwnerENDclose curObjectdeallocate curObjectGO 10、SQL SERVER中直接循环写入数据declare @i intset @i=1while @i30begininsert into test (userid) values(@i)set @i=@i+1end 案例 ： 有如下表，要求就裱中所有沒有及格的成績，在每次增長0.1的基礎上，使他們剛好及格： Name scoreZhangshan 80Lishi 59Wangwu 50Songquan 69while((select min(score) from tb_table)60) begin update tb_table set score =score*1.01 where score60 if (select min(score) from tb_table)60 break else continue end 四、数据开发篇 1.按姓氏笔画排序Select * From TableName Order By CustomerName Collate Chinese_PRC_Stroke_ci_as //从少到多 2.数据库加密select encrypt(原始密码) select pwdencrypt(原始密码) select pwdcompare(原始密码,加密后密码) = 1--相同；否则不相同 encrypt(原始密码) select pwdencrypt(原始密码) select pwdcompare(原始密码,加密后密码) = 1--相同；否则不相同 3.取回表中字段declare @list varchar(1000), @sql nvarchar(1000) select @list=@list+,+b.name from sysobjects a,syscolumns b where a.id=b.id and a.name=表A set @sql=select +right(@list,len(@list)-1)+ from 表A exec (@sql) 4.查看硬盘分区EXEC master..xp_fixeddrives 5.比较A,B表是否相等if (select checksum_agg(binary_checksum(*)) from A) = (select checksum_agg(binary_checksum(*)) from B) print 相等 else print 不相等 6.杀掉所有的事件探察器进程DECLARE hcforeach CURSOR GLOBAL FOR SELECT kill +RTRIM(spid) FROM master.dbo.sysprocesses WHERE program_name IN(SQL profiler,NSQL 事件探查器) EXEC sp_msforeach_worker ? 7.记录搜索开头到N条记录 Select Top N * From 表 N到M条记录(要有主索引ID) Select Top M-N * From 表 Where ID in (Select Top M ID From 表) Order by ID Desc N到结尾记录 Select Top N * From 表 Order by ID Desc 案例 示例1：一张表有一万多条记录，表的第一个字段 RecID 是自增长字段， 写一个SQL语句， 找出表的第31到第40个记录。 select top 10 recid from A where recid not in(select top 30 recid from A) **　分析：**如果这样写会产生某些问题，如果recid在表中存在逻辑索引。 select top 10 recid from A where……是从索引中查找，而后面的select top 30 recid from A则在数据表中查找，这样由于索引中的顺序有可能和数据表中的不一致，这样就导致查询到的不是本来的欲得到的数据。 **　解决方案** **　1， 用order by** select top 30 recid from A order by ricid 如果该字段不是自增长，就会出现问题 **　2， 在那个子查询中也加条件：**select top 30 recid from A where recid-1 **　示例2：查询表中的最后以条记录，并不知道这个表共有多少数据,以及表结构。** set @s = select top 1 * from T where pid not in (select top + str(@count-1) + pid from T)print @s exec sp_executesql @s 9：获取当前数据库中的所有用户表select Name from sysobjects where xtype=u and status=0 10：获取某一个表的所有字段select name from syscolumns where id=object_id(表名) select name from syscolumns where id in (select id from sysobjects where type = u and name = 表名) **注：**以上两种方式的效果相同 11：查看与某一个表相关的视图、存储过程、函数select a.* from sysobjects a, syscomments b where a.id = b.id and b.text like %表名% 12：查看当前数据库中所有存储过程select name as 存储过程名称 from sysobjects where xtype=P 13：查询用户创建的所有数据库select * from master..sysdatabases D where sid not in(select sid from master..syslogins where name=sa) 或者： select dbid, name AS DB_NAME from master..sysdatabases where sid 0x01 14：查询某一个表的字段和数据类型select column_name,data_type from information_schema.columns where table_name = 表名 15：不同服务器数据库之间的数据操作–创建链接服务器 exec sp_addlinkedserver ITSV , , SQLOLEDB , 远程服务器名或ip地址 exec sp_addlinkedsrvlogin ITSV , false ,null, 用户名 , 密码 –查询示例 select * from ITSV.数据库名.dbo.表名 –导入示例 select * into 表 from ITSV.数据库名.dbo.表名 –以后不再使用时删除链接服务器 exec sp_dropserver ITSV , droplogins –连接远程局域网数据(openrowsetopenqueryopendatasource) –1、openrowset –查询示例： select * from openrowset( SQLOLEDB , sql服务器名 ; 用户名 ; 密码 ,数据库名.dbo.表名) –生成本地表： select * into 表 from openrowset( SQLOLEDB , sql服务器名 ; 用户名 ; 密码 ,数据库名.dbo.表名) –把本地表导入远程表： insert openrowset( SQLOLEDB , sql服务器名 ; 用户名 ; 密码 ,数据库名.dbo.表名)select *from 本地表 –更新本地表： update bset b.列A=a.列Afrom openrowset( SQLOLEDB , sql服务器名 ; 用户名 ; 密码 ,数据库名.dbo.表名)as a inner join 本地表 bon a.column1=b.column1 –openquery用法需要创建一个连接 –首先创建一个连接创建链接服务器 exec sp_addlinkedserver ITSV , , SQLOLEDB , 远程服务器名或ip地址 –查询 select *FROM openquery(ITSV, SELECT * FROM 数据库.dbo.表名 ) –把本地表导入远程表 insert openquery(ITSV, SELECT * FROM 数据库.dbo.表名 )select * from 本地表 –更新本地表 update bset b.列B=a.列BFROM openquery(ITSV, SELECT * FROM 数据库.dbo.表名 ) as ainner join 本地表 b on a.列A=b.列A –3、opendatasourceopenrowset SELECT *FROM opendatasource( SQLOLEDB , Data Source=ip/ServerName;User ID=登陆名;Password=密码 ).test.dbo.roy_ta –把本地表导入远程表 insert opendatasource( SQLOLEDB , Data Source=ip/ServerName;User ID=登陆名;Password=密码 ).数据库.dbo.表名select * from 本地表"},{"title":"认识Git","path":"/wiki/git/start.html","content":"认识 Git什么是 Git ？Git 是目前世界上最先进的分布式版本控制系统，用于敏捷高效地处理任何或小或大的项目。 Git 与 SVN 区别点 Git 是分布式的，SVN 不是。这是 Git 和其它非分布式的版本控制系统如 SVN，CVS 等最核心的区别。 Git 把内容按元数据方式存储，而 SVN 是按文件。 Git 分支和 SVN 的分支不同：分支在 SVN 中一点都不特别，其实它就是版本库中的另外一个目录。 Git 没有一个全局的版本号，而 SVN 有。目前为止这是跟 SVN 相比 Git 缺少的最大的一个特征。 Git 的内容完整性要优于 SVN。Git 的内容存储使用的是 SHA-1 哈希算法。这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时降低对版本库的破坏。 图片来源于 RUNOOB Git 工作区、暂存区和版本库 工作区：就是你在电脑里能看到的目录。 暂存区：英文叫stage, 或index。一般存放在 “.git目录下” 下的index文件（.gitindex）中，所以我们把暂存区有时也叫作索引（index）。 版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。"},{"title":"安装与配置","path":"/wiki/git/install-and-config.html","content":"安装与配置安装Linux源码包下载地址： https://git-scm.com/downloads/linux 安装指定系统的依赖包： CentOSRedHat $ yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel DebianUbuntu $ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev 解压安装下载的源码包： $ tar -zxf git-1.7.2.2.tar.gz$ cd git-1.7.2.2$ make prefix=/usr/local all$ sudo make prefix=/usr/local install 使用终端指令安装 DebianUbuntu $ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev$ apt-get install git$ git --versiongit version 1.8.1.2Copy CentOSRedHat $ yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel$ yum -y install git-core$ git --versiongit version 1.7.1 Windows安装包下载地址： https://gitforwindows.org 完成安装之后，就可以使用命令行的 git 工具（已经自带了 ssh 客户端）了，另外还有一个图形界面的 Git 项目管理工具。 在开始菜单里找到 Git - Git Bash，会弹出 Git 命令窗口，你可以在该窗口进行 Git 操作。 Mac安装包下载地址： https://git-scm.com/downloads/mac Mac 自带 git 并且随着系统版本的更新，自带的 git 也会升级到最新，一般无需手动安装。 配置Git 提供了一个叫做 git config 的工具，专门用来配置或读取相应的工作环境变量。这些环境变量，决定了 Git 在各个环节的具体工作方式和行为。这些变量可以存放在以下三个不同的地方： /etc/gitconfig 文件：系统中对所有用户都普遍适用的配置。若使用 git config 时用 --system 选项，读写的就是这个文件。 ~/.gitconfig 文件：用户目录下的配置文件只适用于该用户。若使用 git config 时用 --global 选项，读写的就是这个文件。 当前项目的 Git 目录中的配置文件（也就是工作目录中的 .git/config 文件）：这里的配置仅仅针对当前项目有效。每一个级别的配置都会覆盖上层的相同配置，所以 .git/config 里的配置会覆盖 /etc/gitconfig 中的同名变量。 用户信息git config --global user.name xaoxuugit config --global user.email git@xaoxuu.com 如果用了 --global 选项，那么更改的配置文件就是位于你用户主目录下的那个，以后你所有的项目都会默认使用这里配置的用户信息。 如果要在某个特定的项目中使用其他名字或者电邮，只要去掉 --global 选项重新配置即可，新的设定保存在当前项目的 .git/config 文件里。 查看配置信息git config --listhttp.postbuffer=2Muser.name=xaoxuuuser.email=git@xaoxuu.com git-sshssh-keygen -t rsa -C user@example.com 其中 user@example.com 对应的是你的 Git 邮箱。 ssh-agent 是一种控制用来保存公钥身份验证所使用的私钥的程序，其实 ssh-agent 就是一个密钥管理器，运行 ssh-agent 以后，使用 ssh-add 将私钥交给 ssh-agent 保管，其他程序需要身份验证的时候可以将验证申请交给 ssh-agent 来完成整个认证过程。 eval $(ssh-agent -s) 添加生成的 SSH key 到 ssh-agent： ssh-add ~/.ssh/id_rsa 登陆 Github，添加 ssh： 把 id_rsa.pub 文件里的内容复制到这里："},{"title":"基本操作入门","path":"/wiki/git/usage.html","content":"基本操作入门基本操作流程 在对代码进行了一些修改之后，使用：git add --all 将本地所有新增文件和修改内容添加到暂存区。 使用：git commit -m 备注 将代码提交到本地版本库。（备注内容没有空格的话不需要加引号） 使用：git pull origin 从服务器拉取代码，更新本地版本库。 使用：git push origin 将本地版本库推送到服务器。 克隆与配置克隆版本库git clone https://github.com/xaoxuu/AXKit.git# 或者git clone https://github.com/xaoxuu/AXKit.git AXKit 配置版本库要忽略某些文件的改动需要配置 .gitignore 文件： # 这是macOS文件夹属性的隐藏文件，不需要同步到git.DS_Store# 某个文件夹不想要同步到git/public/node_modules# 某个文件不想要同步到gittest.txt# 通配符._* 基本操作指令创建与切换分支创建并切换 branchgit checkout -b 分支名仅仅切换 branchgit checkout 分支名创建 taggit tag 标签名创建 tag 并备注git tag -a 标签名 -m 备注信息创建 PGP tag 并备注git tag -s 标签名 -m 备注信息 查看分支和标签查看本地 taggit tag查看某个本地 tag 详情git show 标签名查看本地 branch listgit branch 分支名查看远程 branch listgit branch -r 分支名查看所有 branch listgit branch -a 分支名 删除分支和标签删除本地 branch / taggit branch -d 分支名或标签名删除所有未推送的本地 branchgit fetch -p仅仅删除某个远程 branch / taggit push origin :分支名或标签名# 或者git push origin --delete 分支名或标签名 推送分支和标签推送某个 branch / taggit push origin 分支名或标签名推送所有 branchgit push --all origin推送所有 taggit push --tags 重命名分支重命名本地分支： git branch -m 旧分支名 新分支名 重命名远程分支： 删除远程分支 重命名本地分支 推送本地分支 拉取、合并分支拉取某个远程标签git fetch origin tag 远程标签名 合并某本地分支到当前分支git merge 分支名 合并某远程分支到当前分支git pull origin 远程分支名 merge 和 rebase简单的说：用 rebase 方式合并的分支会合并成一条直线，而 merge 方式合并会记录合并操作。 合并前： 使用 merge 进行合并： 使用 rebase 进行合并： 代码冲突我一般使用 Tower 客户端操作，pull 之后有冲突的文件会列出来。建议使用一个比较好的编辑器，有冲突的部分会用两种颜色高亮。 未完待续 代码回退如果冲突文件没有妥善解决就提交到版本库导致严重后果，这是需要查看某个历史时刻的代码，使用： git log# 查看提交记录 然后 copy 某个 commit id 进行回退，回退的类型有两种： soft这是默认的回退方式，版本库的 HEAD 回滚到某个 commit 但本地代码不变，处于未 commit 的状态。 git reset [commit id]# 或者git reset --soft [commit id] hardHEAD 和本地代码都回到某个 commit，后面的更改将会被丢弃。（如同时光穿梭） git reset --hard [commit id] 版本迭代查看本地所有标签 git tag 把当前 HEAD 打个标签（名为：1.0） git tag 1.0# 也可以添加备注信息，如同commitgit tag 1.0 -m message 切换到某个标签（1.0） git checkout 1.0 把标签 push 到远程 push指定的taggit push origin 1.0push所有未push的taggit push --tags 删除标签（1.0） # 删除本地taggit tag -d 1.0# 删除远程tag# 方法一：将空白tag覆盖到远程taggit push origin :1.0# 方法二：执行删除命令git push origin --delete 1.0 客户端操作Stash save：将当前未 commit 的代码保存到 stash，并且回到上次 commit 的状态。 apply：应用某个 stash 的代码。 Git-Flow自动化管理功能，例如： 准备开发新版本的时候：点击 Start Release，客户端会自动新建一个 release 分支。 准备增加一个新特性的时候：点击 Start Feature，客户端会新建一个 feature 分支。 需要修复 bug 的时候：点击 Start Hotfix，客户端会新建一个 fix 分支。 当修复完 bug，点击 Finish Hotfix 的时候，客户端会自动把 fix 分支合并到创建它的分支，并且创建一个 tag。 当一个新特性开发完成，点击 Finish Feature 的时候，客户端会自动把 feature 分支合并到创建它的分支，并且创建一个 tag。 当一个新版本开发完成，点击 Finish Release 的时候，客户端会自动把 release 分支合并到创建它的分支，并且创建一个 tag。"},{"title":"Redis 安装","path":"/wiki/redis/install.html","content":"Linux 安装源码编译安装Redis本教程使用稳定版本，下载并安装Redis： wget http://download.redis.io/redis-stable.tar.gztar -xzvf redis-stable.tar.gzcd redis-stablemake 执行完 make 命令后，src 目录下会出现编译后的 redis 服务程序 redis-server，还有用于测试的客户端程序 redis-cli，两个程序位于安装目录 src 目录下： redis-server Redis 服务器程序 redis-cli 与Redis交互的命令行界面程序 安装可执行程序到usrlocalbin，执行: make install在前台启动和停止 Redis安装后，您可以通过运行来启动 Redis redis-server 如果成功，您将看到 Redis 的启动日志，Redis 将在前台运行。 30858:C 11 May 2023 20:26:52.870 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo30858:C 11 May 2023 20:26:52.870 # Redis version=7.0.11, bits=64, commit=00000000, modified=0, pid=30858, just started30858:C 11 May 2023 20:26:52.870 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf30858:M 11 May 2023 20:26:52.871 * monotonic clock: POSIX clock_gettime _._ _.-``__ -._ _.-`` `. `_. -._ Redis 7.0.11 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ -._ ( , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|` _.-| Port: 6379 | `-._ `._ / _.- | PID: 30858 `-._ `-._ `-./ _.- _.- |`-._`-._ `-.__.- _.-_.-| | `-._`-._ _.-_.- | https://redis.io `-._ `-._`-.__.-_.- _.- |`-._`-._ `-.__.- _.-_.-| | `-._`-._ _.-_.- | `-._ `-._`-.__.-_.- _.- `-._ `-.__.- _.- `-._ _.- `-.__.- 30858:M 11 May 2023 20:26:52.871 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.30858:M 11 May 2023 20:26:52.871 # Server initialized30858:M 11 May 2023 20:26:52.871 # WARNING Memory overcommit must be enabled! Without it, a background save or replication may fail under low memory condition. Being disabled, it can can also cause failures without low memory condition, see https://github.com/jemalloc/jemalloc/issues/1328. To fix this issue add vm.overcommit_memory = 1 to /etc/sysctl.conf and then reboot or run the command sysctl vm.overcommit_memory=1 for this to take effect.30858:M 11 May 2023 20:26:52.872 * Ready to accept connections 要停止 Redis，请输入Ctrl-C。 注意这种方式启动 redis 使用的是默认配置。也可以通过启动参数告诉 redis 使用指定配置文件使用下面命令启动。 cp redis.conf /etc/redis.confredis-server /etc/redis.conf redis.conf 是一个默认的配置文件。我们可以根据需要使用自己的配置文件。 启动 redis 服务进程后，就可以使用测试客户端程序 redis-cli 和 redis 服务交互了。 比如： redis-cliredis set foo barOKredis get foobar 关闭停止redis服务 redis-cli shutdown#直接关闭不保存内存redis-cli shutdown nosave 配置 Redis 为后台服务将配置文件中的 daemonize no 改成 daemonize yes，配置 redis 为后台启动。 Redis 设置访问密码在配置文件中找到 requirepass，去掉前面的注释，并修改后面的密码。 常用配置文件例子 redis.conf #默认端口6379port 6379#绑定ip，如果是内网可以直接绑定 127.0.0.1, 或者忽略, 0.0.0.0是外网bind 0.0.0.0#守护进程启动daemonize yes#超时timeout 300loglevel notice#分区databases 16save 900 1save 300 10save 60 10000rdbcompression yes#存储文件dbfilename dump.rdb#密码 abcd123requirepass abcd123 在 ubuntu 上安装 Redis按照下面给出的步骤在 Ubuntu 上安装 Redis： 首先使用 sudo 设置非 root 用户，然后安装构建和测试依赖项： sudo apt update sudo apt full-upgradesudo apt install build-essential tcl 要继续按 Y 键 安装 Redis 服务器使用以下命令安装 Redis 服务器： sudo apt-get install redis-server 现在安装了 Redis Server。您可以启动 Redis 服务器： 启动 Redis 服务器您使用以下命令启动 redis 服务器： redis-server 启动 Redis 客户端Redis 服务器已启动，因此您可以启动 redis 客户端以在它们之间进行通信。 redis-cli 验证 Redis 是否正常工作执行以下命令： redis-cli 这将打开一个 redis 提示符。 redis 127.0.0.1:6379 在上面的提示中，127.0.0.1 是机器的 IP 地址，6379 是 Redis 服务器运行的端口。 现在键入以下 PING 命令。返回 PONG 表示 Redis 已成功安装在您的系统上。 在 windows 上安装 RedisRedis 官方不建议在 windows 下使用 Redis，所以官网没有 windows 版本可以下载。还好微软团队维护了开源的 windows 版本，虽然只有 3.2 版本，对于普通测试使用足够了。 安装包方式安装 Redis 服务下载地址：https://github.com/MicrosoftArchive/redis/releases 点击下载： 您可以看到 Redis 现在已下载。 或者您也可以使用下面链接下载。 https://github.com/rgl/redis/downloads 下载完成之后双击按着引导流程安装。 启动 RedisRedis 现在可以使用了。打开 Redis 程序目录： 文件介绍： redis-server.exe：服务端程序，提供 redis 服务 redis-cli.exe: 客户端程序，通过它连接 redis 服务并进行操作 redis-check-dump.exe：RDB 文件修复工具 redis-check-aof.exe：AOF 文件修复工具 redis-benchmark.exe：性能测试工具，用以模拟同时由 N 个客户端发送 M 个 SETsGETs 查询 (类似于 Apache 的 ab 工具) redis.windows.conf： 配置文件，将 redis 作为普通软件使用的配置，命令行关闭则 redis 关闭 redis.windows-service.conf：配置文件，将 redis 作为系统服务的配置 单击 redis-server.exe，启动 Redis 服务。 现在启动 Redis 客户端。 检查 Redis 是否已连接。 使用 PING 命令。 Redis 服务窗口也输出 1 个客户端已连接。 直接解压的方式安装 redis首先下载 redis 安装包：https://github.com/MSOpenTech/redis/releases 解压安装包到相应文件夹，任何盘符都行，例如 E:\\tools\\redis-3.2.100。 使用命令行启动 Redis 服务运行 cmd，cd 进入对应目录 E:\\tools\\redis-3.2.100，执行： redis-server.exe redis.windows.conf *注：可以把 redis 的路径加到系统的环境变量里，这样就省得再输路径了，后面的那个 redis.windows.conf 可以省略，如果省略，会启用默认的参数。 输入之后会显示如下： 安装 redis 到 windows 服务redis-server --service-install redis.windows.conf 查看 windows 服务是否加入： 这时候先关闭打开的第一个 cmd 窗口，然后执行以下命令启动再次 redis： redis-server --service-start 停止 redis 服务： redis-server --service-stop 最后，测试一下 redis 是否能够正常使用： 切换到 redis 目录下：E:\\tools\\redis-3.2.100 下： redis-cli.exe -h 127.0.0.1 -p 6379"},{"title":"Redis 配置文件详解","path":"/wiki/redis/config.html","content":"Redis 配置文件详解在 Redis 中，Redis 的根目录中有一个配置文件（redis.conf）。您可以通过 Redis CONFIG 命令获取和设置所有 Redis 配置。 查看Redis配置句法 CONFIG GET 命令的基本语法: redis 127.0.0.1:6379 CONFIG GET CONFIG_SETTING_NAME 查看日志等级的配置 redis 127.0.0.1:6379 CONFIG GET loglevel 输出 1) loglevel2) verbose 要获取所有配置设置，请使用 * 代替 CONFIG_SETTING_NAME redis 127.0.0.1:6379 CONFIG GET * 输出 1. dir2. C:\\\\\\\\Program Files\\\\\\\\Redis3. dbfilename4. dump.rdb5. requirepass6. (nil)7. masterauth8. (nil)9. maxmemory10. 011. maxmemory-policy12. volatile-lru13. maxmemory-samples14. 315. timeout16. 017. appendonly18. no19. no-appendfsync-on-rewrite20. no21. appendfsync22. everysec23. save24. 3600 1 300 100 60 1000025. auto-aof-rewrite-percentage26. 10027. auto-aof-rewrite-min-size28. 104857629. slave-serve-stale-data30. yes31. hash-max-zipmap-entries32. 51233. hash-max-zipmap-value34. 6435. list-max-ziplist-entries36. 51237. list-max-ziplist-value38. 6439. set-max-intset-entries40. 51241. zset-max-ziplist-entries42. 12843. zset-max-ziplist-value44. 6445. slowlog-log-slower-than46. 1000047. slowlog-max-len48. 6449. loglevel50. verbose \\ 编辑修改Redis配置要更新配置，可以直接编辑 redis.conf 文件，也可以通过 CONFIG set 命令更新配置。 语法 以下是 CONFIG SET 命令的基本语法。 redis 127.0.0.1:6379 CONFIG SET CONFIG_SETTING_NAME NEW_CONFIG_VALUE 示例如下： 127.0.0.1:6379 CONFIG SET loglevel verboseOK127.0.0.1:6379 CONFIG GET loglevel1) loglevel2) verbose Redis 的日志级别有以下四种： debug：会打印出很多信息，适用于开发和测试阶段。 verbose（冗长的）：包含很多不太有用的信息，但比debug简化一些。 notice：适用于生产模式。 warning : 警告信息。 Redis 默认设置为 verbose，开发测试阶段可以用 debug，生产模式一般选用 notice。 Redis 常用配置参数说明redis.conf 配置项说明如下： 参数 描述 daemonize Redis 默认不是以守护进程的方式运行 daemonize no，可以通过该配置项修改，使用 yes 启用守护进程 pidfile 当 Redis 以守护进程方式运行时，Redis 默认会把 pid 写入 varrunredis.pid 文件，可以通过 pidfile 指定 pidfile varrunredis.pid port port 6379 指定 Redis 监听端口，默认端口为 6379，作者在自己的一篇博文中解释了为什么选用 6379 作为默认端口，因为 6379 在手机按键上 MERZ 对应的号码，而 MERZ 取自意大利歌女 Alessia Merz 的名字 bind 监听的主机地址 bind 127.0.0.1 timeout timeout 300 当客户端闲置多长时间后关闭连接，如果指定为 0，表示关闭该功能 loglevel loglevel verbose 指定日志记录级别，Redis 总共支持四个级别：debug、verbose、notice、warning，默认为 verbose logfile logfile stdout 日志记录方式，默认为标准输出，如果配置 Redis 为守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给 devnull databases databases 16 设置数据库的数量，默认数据库为 0，可以使用 SELECT dbid 命令在连接上指定数据库 id save save seconds changes 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件，可以多个条件配合, Redis 默认配置文件中提供了三个条件：save 900 1、save 300 10、save 60 10000 ,分别表示 90 0 秒（15 分钟）内有 1 个更改，300 秒（5 分钟）内有 10 个更改以及 60 秒内有 10000 个更改。 rdbcompression rdbcompression yes 10.指定存储至本地数据库时是否压缩数据，默认为 yes，Redis 采用 LZF 压缩，如果为了节省 CPU 时间，可以关闭该选项，但会导致数据库文件变的巨大 dbfilename dbfilename dump.rdb 指定本地数据库文件名，默认值为 dump.rdb dir dir . 指定本地数据库存放目录 slaveof slaveof masterip masterport 设置当本机为 slave 服务时，设置 master 服务的 IP 地址及端口，在 Redis 启动时，它会自动从 master 进行数据同步 masterauth masterauth master-password master 服务设置了密码保护时，slave 服务连接 master 的密码 requirepass requirepass foobared 设置 Redis 连接密码，如果配置了连接密码，客户端在连接 Redis 时需要通过 AUTH password命令提供密码，默认关闭 maxclients maxclients 128 设置同一时间最大客户端连接数，默认无限制，Redis 可以同时打开的客户端连接数为 Redis 进程可以打开的最大文件描述符数，如果设置 maxclients 0，表示不作限制。当客户端连接数到达限制时，Redis 会关闭新的连接并向客户端返回 max number of clients reached 错误信息 maxmemory maxmemory bytes 指定 Redis 最大内存限制，Redis 在启动时会把数据加载到内存中，达到最大内存后，Redis 会先尝试清除已到期或即将到期的 Key，当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis 新的 vm 机制，会把 Key 存放内存，Value 会存放在 swap 区 appendonly appendonly no 指定是否在每次更新操作后进行日志记录，Redis 在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失。因为 redis 本身同步数据文件是按上面 save 条件来同步的，所以有的数据会在一段时间内只存在于内存中。默认为 no appendfilename appendfilename appendonly.aof 指定更新日志文件名，默认为 appendonly.aof appendfsync appendfsync everysec 指定更新日志条件，共有 3 个可选值：no：表示等操作系统进行数据缓存同步到磁盘（快）; always：表示每次更新操作后手动调用 fsync() 将数据写到磁盘（慢，安全）; everysec：表示每秒同步一次（折衷，默认值） vm-enabled vm-enabled no 指定是否启用虚拟内存机制，默认值为 no，简单的介绍一下，VM 机制将数据分页存放，由 Redis 将访问量较少的页即冷数据 swap 到磁盘上，访问多的页面由磁盘自动换出到内存中（在后面的文章我会仔细分析 Redis 的 VM 机制） vm-swap-file vm-swap-file tmpredis.swap 虚拟内存文件路径，默认值为 tmpredis.swap，不可多个 Redis 实例共享 vm-max-memory vm-max-memory 0 将所有大于 vm-max-memory 的数据存入虚拟内存,无论 vm-max-memory 设置多小,所有索引数据都是内存存储的( Redis 的索引数据就是 keys ),也就是说,当 vm-max-memory 设置为 0 的时候,其实是所有 value 都存在于磁盘。默认值为 0 vm-page-size vm-page-size 32 Redis swap 文件分成了很多的 page，一个对象可以保存在多个 page 上面，但一个 page 上不能被多个对象共享，vm-page-size 是要根据存储的数据大小来设定的，作者建议如果存储很多小对象，page 大小最好设置为 32 或者 64 bytes；如果存储很大大对象，则可以使用更大的 page，如果不确定，就使用默认值 vm-pages vm-pages 134217728 设置 swap 文件中的 page 数量，由于页表（一种表示页面空闲或使用的 bitmap）是在放在内存中的，在磁盘上每 8 个 pages 将消耗 1byte 的内存。 vm-max-threads vm-max-threads 4 设置访问 swap 文件的线程数,最好不要超过机器的核数,如果设置为 0,那么所有对 swap 文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为 4 glueoutputbuf glueoutputbuf yes 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 hash-max-zipmap-entries hash-max-zipmap-entries 64 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 hash-max-zipmap-value sh-max-zipmap-value 512 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 activerehashing activerehashing yes 指定是否激活重置哈希，默认为开启（后面在介绍 Redis 的哈希算法时具体介绍） include include pathtolocal.conf 指定包含其它的配置文件，可以在同一主机上多个 Redis 实例之间使用同一份配置文件，而同时各个实例又拥有自己的特定配置文件"},{"title":"Redis 简介","path":"/wiki/redis/intro.html","content":"Redis 简介Redis（全称为Remote Dictionary Server）是一个开源的高性能键值对存储系统，具有快速、灵活和可扩展的特性。它是一个基于内存的数据结构存储系统，可以用作数据库、缓存和消息代理。 Redis 的一些主要特点和用途： 高性能：Redis 数据存储在内存中，因此能够提供极快的读写操作。它采用单线程模型和异步 IO，避免了多线程的竞争和阻塞，从而达到了非常高的性能。 数据结构多样：Redis 支持多种数据结构，包括字符串（String）、哈希（Hash）、列表（List）、集合（Set）和有序集合（Sorted Set）。这些数据结构提供了丰富的操作命令，使得开发者可以方便地处理各种数据需求。 持久化支持：Redis 提供了两种持久化方式，即快照（Snapshotting）和日志追加（Append-only file，AOF）。快照方式将 Redis 内存数据以二进制格式写入磁盘，而 AOF 则通过追加记录 Redis 的操作命令来实现持久化。 发布订阅：Redis 支持发布订阅模式，可以用作消息代理。发布者将消息发送到指定的频道，订阅者则可以接收和处理这些消息。这种模式在构建实时通信、事件驱动系统和消息队列等场景中非常有用。 分布式缓存：Redis可以通过主从复制和分片来实现数据的分布式存储和高可用性。主从复制可以将数据复制到多个从节点，实现读写分离和数据备份。而分片则可以将数据分布在多个Redis节点上，实现横向扩展和负载均衡。 事务支持：Redis 支持事务，开发者可以将多个操作组合成一个原子性的操作序列，保证这些操作要么全部执行成功，要么全部不执行。 功能丰富：Redis不仅仅是一个简单的缓存，它还提供了许多其他功能，如事务支持、Lua脚本执行、定时任务、原子操作等。这使得开发者可以在Redis中实现更复杂的应用逻辑。 Redis 是一个功能丰富的存储系统，适用于多种场景，包括缓存、会话存储、排行榜、实时分析等。它有广泛的应用，并且拥有活跃的社区支持。 Redis 与其他 key-value 存储有什么不同？ Redis 比起其它键值类数据库，值可以包含更复杂的数据类型，并且在数据类型上定义原子操作。Redis 数据类型与基本数据结构密切相关，并直接向程序员公开，无需额外的抽象层。 Redis 运行在内存中但是可以持久化到磁盘，因此它代表了一种不同的权衡，即在数据集不能大于内存的限制下实现非常高的写入和读取速度。内存数据库的另一个优点是，与磁盘上的相同数据结构相比，复杂数据结构的内存表示更易于操作，因此 Redis 可以做很多事情而内部复杂性很小。同时，因 RDB 和 AOF 两种磁盘持久化方式是不适合随机访问，因为它们是顺序写入的。 Redis 架构Redis 主要由有两个程序组成： Redis 客户端 redis-cli Redis 服务器 redis-server 客户端、服务器可以位于同一台计算机或两台不同的计算机中。"},{"title":"Redis 数据类型","path":"/wiki/redis/data-types.html","content":"redis 支持的数据类型Redis 数据库支持多种数据类型。 字符串（string） 哈希（hash） 列表（list） 集合（set） 有序集合（sorted set） 位图 ( Bitmaps ) 基数统计 ( HyperLogLogs ) 字符串String 是一组字节。在 Redis 数据库中，字符串是二进制安全的。这意味着它们具有已知长度，并且不受任何特殊终止字符的影响。可以在一个字符串中存储最多 512 兆字节的内容。 示例： 使用 SET 命令在 name 键中存储字符串 redis.com.cn，然后使用 GET 命令查询 name。 SET name redis.com.cn OK GET name redis.com.cn 在上面的例子中，SET 和 GET 是 Redis 命令，name 是 Redis 中使用的 key，redis.com.cn 是存储在 Redis 中的字符串值。 哈希哈希是键值对的集合。在 Redis 中，哈希是字符串字段和字符串值之间的映射。因此，它们适合表示对象。 示例： 让我们存储一个用户的对象，其中包含用户的基本信息。 HMSET user:1 username ajeet password redis alexa 2000 OK HGETALL user:1 username ajeet password redis alexa 2000 这里，HMSET 和 HGETALL 是 Redis 的命令，而 user：1 是键。 每个哈希可以存储多达 232 - 1 个键-值对。 列表Redis 列表定义为字符串列表，按插入顺序排序。可以将元素添加到 Redis 列表的头部或尾部。 示例： lpush rediscomcn java (integer) 1 lpush rediscomcn sql (integer) 1 lpush rediscomcn mongodb (integer) 1 lpush rediscomcn cassandra (integer) 1 lrange rediscomcn 0 10 cassandra mongodb sql java 列表的最大长度为 232 – 1 个元素（超过 40 亿个元素）。 集合集合（set）是 Redis 数据库中的无序字符串集合。在 Redis 中，添加，删除和查找的时间复杂度是 O(1)。 示例： sadd tutoriallist redis (integer) 1 redis 127.0.0.1:6379 sadd tutoriallist sql (integer) 1 redis 127.0.0.1:6379 sadd tutoriallist postgresql (integer) 1 redis 127.0.0.1:6379 sadd tutoriallist postgresql (integer) 0 redis 127.0.0.1:6379 sadd tutoriallist postgresql (integer) 0 redis 127.0.0.1:6379 smembers tutoriallist 1) redis 2) postgresql 3) sql 在上面的示例中，您可以看到 postgresql 被添加了三次，但由于该集的唯一属性，它只添加一次。 集合中的最大成员数为 232 -1 个元素（超过 40 亿个元素）。 有序集合Redis 有序集合类似于 Redis 集合，也是一组非重复的字符串集合。但是，排序集的每个成员都与一个分数相关联，该分数用于获取从最小到最高分数的有序排序集。虽然成员是独特的，但可以重复分数。 示例： redis 127.0.0.1:6379 zadd tutoriallist 0 redis (integer) 1 redis 127.0.0.1:6379 zadd tutoriallist 0 sql (integer) 1 redis 127.0.0.1:6379 zadd tutoriallist 0 postgresql (integer) 1 redis 127.0.0.1:6379 zadd tutoriallist 0 postgresql (integer) 0 redis 127.0.0.1:6379 zadd tutoriallist 0 postgresql (integer) 0 redis 127.0.0.1:6379 ZRANGEBYSCORE tutoriallist 0 10 1) postgresql 2) redis 3) sql 位图Redis Bitmap 通过类似 map 结构存放 0 或 1 ( bit 位 ) 作为值。 Redis Bitmap 可以用来统计状态，如日活是否浏览过某个东西。 Redis setbit 命令Redis setbit 命令用于设置或者清除一个 bit 位。 *Redis setbit 命令语法格式SETBIT key offset value *范例127.0.0.1:6379 setbit aaa:001 10001 1 # 返回操作之前的数值(integer) 0127.0.0.1:6379 setbit aaa:001 10002 2 # 如果值不是0或1就报错(error) ERR bit is not an integer or out of range127.0.0.1:6379 setbit aaa:001 10002 0(integer) 0127.0.0.1:6379 setbit aaa:001 10003 1(integer) 0 基数统计Redis HyperLogLog 可以接受多个元素作为输入，并给出输入元素的基数估算值 基数 集合中不同元素的数量，比如 {‘apple’, ‘banana’, ‘cherry’, ‘banana’, ‘apple’} 的基数就是 3 估算值 算法给出的基数并不是精确的，可能会比实际稍微多一些或者稍微少一些，但会控制在合 理的范围之内 HyperLogLog 的优点是：即使输入元素的数量或者体积非常非常大，计算基数所需的空间总是固定的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 264 个不同元素的基数。 这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 Redis PFADD 命令Redis PFADD 命令将元素添加至 HyperLogLog *Redis PFADD 命令语法格式PFADD key element [element ...] *范例127.0.0.1:6379 PFADD unique::ip::counter 192.168.0.1(integer) 1127.0.0.1:6379 PFADD unique::ip::counter 127.0.0.1(integer) 1127.0.0.1:6379 PFADD unique::ip::counter 255.255.255.255(integer) 1127.0.0.1:6379 PFCOUNT unique::ip::counter(integer) 3"},{"title":"Redis 命令","path":"/wiki/redis/commands.html","content":"Redis 命令Redis 命令用于在 redis 服务上执行操作。 要在 redis 服务上执行命令需要一个 redis 客户端。Redis 客户端在我们之前下载的 redis 安装包中。 语法Redis 客户端的基本语法为： $ redis-cli 实例以下实例讲解了如何启动 redis 客户端： 启动 redis 客户端，打开终端并输入命令 redis-cli。该命令会连接本地的 redis 服务。 $redis-cliredis 127.0.0.1:6379redis 127.0.0.1:6379 PINGPONG 在以上实例中我们连接到本地的 redis 服务并执行 PING 命令，该命令用于检测 redis 服务是否启动。 在远程服务上执行命令如果需要在远程 redis 服务上执行命令，同样我们使用的也是 redis-cli 命令。 语法$ redis-cli -h host -p port -a password 实例以下实例演示了如何连接到主机为 127.0.0.1，端口为 6379 ，密码为 mypass 的 redis 服务上。 $redis-cli -h 127.0.0.1 -p 6379 -a mypassredis 127.0.0.1:6379redis 127.0.0.1:6379 PINGPONG"},{"title":"Redis 哈希","path":"/wiki/redis/hashes.html","content":"Redis 哈希 ( Hashes )Redis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。 每个哈希键中可以存储多达 40 亿个字段值对。 例127.0.0.1:6379 HMSET mysite name redis url https://redis.com.cn rank 1 visitors 240000000OK127.0.0.1:6379 HGETALL mysite 1) name2) mysite3) url4) https://redis.com.cn5) rank6) 17) visitors8) 230000000 在上面的例子中，mysite 是 Redis 哈希列表，它包含详细信息（name，url，rank，visitors）属性。 Redis哈希命令 命令 描述 HDEL 删除一个或多个哈希表字段 HEXISTS 查看哈希表 key 中，指定的字段是否存在 HGET 获取存储在哈希表中指定字段的值 HGETALL 获取在哈希表中指定 key 的所有字段和值 HINCRBY 为哈希表 key 中的指定字段的整数值加上增量 increment HINCRBYFLOAT 为哈希表 key 中的指定字段的浮点数值加上增量 increment HKEYS 获取所有哈希表中的字段 HLEN 获取哈希表中字段的数量 HMGET 获取所有给定字段的值 HMSET 同时将多个 field-value (域-值)对设置到哈希表 key 中 HSET 将哈希表 key 中的字段 field 的值设为 value HSETNX 只有在字段 field 不存在时，设置哈希表字段的值 HVALS 获取哈希表中所有值 HSCAN 迭代哈希表中的键值对 HSTRLEN 返回哈希表 key 中， 与给定域 field 相关联的值的字符串长度"},{"title":"Redis 键","path":"/wiki/redis/keys.html","content":"Redis 键(key)Redis key 作为参数与 Redis 命令配合使用。 Redis 键的类型, redis是key-value的数据，所以每个数据都是一个键值对，键的类型是字符串。 语法： redis 127.0.0.1:6379 COMMAND KEY_NAME 例 让我们以 Redis DEL 命令为例。如果键被删除，它将给出输出 1，否则它将为 0。 redis 127.0.0.1:6379 SET mykey redis.com.cn OK redis 127.0.0.1:6379 DEL mykey (integer) 1 这里，DEL 是 Redis 命令，而 mykey 是键。 Redis keys 命令下表列出了 Redis 键相关的命令: 命令 描述 DEL 用于删除 key DUMP 序列化给定 key ，并返回被序列化的值 EXISTS 检查给定 key 是否存在 EXPIRE 为给定 key 设置过期时间 EXPIREAT 用于为 key 设置过期时间，接受的时间参数是 UNIX 时间戳 PEXPIRE 设置 key 的过期时间，以毫秒计 PEXPIREAT 设置 key 过期时间的时间戳(unix timestamp)，以毫秒计 KEYS 查找所有符合给定模式的 key MOVE 将当前数据库的 key 移动到给定的数据库中 PERSIST 移除 key 的过期时间，key 将持久保持 PTTL 以毫秒为单位返回 key 的剩余的过期时间 TTL 以秒为单位，返回给定 key 的剩余生存时间( RANDOMKEY 从当前数据库中随机返回一个 key RENAME 修改 key 的名称 RENAMENX 仅当 newkey 不存在时，将 key 改名为 newkey TYPE 返回 key 所储存的值的类型"},{"title":"Redis 列表","path":"/wiki/redis/lists.html","content":"Redis 列表 ( Lists )Redis 列表是按插入顺序排序的字符串列表。可以在列表的头部（左边）或尾部（右边）添加元素。 列表可以包含超过 40 亿 个元素 ( 232 - 1 )。 例 用 LPUSH 命令将三个值插入了名为 language 的列表当中: redis 127.0.0.1:6379 LPUSH rediscomcn sql (integer) 1 redis 127.0.0.1:6379 LPUSH rediscomcn mysql (integer) 2 redis 127.0.0.1:6379 LPUSH rediscomcn cassandra (integer) 3 redis 127.0.0.1:6379 LRANGE rediscomcn 0 10 1) cassandra 2) mysql 3) sql redis 127.0.0.1:6379 Redis 列表命令下表列出了列表相关命令： 命令 描述 BLPOP 移出并获取列表的第一个元素 BRPOP 移出并获取列表的最后一个元素 BRPOPLPUSH 从列表中弹出一个值，并将该值插入到另外一个列表中并返回它 LINDEX 通过索引获取列表中的元素 LINSERT 在列表的元素前或者后插入元素 LLEN 获取列表长度 LPOP 移出并获取列表的第一个元素 LPUSH 将一个或多个值插入到列表头部 LPUSHX 将一个值插入到已存在的列表头部 LRANGE 获取列表指定范围内的元素 LREM 移除列表元素 LSET 通过索引设置列表元素的值 LTRIM 对一个列表进行修剪(trim) RPOP 移除并获取列表最后一个元素 RPOPLPUSH 移除列表的最后一个元素，并将该元素添加到另一个列表并返回 RPUSH 在列表中添加一个或多个值 RPUSHX 为已存在的列表添加值"},{"title":"Redis 集合","path":"/wiki/redis/sets.html","content":"Redis 集合 ( Sets )Redis 的 Set 是 string 类型的无序集合。 集合成员是唯一的，这就意味着集合中没有重复的数据。 在 Redis 中，添加、删除和查找的时间复杂都是 O(1)（不管 Set 中包含多少元素）。 集合中最大的成员数为 232 – 1 (4294967295), 每个集合可存储 40 多亿个成员。 例通过 SADD 命令向名为 rediscomcn 的集合插入的三个元素: redis 127.0.0.1:6379 SADD rediscomcn db2 (integer) 1 redis 127.0.0.1:6379 SADD rediscomcn mongodb (integer) 1 redis 127.0.0.1:6379 SADD rediscomcn db2 (integer) 0 redis 127.0.0.1:6379 SADD rediscomcn cassandra (integer) 1 redis 127.0.0.1:6379 SMEMBERS rediscomcn 1) cassandra 2) db2 3) mongodb 在上面的示例中，我们使用 SADD 命令在集合中添加了 4 个元素。但是，使用 SMEMBERS 命令只检索了 3 个元素，因为有一个元素是重复的，Redis 只集合只含唯一元素。 Redis 集合命令下表列出了 Redis 集合相关命令： 命令 描述 SADD 向集合添加一个或多个成员 SCARD 获取集合的成员数 SDIFF 返回给定所有集合的差集 SDIFFSTORE 返回给定所有集合的差集并存储在 destination 中 SINTER 返回给定所有集合的交集 SINTERSTORE 返回给定所有集合的交集并存储在 destination 中 SISMEMBER 判断 member 元素是否是集合 key 的成员 SMEMBERS 返回集合中的所有成员 SMOVE 将 member 元素从 source 集合移动到 destination 集合 SPOP 移除并返回集合中的一个随机元素 SRANDMEMBER 返回集合中一个或多个随机数 SREM 移除集合中一个或多个成员 SUNION 返回所有给定集合的并集 SUNIONSTORE 所有给定集合的并集存储在 destination 集合中 SSCAN 迭代集合中的元素"},{"title":"Redis 字符串","path":"/wiki/redis/strings.html","content":"Redis 字符串 ( Strings )Redis 字符串命令用于管理 Redis 中的字符串值。 语法： redis 127.0.0.1:6379 COMMAND KEY_NAME 例 redis 127.0.0.1:6379 SET mykey redis.com.cn OK redis 127.0.0.1:6379 GET mykey redis.com.cn 这里，SET 和 GET 是命令，mykey 是键。 Redis 字符串命令以下是一些用于在 Redis 中管理字符串的基本命令的列表： 命令 描述 SET 设置指定 key 的值 GET 获取指定 key 的值 GETRANGE 返回 key 中字符串值的子字符 GETSET 将给定 key 的值设为 value ，并返回 key 的旧值 ( old value ) GETBIT 对 key 所储存的字符串值，获取指定偏移量上的位 ( bit ) MGET 获取所有(一个或多个)给定 key 的值 SETBIT 对 key 所储存的字符串值，设置或清除指定偏移量上的位(bit) SETEX 设置 key 的值为 value 同时将过期时间设为 seconds SETNX 只有在 key 不存在时设置 key 的值 SETRANGE 从偏移量 offset 开始用 value 覆写给定 key 所储存的字符串值 STRLEN 返回 key 所储存的字符串值的长度 MSET 同时设置一个或多个 key-value 对 MSETNX 同时设置一个或多个 key-value 对 PSETEX 以毫秒为单位设置 key 的生存时间 INCR 将 key 中储存的数字值增一 INCRBY 将 key 所储存的值加上给定的增量值 ( increment ) INCRBYFLOAT 将 key 所储存的值加上给定的浮点增量值 ( increment ) DECR 将 key 中储存的数字值减一 DECRBY 将 key 所储存的值减去给定的减量值 ( decrement ) APPEND 将 value 追加到 key 原来的值的末尾"},{"title":"Redis 地理信息GEO","path":"/wiki/redis/geo.html","content":"Redis 地理信息GEORedis GEO 主要用于存储地理位置信息，并对存储的信息进行操作，该功能在 Redis 3.2 版本新增。 Redis GEO 操作方法有： geoadd：添加地理位置的坐标。 geopos：获取地理位置的坐标。 geodist：计算两个位置之间的距离。 georadius：根据用户给定的经纬度坐标来获取指定范围内的地理位置集合。 georadiusbymember：根据储存在位置集合里面的某个地点获取指定范围内的地理位置集合。 geohash：返回一个或多个位置对象的 geohash 值。 geoaddgeoadd 用于存储指定的地理空间位置，可以将一个或多个经度(longitude)、纬度(latitude)、位置名称(member)添加到指定的 key 中。 geoadd 语法格式如下： GEOADD key longitude latitude member [longitude latitude member ...] 以下实例中 key 为 Sicily、Catania 为位置名称 ： 实例redis GEOADD Sicily 13.361389 38.115556 Palermo 15.087269 37.502669 Catania(integer) 2redis GEODIST Sicily Palermo Catania166274.1516redis GEORADIUS Sicily 15 37 100 km1) Cataniaredis GEORADIUS Sicily 15 37 200 km1) Palermo2) Cataniaredis geoposgeopos 用于从给定的 key 里返回所有指定名称(member)的位置（经度和纬度），不存在的返回 nil。 geopos 语法格式如下： GEOPOS key member [member ...] 实例redis GEOADD Sicily 13.361389 38.115556 Palermo 15.087269 37.502669 Catania(integer) 2redis GEOPOS Sicily Palermo Catania NonExisting1) 1) 13.36138933897018433 2) 38.115556395496298592) 1) 15.08726745843887329 2) 37.502668423331620323) (nil)redis geodistgeodist 用于返回两个给定位置之间的距离。 geodist 语法格式如下： GEODIST key member1 member2 [m|km|ft|mi] member1 member2 为两个地理位置。 最后一个距离单位参数说明： m ：米，默认单位。 km ：千米。 mi ：英里。 ft ：英尺。 计算 Palermo 与 Catania 之间的距离实例redis GEOADD Sicily 13.361389 38.115556 Palermo 15.087269 37.502669 Catania(integer) 2redis GEODIST Sicily Palermo Catania166274.1516redis GEODIST Sicily Palermo Catania km166.2742redis GEODIST Sicily Palermo Catania mi103.3182redis GEODIST Sicily Foo Bar(nil)redis georadius、georadiusbymembergeoradius 以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。 georadiusbymember 和 GEORADIUS 命令一样， 都可以找出位于指定范围内的元素， 但是 georadiusbymember 的中心点是由给定的位置元素决定的， 而不是使用经度和纬度来决定中心点。 georadius 与 georadiusbymember 语法格式如下： GEORADIUS key longitude latitude radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key]GEORADIUSBYMEMBER key member radius m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT count] [ASC|DESC] [STORE key] [STOREDIST key] 参数说明： m ：米，默认单位。 km ：千米。 mi ：英里。 ft ：英尺。 WITHDIST: 在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。 WITHCOORD: 将位置元素的经度和维度也一并返回。 WITHHASH: 以 52 位有符号整数的形式， 返回位置元素经过原始 geohash 编码的有序集合分值。 这个选项主要用于底层应用或者调试， 实际中的作用并不大。 COUNT 限定返回的记录数。 ASC: 查找结果根据距离从近到远排序。 DESC: 查找结果根据从远到近排序。 georadius实例redis GEOADD Sicily 13.361389 38.115556 Palermo 15.087269 37.502669 Catania(integer) 2redis GEORADIUS Sicily 15 37 200 km WITHDIST1) 1) Palermo 2) 190.44242) 1) Catania 2) 56.4413redis GEORADIUS Sicily 15 37 200 km WITHCOORD1) 1) Palermo 2) 1) 13.36138933897018433 2) 38.115556395496298592) 1) Catania 2) 1) 15.08726745843887329 2) 37.50266842333162032redis GEORADIUS Sicily 15 37 200 km WITHDIST WITHCOORD1) 1) Palermo 2) 190.4424 3) 1) 13.36138933897018433 2) 38.115556395496298592) 1) Catania 2) 56.4413 3) 1) 15.08726745843887329 2) 37.50266842333162032redis georadiusbymember实例redis GEOADD Sicily 13.583333 37.316667 Agrigento(integer) 1redis GEOADD Sicily 13.361389 38.115556 Palermo 15.087269 37.502669 Catania(integer) 2redis GEORADIUSBYMEMBER Sicily Agrigento 100 km1) Agrigento2) Palermoredis geohashRedis GEO 使用 geohash 来保存地理位置的坐标。 geohash 用于获取一个或多个位置元素的 geohash 值。 geohash 语法格式如下： GEOHASH key member [member ...] geohash实例redis GEOADD Sicily 13.361389 38.115556 Palermo 15.087269 37.502669 Catania(integer) 2redis GEOHASH Sicily Palermo Catania1) sqc8b49rny02) sqdtr74hyu0redis"},{"title":"Redis 连接","path":"/wiki/redis/connection.html","content":"Redis连接Redis 连接命令用于控制和管理到 Redis Server 的客户端连接。 例以下示例说明客户端如何向 Redis 服务器验证自身并检查服务器是否正在运行。 redis 127.0.0.1:6379 AUTH password (error) ERR Client sent AUTH, but no password is set redis 127.0.0.1:6379 redis 127.0.0.1:6379 PING PONG redis 127.0.0.1:6379 *注意：在这里您可以看到未设置“密码”，因此您可以直接访问任何命令。 Redis 连接命令下表列出了用于 Redis 连接相关的命令 命令 描述 AUTH password 验证密码是否正确 ECHO message 打印字符串 PING 查看服务是否运行 QUIT 关闭当前连接 SELECT index 切换到指定的数据库"},{"title":"Redis HyperLogLog","path":"/wiki/redis/hyperloglog.html","content":"Redis HyperLogLogRedis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。 在 Redis 里面，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 264 个不同元素的基 数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 但是，因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 什么是基数?比如数据集 {1, 3, 5, 7, 5, 7, 8}， 那么这个数据集的基数集为 {1, 3, 5 ,7, 8}, 基数(不重复元素)为5。 基数估计就是在误差可接受的范围内，快速计算基数。 实例以下实例演示了 HyperLogLog 的工作过程： redis 127.0.0.1:6379 PFADD rediscomcn redis1) (integer) 1redis 127.0.0.1:6379 PFADD rediscomcn mongodb1) (integer) 1redis 127.0.0.1:6379 PFADD rediscomcn mysql1) (integer) 1redis 127.0.0.1:6379 PFCOUNT rediscomcn(integer) 3 Redis HyperLogLog命令下表列出了列表相关命令： 命令 描述 PFADD 添加指定元素到 HyperLogLog 中。 PFCOUNT 返回给定 HyperLogLog 的基数估算值。 PFMERGE 将多个 HyperLogLog 合并为一个 HyperLogLog"},{"title":"Redis 发布订阅","path":"/wiki/redis/pub-sub.html","content":"Redis 发布订阅Redis 发布订阅是一种消息传模式，其中发送者（在Redis术语中称为发布者）发送消息，而接收者（订阅者）接收消息。传递消息的通道称为channel。 在Redis中，客户端可以订阅任意数量的频道。 下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系： 当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端： 实例以下实例演示了发布订阅是如何工作的，需要开启两个 redis-cli 客户端。 在我们实例中我们创建了订阅频道名为 rediscomcnChat: 第一个 redis-cli 客户端redis 127.0.0.1:6379 SUBSCRIBE rediscomcnChatReading messages... (press Ctrl-C to quit)1) subscribe2) redisChat3) (integer) 1 现在，我们先重新开启个 redis 客户端，然后在同一个频道 rediscomcnChat 发布两次消息，订阅者就能接收到消息。 第二个 redis-cli 客户端redis 127.0.0.1:6379 PUBLISH rediscomcnChat Redis PUBLISH test(integer) 1redis 127.0.0.1:6379 PUBLISH rediscomcnChat Learn redis by redis.com.cn(integer) 1# 订阅者的客户端会显示如下消息1) message2) rediscomcnChat3) Redis PUBLISH test1) message2) rediscomcnChat3) Learn redis by redis.com.cn Redis 发布订阅命令下表列出了列表相关命令： 命令 描述 PSUBSCRIBE 订阅一个或多个符合给定模式的频道。 PUBSUB 查看订阅与发布系统状态。 PUBLISH 将信息发送到指定的频道。 PUNSUBSCRIBE 退订所有给定模式的频道。 SUBSCRIBE 订阅给定的一个或多个频道的信息。 UNSUBSCRIBE 指退订给定的频道。"},{"title":"Redis 脚本","path":"/wiki/redis/scripting.html","content":"Redis脚本Redis 脚本使用 Lua 解释器来执行脚本。 自版本 2.6.0 开始内嵌于 Redis 中。 用于编写脚本的命令是 EVAL。 句法 redis 127.0.0.1:6379 EVAL script numkeys key [key ...] arg [arg ...] 例 让我们举一个例子来看看 Redis 脚本的工作原理： redis 127.0.0.1:6379 EVAL return 2 key1 key2 first second 1) key1 2) key2 3) first 4) second"},{"title":"Redis 服务器","path":"/wiki/redis/server.html","content":"Redis 服务器Redis Server 命令用于管理 Redis 服务器。 有不同的服务器命令可用于获取服务器信息，统计信息和其他特征。 例我们举一个例子来看看如何获取有关服务器的所有统计信息和信息。 redis 127.0.0.1:6379 ping PONG redis 127.0.0.1:6379 AUTH password (error) ERR Client sent AUTH, but no password is set redis 127.0.0.1:6379 PING PONG redis 127.0.0.1:6379 ECHO Welcome to rediscomcn Welcome to rediscomcn redis 127.0.0.1:6379 INFO redis_version:2.4.6 redis_git_sha1:26cdd13a redis_git_dirty:0 arch_bits:64 multiplexing_api:winsock2 gcc_version:4.6.1 process_id:6360 uptime_in_seconds:4442 uptime_in_days:0 lru_clock:1716856 used_cpu_sys:1.80 used_cpu_user:0.42 used_cpu_sys_children:0.00 used_cpu_user_children:0.00 connected_clients:1 connected_slaves:0 client_longest_output_list:0 client_biggest_input_buf:0 blocked_clients:0 used_memory:1188152 used_memory_human:1.13M used_memory_rss:1188152 used_memory_peak:1188112 used_memory_peak_human:1.13M mem_fragmentation_ratio:1.00 mem_allocator:libc loading:0 aof_enabled:0 changes_since_last_save:0 bgsave_in_progress:0 last_save_time:1506142039 bgrewriteaof_in_progress:0 total_connections_received:1 total_commands_processed:4 expired_keys:0 evicted_keys:0 keyspace_hits:0 keyspace_misses:0 pubsub_channels:0 pubsub_patterns:0 latest_fork_usec:0 vm_enabled:0 role:master Redis 管理 redis 服务相关命令下表列出了管理 redis 服务相关的命令 命令 描述 BGREWRITEAOF 异步执行一个 AOF（AppendOnly File） 文件重写操作 BGSAVE 在后台异步保存当前数据库的数据到磁盘 CLIENT 关闭客户端连接 CLIENT LIST 获取连接到服务器的客户端连接列表 CLIENT GETNAME 获取连接的名称 CLIENT PAUSE 在指定时间内终止运行来自客户端的命令 CLIENT SETNAME 设置当前连接的名称 CLUSTER SLOTS 获取集群节点的映射数组 COMMAND 获取 Redis 命令详情数组 COMMAND COUNT 获取 Redis 命令总数 COMMAND GETKEYS 获取给定命令的所有键 TIME 返回当前服务器时间 COMMAND INFO 获取指定 Redis 命令描述的数组 CONFIG GET 获取指定配置参数的值 CONFIG REWRITE 修改 redis.conf 配置文件 CONFIG SET 修改 redis 配置参数，无需重启 CONFIG RESETSTAT 重置 INFO 命令中的某些统计数据 DBSIZE 返回当前数据库的 key 的数量 DEBUG OBJECT 获取 key 的调试信息 DEBUG SEGFAULT 让 Redis 服务崩溃 FLUSHALL 删除所有数据库的所有 key FLUSHDB 删除当前数据库的所有 key INFO 获取 Redis 服务器的各种信息和统计数值 LASTSAVE 返回最近一次 Redis 成功将数据保存到磁盘上的时间 MONITOR 实时打印出 Redis 服务器接收到的命令，调试用 ROLE 返回主从实例所属的角色 SAVE 异步保存数据到硬盘 SHUTDOWN 异步保存数据到硬盘，并关闭服务器 SLAVEOF 将当前服务器转变从属服务器(slave server) SLOWLOG 管理 redis 的慢日志 SYNC 用于复制功能 ( replication ) 的内部命令"},{"title":"Redis 有序集合","path":"/wiki/redis/sorted-sets.html","content":"Redis 有序集合 ( Sorted Sets )Redis 有序集合和集合一样也是 string 类型元素的集合，且不允许重复的成员。 不同的是每个元素都会关联一个 double 类型的分数。Redis 正是通过分数来为集合中的成员进行从小到大的排序。 有序集合的成员是唯一的,但分数 ( score ) 却可以重复。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。 集合中最大的成员数为 232 – 1 ( 4294967295 ) , 每个集合可存储 40 多亿个成员。 例通过 ZADD 命令向 Redis 的有序集合中添加了三个值并关联分数: redis 127.0.0.1:6379 ZADD rediscomcn 1 redis (integer) 0 redis 127.0.0.1:6379 ZADD rediscomcn 2 cassandra (integer) 1 redis 127.0.0.1:6379 ZADD rediscomcn 3 cassandra (integer) 0 redis 127.0.0.1:6379 ZADD rediscomcn 3 mysql (integer) 1 redis 127.0.0.1:6379 ZADD rediscomcn 4 mysql (integer) 0 redis 127.0.0.1:6379 ZRANGE rediscomcn 0 10 WITHSCORES 1) redis 2) 1 3) cassandra 4) 3 5) mysql 6) 4 Redis 有序集合命令下表列出了 Redis 有序集合的基本命令 命令 描述 ZADD 向有序集合添加一个或多个成员，或者更新已存在成员的分数 ZCARD 获取有序集合的成员数 ZCOUNT 计算在有序集合中指定区间分数的成员数 ZINCRBY 有序集合中对指定成员的分数加上增量 increment ZINTERSTORE 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中 ZLEXCOUNT 在有序集合中计算指定字典区间内成员数量 ZRANGE 通过索引区间返回有序集合成指定区间内的成员 ZRANGEBYLEX 通过字典区间返回有序集合的成员 ZRANGEBYSCORE 通过分数返回有序集合指定区间内的成员 ZRANK 返回有序集合中指定成员的索引 ZREM 移除有序集合中的一个或多个成员 ZREMRANGEBYLEX 移除有序集合中给定的字典区间的所有成员 ZREMRANGEBYRANK 移除有序集合中给定的排名区间的所有成员 ZREMRANGEBYSCORE 移除有序集合中给定的分数区间的所有成员 ZREVRANGE 返回有序集中指定区间内的成员，通过索引，分数从高到底 ZREVRANGEBYSCORE 返回有序集中指定分数区间内的成员，分数从高到低排序 ZREVRANK 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序 ZSCORE 返回有序集中，成员的分数值 ZUNIONSTORE 计算一个或多个有序集的并集，并存储在新的 key 中 ZSCAN 迭代有序集合中的元素（包括元素成员和元素分值）"},{"title":"Redis Stream","path":"/wiki/redis/stream.html","content":"Redis StreamRedis Stream 是 Redis 5.0 版本新增加的数据结构。 Redis Stream 主要用于消息队列（MQ，Message Queue），Redis 本身是有一个 Redis 发布订阅 (pubsub) 来实现消息队列的功能，但它有个缺点就是消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。 简单来说发布订阅 (pubsub) 可以分发消息，但无法记录历史消息。 而 Redis Stream 提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。 Redis Stream 的结构如下所示，它有一个消息链表，将所有加入的消息都串起来，每个消息都有一个唯一的 ID 和对应的内容： 每个 Stream 都有唯一的名称，它就是 Redis 的 key，在我们首次使用 xadd 指令追加消息时自动创建。 上图解析： Consumer Group ：消费组，使用 XGROUP CREATE 命令创建，一个消费组有多个消费者(Consumer)。 lastdeliveredid ：游标，每个消费组会有个游标 lastdeliveredid，任意一个消费者读取了消息都会使游标 lastdeliveredid 往前移动。 pendingids ：消费者(Consumer)的状态变量，作用是维护消费者的未确认的 id。 pendingids 记录了当前已经被客户端读取的消息，但是还没有 ack (Acknowledge character：确认字符）。 消息队列相关命令： XADD - 添加消息到末尾 XTRIM - 对流进行修剪，限制长度 XDEL - 删除消息 XLEN - 获取流包含的元素数量，即消息长度 XRANGE - 获取消息列表，会自动过滤已经删除的消息 XREVRANGE - 反向获取消息列表，ID 从大到小 XREAD - 以阻塞或非阻塞方式获取消息列表 消费者组相关命令： XGROUP CREATE - 创建消费者组 XREADGROUP GROUP - 读取消费者组中的消息 XACK - 将消息标记为”已处理” XGROUP SETID - 为消费者组设置新的最后递送消息ID XGROUP DELCONSUMER - 删除消费者 XGROUP DESTROY - 删除消费者组 XPENDING - 显示待处理消息的相关信息 XCLAIM - 转移消息的归属权 XINFO - 查看流和消费者组的相关信息； XINFO GROUPS - 打印消费者组的信息； XINFO STREAM - 打印流信息 XADD使用 XADD 向队列添加消息，如果指定的队列不存在，则创建一个队列，XADD 语法格式： XADD key ID field value [field value ...] key ：队列名称，如果不存在就创建 ID ：消息 id，我们使用 * 表示由 redis 生成，可以自定义，但是要自己保证递增性。 field value ： 记录。 XADD实例redis XADD mystream * name Sara surname OConnor1601372323627-0redis XADD mystream * field1 value1 field2 value2 field3 value31601372323627-1redis XLEN mystream(integer) 2redis XRANGE mystream - +1) 1) 1601372323627-0 2) 1) name 2) Sara 3) surname 4) OConnor2) 1) 1601372323627-1 2) 1) field1 2) value1 3) field2 4) value2 5) field3 6) value3redis XTRIM使用 XTRIM 对流进行修剪，限制长度， 语法格式： XTRIM key MAXLEN [~] count key ：队列名称 MAXLEN ：长度 count ：数量 XTRIM实例127.0.0.1:6379 XADD mystream * field1 A field2 B field3 C field4 D1601372434568-0127.0.0.1:6379 XTRIM mystream MAXLEN 2(integer) 0127.0.0.1:6379 XRANGE mystream - +1) 1) 1601372434568-0 2) 1) field1 2) A 3) field2 4) B 5) field3 6) C 7) field4 8) D127.0.0.1:6379redis XDEL使用 XDEL 删除消息，语法格式： XDEL key ID [ID ...] key：队列名称 ID ：消息 ID XDEL实例127.0.0.1:6379 XADD mystream * a 11538561698944-0127.0.0.1:6379 XADD mystream * b 21538561700640-0127.0.0.1:6379 XADD mystream * c 31538561701744-0127.0.0.1:6379 XDEL mystream 1538561700640-0(integer) 1127.0.0.1:6379 XRANGE mystream - +1) 1) 1538561698944-0 2) 1) a 2) 12) 1) 1538561701744-0 2) 1) c 2) 3 XLEN使用 XLEN 获取流包含的元素数量，即消息长度，语法格式： XLEN key key：队列名称 XLEN实例redis XADD mystream * item 11601372563177-0redis XADD mystream * item 21601372563178-0redis XADD mystream * item 31601372563178-1redis XLEN mystream(integer) 3redis XRANGE使用 XRANGE 获取消息列表，会自动过滤已经删除的消息 ，语法格式： XRANGE key start end [COUNT count] key ：队列名 start ：开始值， - 表示最小值 end ：结束值， + 表示最大值 count ：数量 实例redis XADD writers * name Virginia surname Woolf1601372577811-0redis XADD writers * name Jane surname Austen1601372577811-1redis XADD writers * name Toni surname Morrison1601372577811-2redis XADD writers * name Agatha surname Christie1601372577812-0redis XADD writers * name Ngozi surname Adichie1601372577812-1redis XLEN writers(integer) 5redis XRANGE writers - + COUNT 21) 1) 1601372577811-0 2) 1) name 2) Virginia 3) surname 4) Woolf2) 1) 1601372577811-1 2) 1) name 2) Jane 3) surname 4) Austenredis XREVRANGE使用 XREVRANGE 获取消息列表，会自动过滤已经删除的消息 ，语法格式： XREVRANGE key end start [COUNT count] key ：队列名 end ：结束值， + 表示最大值 start ：开始值， - 表示最小值 count ：数量 XREVRANGE实例redis XADD writers * name Virginia surname Woolf1601372731458-0redis XADD writers * name Jane surname Austen1601372731459-0redis XADD writers * name Toni surname Morrison1601372731459-1redis XADD writers * name Agatha surname Christie1601372731459-2redis XADD writers * name Ngozi surname Adichie1601372731459-3redis XLEN writers(integer) 5redis XREVRANGE writers + - COUNT 11) 1) 1601372731459-3 2) 1) name 2) Ngozi 3) surname 4) Adichieredis XREAD使用 XREAD 以阻塞或非阻塞方式获取消息列表 ，语法格式： XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key ...] id [id ...] count ：数量 milliseconds ：可选，阻塞毫秒数，没有设置就是非阻塞模式 key ：队列名 id ：消息 ID 实例# 从 Stream 头部读取两条消息 redis XREAD COUNT 2 STREAMS mystream writers 0-0 0-01) 1) mystream 2) 1) 1) 1526984818136-0 2) 1) duration 2) 1532 3) event-id 4) 5 5) user-id 6) 7782813 2) 1) 1526999352406-0 2) 1) duration 2) 812 3) event-id 4) 9 5) user-id 6) 3882342) 1) writers 2) 1) 1) 1526985676425-0 2) 1) name 2) Virginia 3) surname 4) Woolf 2) 1) 1526985685298-0 2) 1) name 2) Jane 3) surname 4) Austen XGROUP CREATE使用 XGROUP CREATE 创建消费者组，语法格式： XGROUP [CREATE key groupname id-or-$] [SETID key groupname id-or-$] [DESTROY key groupname] [DELCONSUMER key groupname consumername] key ：队列名称，如果不存在就创建 groupname ：组名。 $ ： 表示从尾部开始消费，只接受新消息，当前 Stream 消息会全部忽略。 从头开始消费: XGROUP CREATE mystream consumer-group-name 0-0 从尾部开始消费: XGROUP CREATE mystream consumer-group-name $ XREADGROUP GROUP使用 XREADGROUP GROUP 读取消费组中的消息，语法格式： XREADGROUP GROUP group consumer [COUNT count] [BLOCK milliseconds] [NOACK] STREAMS key [key ...] ID [ID ...] group ：消费组名 consumer ：消费者名。 count ： 读取数量。 milliseconds ： 阻塞毫秒数。 key ： 队列名。 ID ： 消息 ID。 XREADGROUP GROUP consumer-group-name consumer-name COUNT 1 STREAMS mystream"},{"title":"Redis 事务","path":"/wiki/redis/transaction.html","content":"Redis 事务事务是指一个完整的动作，要么全部执行，要么什么也没有做。 Redis 事务不是严格意义上的事务，只是用于帮助用户在一个步骤中执行多个命令。单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以 Redis 事务的执行并不是原子性的。 Redis 事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做。 Redis 事务可以一次执行多个命令， 并且带有以下三个重要的保证： 批量操作在发送 EXEC 命令前被放入队列缓存。 收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。 在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。 一个事务从开始到执行会经历以下三个阶段： 开始事务。 命令入队。 执行事务。 MULTI、EXEC、DISCARD、WATCH 这四个指令构成了 redis 事务处理的基础。 MULTI 用来组装一个事务； EXEC 用来执行一个事务； DISCARD 用来取消一个事务； WATCH 用来监视一些 key，一旦这些 key 在事务执行之前被改变，则取消事务的执行。 在 Redis 中，通过使用MULTI命令启动事务，然后需要传递应在事务中执行的命令列表，之后整个事务由EXEC命令执行。 例子如何启动和执行 Redis 事务。 redis 127.0.0.1:6379 MULTI OK redis 127.0.0.1:6379 EXEC (empty list or set) redis 127.0.0.1:6379 MULTI OK redis 127.0.0.1:6379 SET rediscomcn redis QUEUED redis 127.0.0.1:6379 GET rediscomcn QUEUED redis 127.0.0.1:6379 INCR visitors QUEUED redis 127.0.0.1:6379 EXEC 1) OK 2) redis 3) (integer) 1 在上面的例子中，我们看到了 QUEUED 的字样，这表示我们在用 MULTI 组装事务时，每一个命令都会进入到内存队列中缓存起来，如果出现 QUEUED 则表示我们这个命令成功插入了缓存队列，在将来执行 EXEC 时，这些被 QUEUED 的命令都会被组装成一个事务来执行。 对于事务的执行来说，如果 redis 开启了 AOF 持久化的话，那么一旦事务被成功执行，事务中的命令就会通过 write 命令一次性写到磁盘中去，如果在向磁盘中写的过程中恰好出现断电、硬件故障等问题，那么就可能出现只有部分命令进行了 AOF 持久化，这时 AOF 文件就会出现不完整的情况，这时，我们可以使用 redis-check-aof 工具来修复这一问题，这个工具会将 AOF 文件中不完整的信息移除，确保 AOF 文件完整可用。 Redis 事务错误有关事务，大家经常会遇到的是两类错误： 调用 EXEC 之前的错误 调用 EXEC 之后的错误 调用 EXEC 之前的错误，有可能是由于语法有误导致的，也可能时由于内存不足导致的。只要出现某个命令无法成功写入缓冲队列的情况，redis 都会进行记录，在客户端调用 EXEC 时，redis 会拒绝执行这一事务。（这是 2.6.5 版本之后的策略。在 2.6.5 之前的版本中，redis 会忽略那些入队失败的命令，只执行那些入队成功的命令）。我们来看一个这样的例子： 127.0.0.1:6379 multiOK127.0.0.1:6379 haha //一个明显错误的指令(error) ERR unknown command haha127.0.0.1:6379 pingQUEUED127.0.0.1:6379 exec//redis无情的拒绝了事务的执行，原因是“之前出现了错误”(error) EXECABORT Transaction discarded because of previous errors. 而对于调用 EXEC 之后的错误，redis 则采取了完全不同的策略，即 redis 不会理睬这些错误，而是继续向下执行事务中的其他命令。这是因为，对于应用层面的错误，并不是 redis 自身需要考虑和处理的问题，所以一个事务中如果某一条命令执行失败，并不会影响接下来的其他命令的执行。我们也来看一个例子： 127.0.0.1:6379 multiOK127.0.0.1:6379 set age 23QUEUED//age不是集合，所以如下是一条明显错误的指令127.0.0.1:6379 sadd age 15 QUEUED127.0.0.1:6379 set age 29QUEUED127.0.0.1:6379 exec //执行事务时，redis不会理睬第2条指令执行错误1) OK2) (error) WRONGTYPE Operation against a key holding the wrong kind of value3) OK127.0.0.1:6379 get age29 //可以看出第3条指令被成功执行了 最后，我们来说说最后一个指令WATCH，这是一个很好用的指令，它可以帮我们实现类似于“乐观锁”的效果，即CAS（check and set）。 WATCH 本身的作用是监视 key 是否被改动过，而且支持同时监视多个 key，只要还没真正触发事务，WATCH 都会尽职尽责的监视，一旦发现某个 key 被修改了，在执行 EXEC 时就会返回 nil，表示事务无法触发。 127.0.0.1:6379 set age 23OK127.0.0.1:6379 watch age //开始监视ageOK127.0.0.1:6379 set age 24 //在EXEC之前，age的值被修改了OK127.0.0.1:6379 multiOK127.0.0.1:6379 set age 25QUEUED127.0.0.1:6379 get ageQUEUED127.0.0.1:6379 exec //触发EXEC(nil) //事务无法被执行 Redis 事务命令下表列出了 Redis 事务的相关命令 命令 描述 DISCARD 取消事务，放弃执行事务块内的所有命令 EXEC 执行所有事务块内的命令 MULTI 标记一个事务块的开始 UNWATCH 取消 WATCH 命令对所有 key 的监视 WATCH 监视一个(或多个) key"},{"title":"Redis 备份和恢复","path":"/wiki/redis/backup-restore.html","content":"redis备份和恢复SAVE 命令用于创建当前 Redis 数据库的备份。此命令将通过执行同步 SAVE 在 Redis 目录中创建 dump.rdb 文件。 语法 SAVE 返回值 执行成功后，SAVE 命令返回 OK。 Redis备份示例使用 SAVE 命令创建当前数据库的备份。 SAVE 它将在 Redis 目录中创建 dump.rdb 文件。 可以看到 dump.rdb 文件已创建。 还原Redis数据将 Redis 备份文件（dump.rdb）移动到 Redis 目录中并启动服务器以恢复 Redis 数据。 查找 Redis 的安装目录，使用 Redis 的 CONFIG 命令，如下所示。 Redis 服务器安装在以下目录中。 “varlibredis” BGSAVE命令BGSAVE 是创建 Redis 备份的备用命令。 此命令将启动备份过程并在后台运行。 语法 BGSAVE 例"},{"title":"Redis 性能测试","path":"/wiki/redis/benchmarks.html","content":"Redis 基准性能测试Redis 基准测试 redis-benchmark 是一种实用工具，用于通过同时使用 multiple(n) 命令来检查 Redis 的性能。 语法 redis-benchmark [option] [option value] 例调用 Redis Benchmark 命令： redis-benchmark -n 100000 注意：该命令是在 redis 的安装目录下执行的，而不是 redis 客户端的内部指令。 \\ redis 性能测试工具可选参数如下所示： 选项 描述 默认值 -h 指定服务器主机名 127.0.0.1 -p 指定服务器端口 6379 -s 指定服务器 socket -c 指定并发连接数 50 -n 指定请求数 10000 -d 以字节的形式指定 SETGET 值的数据大小 2 -k 1keep alive 0reconnect 1 -r SETGETINCR 使用随机 key, SADD 使用随机值 -P 通过管道传输 请求 1 -q 强制退出 redis。仅显示 querysec 值 –csv 以 CSV 格式输出 -l 生成循环，永久执行测试 -t 仅运行以逗号分隔的测试命令列表 -I Idle 模式。仅打开 N 个 idle 连接并等待 实例以下实例我们使用了多个参数来测试 redis 性能：主机为 127.0.0.1，端口号为 6379，执行的命令为 set,lpush，请求数为 10000，通过 -q 参数让结果只显示每秒执行的请求数。 redis-benchmark -h 127.0.0.1 -p 6379 -t set,lpush -n 100000 -q"},{"title":"Redis 面试题","path":"/wiki/redis/interview-questions.html","content":"redis面试题Redis 常见面试问题总结和答案。 什么是Redis？Redis(Remote Dictionary Server) Redis 是一个开源的使用 ANSI C 语言编写、遵守 BSD 协议、支持网络、可基于内存亦可持久化的日志型、Key-Value 数据库，并提供多种语言的 API 的非关系型数据库。 传统数据库遵循 ACID 规则。而 Nosql（Not Only SQL 的缩写，是对不同于传统的关系型数据库的数据库管理系统的统称） 一般为分布式而分布式一般遵循 CAP 定理。 Github 源码：https://github.com/antirez/redis Redis 官网：https://redis.io/ 与传统数据库不同的是 Redis 的数据是存在内存中的，所以读写速度非常快，因此 redis 被广泛应用于缓存，每秒可以处理超过 10 万次读写操作，是已知性能最快的 Key-Value 数据库。另外，Redis 也经常用来做分布式锁。除此之外，Redis 支持事务、持久化、LUA 脚本、LRU 驱动事件、多种集群方案。 Redis支持的数据类型？Redis 可以存储键和不同类型的值之间的映射。键的类型只能为字符串，值常见有五种数据类型：字符串、列表、集合、散列表、有序集合。 String字符串： 格式: set key value string类型是二进制安全的。意思是redis的string可以包含任何数据。比如jpg图片或者序列化的对象 。 string类型是Redis最基本的数据类型，一个键最大能存储512MB。 Hash（哈希） 格式: hmset name key1 value1 key2 value2 Redis hash 是一个键值(keyvalue)对集合。 Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象。 List（列表） Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边） 格式: lpush name value 在 key 对应 list 的头部添加字符串元素 格式: rpush name value 在 key 对应 list 的尾部添加字符串元素 格式: lrem name index key 对应 list 中删除 count 个和 value 相同的元素 格式: llen name 返回 key 对应 list 的长度 Set（集合） 格式: sadd name value Redis的Set是string类型的无序集合。 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 zset(sorted set：有序集合) 格式: zadd name score value Redis zset 和 set 一样也是string类型元素的集合,且不允许重复的成员。 不同的是每个元素都会关联一个double类型的分数。redis正是通过分数来为集合中的成员进行从小到大的排序。 zset的成员是唯一的,但分数(score)却可以重复。 什么是Redis持久化？Redis有哪几种持久化方式？优缺点是什么？持久化就是把内存的数据写到磁盘中去，防止服务宕机了内存数据丢失。 Redis 提供了两种持久化方式:RDB（默认） 和AOF RDB： rdb是Redis DataBase缩写 功能核心函数rdbSave(生成RDB文件)和rdbLoad（从文件加载内存）两个函数 AOF: Aof是Append-only file缩写 每当执行服务器(定时)任务或者函数时flushAppendOnlyFile 函数都会被调用， 这个函数执行以下两个工作 aof写入保存： WRITE：根据条件，将 aof_buf 中的缓存写入到 AOF 文件 SAVE：根据条件，调用 fsync 或 fdatasync 函数，将 AOF 文件保存到磁盘中。 存储结构: 内容是redis通讯协议(RESP )格式的命令文本存储。 比较： 1、aof文件比rdb更新频率高，优先使用aof还原数据。 2、aof比rdb更安全也更大 3、rdb性能比aof好 4、如果两个都配了优先加载AOF 刚刚上面你有提到redis通讯协议(RESP )，能解释下什么是RESP？有什么特点？（可以看到很多面试其实都是连环炮，面试官其实在等着你回答到这个点，如果你答上了对你的评价就又加了一分）RESP 是redis客户端和服务端之前使用的一种通讯协议； RESP 的特点：实现简单、快速解析、可读性好 For Simple Strings the first byte of the reply is “+” 回复 For Errors the first byte of the reply is “-“ 错误 For Integers the first byte of the reply is “:” 整数 For Bulk Strings the first byte of the reply is “$” 字符串 For Arrays the first byte of the reply is “*” 数组 Redis 有哪些架构模式？讲讲各自的特点单机版 特点：简单 问题： 1、内存容量有限 2、处理能力有限 3、无法高可用。 主从复制 Redis 的复制（replication）功能允许用户根据一个 Redis 服务器来创建任意多个该服务器的复制品，其中被复制的服务器为主服务器（master），而通过复制创建出来的服务器复制品则为从服务器（slave）。 只要主从服务器之间的网络连接正常，主从服务器两者会具有相同的数据，主服务器就会一直将发生在自己身上的数据更新同步 给从服务器，从而一直保证主从服务器的数据相同。 特点： 1、masterslave 角色 2、masterslave 数据相同 3、降低 master 读压力在转交从库 问题： 无法保证高可用 没有解决 master 写的压力 哨兵 Redis sentinel 是一个分布式系统中监控 redis 主从服务器，并在主服务器下线时自动进行故障转移。其中三个特性： 监控（Monitoring）： Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。 提醒（Notification）： 当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通知。 自动故障迁移（Automatic failover）： 当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作。 特点： 1、保证高可用 2、监控各个节点 3、自动故障迁移 缺点：主从模式，切换需要时间丢数据 没有解决 master 写的压力 集群（proxy 型）： Twemproxy 是一个 Twitter 开源的一个 redis 和 memcache 快速轻量级代理服务器； Twemproxy 是一个快速的单线程代理程序，支持 Memcached ASCII 协议和 redis 协议。 特点：1、多种 hash 算法：MD5、CRC16、CRC32、CRC32a、hsieh、murmur、Jenkins 2、支持失败节点自动删除 3、后端 Sharding 分片逻辑对业务透明，业务方的读写方式和操作单个 Redis 一致 缺点：增加了新的 proxy，需要维护其高可用。 failover 逻辑需要自己实现，其本身不能支持故障的自动转移可扩展性差，进行扩缩容都需要手动干预 集群（直连型）： 从redis 3.0之后版本支持redis-cluster集群，Redis-Cluster采用无中心结构，每个节点保存数据和整个集群状态,每个节点都和其他所有节点连接。 特点： 1、无中心架构（不存在哪个节点影响性能瓶颈），少了 proxy 层。 2、数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布。 3、可扩展性，可线性扩展到 1000 个节点，节点可动态添加或删除。 4、高可用性，部分节点不可用时，集群仍可用。通过增加 Slave 做备份数据副本 5、实现故障自动 failover，节点之间通过 gossip 协议交换状态信息，用投票机制完成 Slave到 Master 的角色提升。 缺点： 1、资源隔离性较差，容易出现相互影响的情况。 2、数据通过异步复制,不保证数据的强一致性 什么是一致性哈希算法？什么是哈希槽？这两个问题篇幅过长 网上找了两个解锁的不错的文章 https://www.cnblogs.com/lpfuture/p/5796398.html http://www.jasontec.cn/articles/2020/04/11/1586586130767.html Redis常用命令？Keys pattern 列出所有key，*表示区配所有。 Set 设置 key 对应的值为 string 类型的 value。 setnx 设置 key 对应的值为 string 类型的 value。如果 key 已经存在，返回 0，nx 是 not exist 的意思。 Del 删除某个key，第一次返回1 删除了 第二次返回0 Expire 设置过期时间（单位秒） TTL 查看剩下多少时间，返回负数则key失效，key不存在了 Setex 设置 key 对应的值为 string 类型的 value，并指定此键值对应的有效期。 Mset 一次设置多个 key 的值，成功返回 ok 表示所有的值都设置了，失败返回 0 表示没有任何值被设置。 Getset 设置 key 的值，并返回 key 的旧值。 Mget 一次获取多个 key 的值，如果对应 key 不存在，则对应返回 nil。 Incr 对 key 的值做加加操作,并返回新的值。注意 incr 一个不是 int 的 value 会返回错误，incr 一个不存在的 key，则设置 key 为 1 incrby 同 incr 类似，加指定值 ，key 不存在时候会设置 key，并认为原来的 value 是 0 Decr 对 key 的值做的是减减操作，decr 一个不存在 key，则设置 key 为-1 Decrby 同 decr，减指定值。 Append 给指定 key 的字符串值追加 value,返回新字符串值的长度。 Strlen 取指定 key 的 value 值的长度。 persist xxx(取消过期时间) 选择数据库（0-15库） Select 0 选择数据库 move age 1 把age 移动到1库 Randomkey 随机返回一个key Rename 重命名 Type 返回数据类型 使用过Redis分布式锁么，它是怎么实现的？先拿setnx来争抢锁，抢到之后，再用expire给锁加一个过期时间防止锁忘记了释放。 如果在setnx之后执行expire之前进程意外crash或者要重启维护了，那会怎么样？ set指令有非常复杂的参数，这个应该是可以同时把setnx和expire合成一条指令来用的！ 使用过Redis做异步队列么，你是怎么用的？有什么缺点？一般使用list结构作为队列，rpush生产消息，lpop消费消息。当lpop没有消息的时候，要适当sleep一会再重试。 缺点： 在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如rabbitmq等。 能不能生产一次消费多次呢？ 使用pubsub主题订阅者模式，可以实现1:N的消息队列。 什么是缓存穿透？如何避免？什么是缓存雪崩？何如避免？缓存穿透 一般的缓存系统，都是按照key去缓存查询，如果不存在对应的value，就应该去后端系统查找（比如DB）。一些恶意的请求会故意查询不存在的key,请求量很大，就会对后端系统造成很大的压力。这就叫做缓存穿透。 如何避免？ 1：对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key对应的数据insert了之后清理缓存。 2：对一定不存在的key进行过滤。可以把所有的可能存在的key放到一个大的Bitmap中，查询时通过该bitmap过滤。 缓存雪崩 当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，会给后端系统带来很大压力。导致系统崩溃。 如何避免？ 1：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 2：做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期 3：不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。 Redis的用途是什么？计数器 可以对 String 进行自增自减运算，从而实现计数器功能。Redis 这种内存型数据库的读写性能非常高，很适合存储频繁读写的计数量。 缓存将热点数据放到内存中，设置内存的最大使用量以及淘汰策略来保证缓存的命中率。 会话缓存 可以使用 Redis 来统一存储多台应用服务器的会话信息。当应用服务器不再存储用户的会话信息，也就不再具有状态，一个用户可以请求任意一个应用服务器，从而更容易实现高可用性以及可伸缩性。 全页缓存（FPC） 除基本的会话 token 之外，Redis 还提供很简便的 FPC 平台。以 Magento 为例，Magento 提供一个插件来使用 Redis 作为全页缓存后端。此外，对 WordPress 的用户来说，Pantheon 有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。 查找表 例如 DNS 记录就很适合使用 Redis 进行存储。查找表和缓存类似，也是利用了Redis快速的查找特性。但是查找表的内容不能失效，而缓存的内容可以失效，因为缓存不作为可靠的数据来源。 消息队列(发布订阅功能) List 是一个双向链表，可以通过 lpush 和 rpop 写入和读取消息。不过最好使用 Kafka、RabbitMQ 等消息中间件。 分布式锁实现 在分布式场景下，无法使用单机环境下的锁来对多个节点上的进程进行同步。可以使用 Redis 自带的 SETNX 命令实现分布式锁，除此之外，还可以使用官方提供的 RedLock 分布式锁实现。 其它 Set 可以实现交集、并集等操作，从而实现共同好友等功能。ZSet可以实现有序性操作，从而实现排行榜等功能。 如何与Redis连接？安装服务器后，可以运行 redis 安装时提供的 Redis 客户端，也可以打开命令提示符并使用以下命令： redis-cli 通过使用其中任何一个，您可以与 Redis 交互。 Redis的主要特点是什么？以下是 Redis 的主要功能： 读写性能优异， Redis 能读的速度是 110000 次s，写的速度是 81000 次s。 支持数据持久化，支持 AOF 和 RDB 两种持久化方式。 支持事务，Redis 的所有操作都是原子性的，同时 Redis 还支持对几个操作合并后的原子性执行。 数据结构丰富，除了支持 string 类型的 value 外还支持 hash、set、zset、list 等数据结构。 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离。 解释Redis的复制功能？Redis 可以使用主从同步，从从同步。第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到内存 buffer，待完成后将 rdb 文件全量同步到复制节点，复制节点接受完成后将 rdb 镜像加载到内存。加载完成后，再通知主节点将期间修改的操作记录同步到复制节点进行重放就完成了同步过程。 Redis和RDBMS有什么区别？Redis 和 RDBMS 之间存在很多差异： Redis 是 NoSQL 数据库，而 RDBMS 是 SQL 数据库。 Redis 遵循键值结构，而 RDBMS 遵循表结构。 Redis 非常快，而 RDBMS 相对较慢。 Redis 将所有数据集存储在主存储器中，而 RDBMS 将其数据集存储在辅助存储器中。 Redis 通常用于存储小型和常用文件，而 RDBMS 用于存储大文件。 Redis 仅为 Linux，BSD，Mac OS X，Solaris 提供官方支持。它目前没有为 Windows 提供官方支持，而 RDBMS 提供对两者的支持。 为什么Redis不同于其他的键值存储数据库？有两个主要原因： Redis发展方向不同与其他键值数据库，它能包含很多复杂数据类型，对这些数据类型操作都是原子的。Redis数据类型与基本数据结构强相关，直接暴露给程序员，没有增加抽象层。 Redis是一个基于内存的，能够持久化到硬盘的数据库，因此为了实现高速读写，数据集大小不能超过内存。内存数据库另一个优点是，内存数据库相对于硬盘数据库非常容易操作复杂数据结构，因此Redis的可以做很多事情，内部复杂性低。与此同时两款磁盘存储格式（RDB和AOF）不需要支持随机访问，因此他们是紧凑的，而且总是以追加形式生成（甚至AOF日志轮换也是一个追加操作，因为新版本是由内存中的副本生成）。比起基于磁盘的数据存储， Redis 用来处理重要数据时需要确保数据集及时落盘刷新。 Redis内存使用情况？举几个例子（所有数据基于64位实例） 一个空实例大约占用3M内存 1百万简单字符串键值对大约占用85M内存 1百万哈希表键值对，每个对象有5个属性，大约占用160M内存 为了测试你的用例，使用redis-benchmark工具生成随机数据集，使用INFO memory命令检查使用内存空间。 存储相同的键，64位系统比32位系统使用更多的内存，键值很小情况下更明显。这是因为64位系统指针占用8字节。但是64位系统优点是可以配置更多内存（校对注：32位操作系统支持的内存最多为2的32次方，就是4G），因此为了运行大型Redis服务器，64位系统尤佳。另一种方案是使用分片。 我喜欢Redis的高性能操作和特性，但是不喜欢所有内容都在内存中，我不能创建一个比内存更大数据集。有计划改变吗？过去为了允许数据集超过RAM大小，Redis开发人员尝试使用虚拟内存和其他系统，但是我们非常高兴可以把一件事情做好：数据服务由内存提供，磁盘用于存储数据。所以现在没有计划为Redis创建磁盘后端，毕竟Redis大部分特性都是基于其当前架构设计的。 你的真正问题并不是所需的总内存，而是你需要划分你的数据集到多个Redis实例上，为了获取更多信息请阅读本文档中的分区页面。 同时使用Redis和磁盘数据库，是不是一个好想法？是的，一个通用的设计方案是，在非常频繁的写小的数据时采用Redis（并且你需要使用Redis数据结构给你的问题建立高效模型），以及将大数据存储到SQL数据库或者最终一致性磁盘数据库中。 有没有方法降低Redis内存使用率？如果可以的话使用Redis 32位实例。另外，还要善于使用哈希表，列表，有序集合和整数集，因为在特殊情况下Redis使用这些数据类型可以更紧凑存储一些元素。可以在内存优化页面获取更多信息。 Redis内存不足时会发生什么？Redis要么被Linux内核OOM杀掉，抛出错误崩溃，要么开始变得卡顿。随着现代操作系统malloc方法通常都不返回NULL，而是服务器开始交换，因此Redis性能降低，因此你可能会观察到一些错误现象。 INFO命令返回Redis使用内存总量，因此你可以编写脚本监控Redis服务器内存临界值。 Redis内置保护措施允许用户在配置文件中使用maxmemory选项，设置Redis最大占用内存。如果达到此限制，Redis将开始返回错误给写命令（但是将继续接受只读命令），或者当最大内存限制达到时也可以配置为键淘汰，在这种情况下Redis作为缓存使用。 我们有文档描述Redis作为LRU缓存使用。 在Linux系统中，即使我有很多空闲内存，后台保存失败报fork()错误！精简回答：echo 1 /proc/sys/vm/overcommit_memory 详细回答： Redis后台保存模式依赖现代操作系统的写时拷贝技术。Redis fork（创建一个子进程）是父进程精确拷贝。子进程存储数据到磁盘并且最终退出。从理论上讲，子进程应该和父进程使用同样多内存，作为父进程副本，但是得益于多数现代操作系统实现的写时复制技术，父进程和子进程共享内存页。内存页在父进程或子进程改变时将被复制。当子进程保存时，理论上所有页面都可能改变，Linux无法提前告知子进程需要多少内存，因此如果overcommit_memory设置为0，fork将会失败除非有足够的空闲RAM真正复制父进程内存页.结果是，如果你有3G Redis数据集，只有2G可用内存将会失败。 overcommit_memory设置为1，意味着Linux 使用更乐观方式fork，这确实是你所期望的Redis。 “理解虚拟机内存 ”是红帽经典文章，可以了解Linux虚拟内存怎么工作，overcommitmemory和overcommitratio的替代品。这篇文章校正了proc(5)用户手册对overcommit_memory1和2配置正确含义。 Redis磁盘快照是不是原子操作？是的，当服务器不在执行命令时，Redis后台保存进程总是被创建，因此每个命令在RAM中是原子的，并且在磁盘快照过程也是原子的。 Redis是单线程的，我怎么利用多CPU核?CPU基本不可能成为的Redis的瓶颈，因为通常Redis受限于内存或网络。例如使用Pipelining，Redis运行在普通的Linux系统上，每秒可以处理50万请求，所以如果你的应用程序主要使用O(N) 或者 O(log(N))命令，几乎不会使用太多的CPU。 然而为了最大限度利用CPU，你可以在一台机器上启动多个Redis实例，并把它们设置为不同服务器。某些时候单个机器是不够的，所以如果你想使用多个CPU，你可以提前考虑使用分片。 关于使用多Redis实例，你可以在Partitioning page找到更多的信息 单个Redis实例最多可以存储多少键？哈希表、列表、集合和有序集合最大可以包含多少元素？Redis最大可以处理232键，实践测试每个实例最少可以处理2.5亿键。 每个哈希表、列表、集合和有序集合可以容纳232元素。 换句话说，Redis极限容量就是系统可用内存。 为什么从实例与主实例拥有不同数量键？如果你使用有生存周期的键，这就是正常现象。这就导致主从实例键的数量不一致原因。 主实例在第一次与从实例同步时生成RDB文件。 RDB文件不包含已经过期的键，但是已经过期的键仍然在内存中。 尽管这些键从逻辑上说已经过期失效，但是还在Redis主实例内存中，他们并不被识别为存在的，当增量或访问这些键时这些键会被回收。尽管从逻辑上说这些键不是数据集一部分，但是INFO和DBSIZE命令结果包含这些信息。 当从实例读取主实例生成的RDB文件时，过期键不会被载入。 为很多键设置过期属性，通常为用户提供了在从实例上存储更少键，但是实际上实例内容没有逻辑区别。 *Redis实际含义是什么？Redis是远程数据字典服务器（REmote DIctionary Server）。 为什么启动Redis项目？最初启动Redis，是为了扩大LLOOGG。但是当我完成了基本服务端工作后，我喜欢把这个想法分享给其他人，然后Redis转变成开源项目。 Redis 如何发音？Redis 读作颜色的”red”，然后是 “iss”。"},{"title":"Java 使用 Redis","path":"/wiki/redis/java-redis.html","content":"Java 使用 Redis开始在 Java 中使用 Redis 前， 我们需要确保已经安装了 redis 服务及 Java redis 驱动，且你的机器上能正常使用 Java。 安装首先，安装 Redis 的 java 驱动。 首先你需要下载驱动包 下载 jedis.jar，确保下载最新驱动包。 在你的 classpath 中包含该驱动包。 连接到 Redis 服务import redis.clients.jedis.Jedis; public class RedisJava public static void main(String[] args) //Connecting to Redis server on localhost Jedis jedis = new Jedis(localhost); System.out.println(Connection to server sucessfully); //check whether server is running or not System.out.println(Server is running: +jedis.ping()); 编译并运行程序。可以根据需要修改你的路径。我们假设 jedis.jar 在当前路径中。 $javac RedisJava.java $java RedisJava Connection to server sucessfully Server is running: PONG Redis Java String 实例import redis.clients.jedis.Jedis; public class RedisStringJava public static void main(String[] args) //Connecting to Redis server on localhost Jedis jedis = new Jedis(localhost); System.out.println(Connection to server sucessfully); //set the data in redis string jedis.set(tutorial-name, Redis tutorial); // Get the stored data and print it System.out.println(Stored string in redis:: + jedis.get(tutorial-name)); 编译和运行上面的程序 $javac RedisStringJava.java $java RedisStringJava Connection to server sucessfully Stored string in redis:: Redis tutorial Redis Java List 实例import redis.clients.jedis.Jedis; public class RedisListJava public static void main(String[] args) //Connecting to Redis server on localhost Jedis jedis = new Jedis(localhost); System.out.println(Connection to server sucessfully); //store data in redis list jedis.lpush(tutorial-list, Redis); jedis.lpush(tutorial-list, Mongodb); jedis.lpush(tutorial-list, Mysql); // Get the stored data and print it ListString list = jedis.lrange(tutorial-list, 0 ,5); for(int i = 0; ilist.size(); i++) System.out.println(Stored string in redis:: +list.get(i)); 编译和运行程序 $javac RedisListJava.java $java RedisListJava Connection to server sucessfully Stored string in redis:: Redis Stored string in redis:: Mongodb Stored string in redis:: Mysql Redis Java Keys 实例import redis.clients.jedis.Jedis; public class RedisKeyJava public static void main(String[] args) //Connecting to Redis server on localhost Jedis jedis = new Jedis(localhost); System.out.println(Connection to server sucessfully); //store data in redis list // Get the stored data and print it ListString list = jedis.keys(*); for(int i = 0; ilist.size(); i++) System.out.println(List of stored keys:: +list.get(i)); 编译和运行程序 $javac RedisKeyJava.java $java RedisKeyJava Connection to server sucessfully List of stored keys:: tutorial-name List of stored keys:: tutorial-list"},{"title":"Redis 分区","path":"/wiki/redis/partitioning.html","content":"redis分区分区用于将 Redis 数据拆分为多个 Redis 实例，以便每个实例仅包含一部分 key。 它通常用于大型数据库。 分区类型redis 中有两种类型的分区： 范围分区 哈希分区 范围分区范围分区是执行分区的最简单方法之一。它通过将对象的范围映射到特定的 Redis 实例来完成。 例如： 假设您有 3000 个用户。因此，您可以说从 ID 0 到 ID 1000 的用户将进入实例 R0，而用户表单 ID 1001 到 ID 2000 将进入实例 R1，用户表单 ID 2001 到 ID 3000 将进入实例 R2，依此类推。 哈希分区散列分区是 Range 分区的替代方法。在散列分区中，散列函数用于将 key 转换为数字，然后将数据存储在不同的 Redis 实例中。 Redis分区的优点 分区有助于您使用多台计算机的集体内存。例如：对于较大的数据库，您需要大量内存，因此分区可以提供来自不同计算机的内存总和。如果不进行分区，则只能使用单台计算机可以支持的有限内存量。 分区还用于将计算能力扩展到多个核心和多个计算机，以及网络带宽扩展到多个计算机和网络适配器。 Redis分区的缺点分区存在一些缺点，因为 Redis 的某些功能受到分区的阻碍。 分区通常不支持具有多个键的操作。例如，如果两个集合存储在映射到不同 Redis 实例的键中，则无法执行它们之间的交集。 分区不支持具有多个 key 的事务。 分区粒度是关键，因此不可能使用单个巨大的 key（如非常大的有序集）对数据集进行分片。 使用分区时，数据处理更复杂，例如，您必须处理多个 RDB AOF 文件，并且需要从多个实例和主机聚合持久性文件来备份数据。 添加和删除容量可能很复杂。例如，Redis Cluster 支持大多数透明的数据重新平衡，能够在运行时添加和删除节点，但客户端分区和代理等其他系统不支持此功能。然而，一种称为预分片的技术在这方面有所帮助。"},{"title":"Redis 持久化","path":"/wiki/redis/persistence.html","content":"Redis 持久化redis 提供了两种持久化的方式，分别是RDB（Redis DataBase）和AOF（Append Only File）。 RDB，简而言之，就是在不同的时间点，将 redis 存储的数据生成快照并存储到磁盘等介质上； AOF，则是换了一个角度来实现持久化，那就是将 redis 执行过的所有写指令记录下来，在下次 redis 重新启动时，只要把这些写指令从前到后再重复执行一遍，就可以实现数据恢复了。 其实 RDB 和 AOF 两种方式也可以同时使用，在这种情况下，如果 redis 重启的话，则会优先采用 AOF 方式来进行数据恢复，这是因为 AOF 方式的数据恢复完整度更高。 如果你没有数据持久化的需求，也完全可以关闭 RDB 和 AOF 方式，这样的话，redis 将变成一个纯内存数据库，就像 memcache 一样。 redis持久化RDBRDB 方式，是将 redis 某一时刻的数据持久化到磁盘中，是一种快照式的持久化方法。 redis 在进行数据持久化的过程中，会先将数据写入到一个临时文件中，待持久化过程都结束了，才会用这个临时文件替换上次持久化好的文件。正是这种特性，让我们可以随时来进行备份，因为快照文件总是完整可用的。 对于 RDB 方式，redis 会单独创建（fork）一个子进程来进行持久化，而主进程是不会进行任何 IO 操作的，这样就确保了 redis 极高的性能。 如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，那 RDB 方式要比 AOF 方式更加的高效。 虽然 RDB 有不少优点，但它的缺点也是不容忽视的。如果你对数据的完整性非常敏感，那么 RDB 方式就不太适合你，因为即使你每 5 分钟都持久化一次，当 redis 故障时，仍然会有近 5 分钟的数据丢失。所以，redis 还提供了另一种持久化方式，那就是 AOF。 redis持久化 AOFAOF，英文是 Append Only File，即只允许追加不允许改写的文件。 如前面介绍的，AOF 方式是将执行过的写指令记录下来，在数据恢复时按照从前到后的顺序再将指令都执行一遍，就这么简单。 我们通过配置 redis.conf 中的 appendonly yes 就可以打开 AOF 功能。如果有写操作（如 SET 等），redis 就会被追加到 AOF 文件的末尾。 默认的 AOF 持久化策略是每秒钟 fsync 一次（fsync 是指把缓存中的写指令记录到磁盘中），因为在这种情况下，redis 仍然可以保持很好的处理性能，即使 redis 故障，也只会丢失最近 1 秒钟的数据。 如果在追加日志时，恰好遇到磁盘空间满、inode 满或断电等情况导致日志写入不完整，也没有关系，redis 提供了 redis-check-aof 工具，可以用来进行日志修复。 因为采用了追加方式，如果不做任何处理的话，AOF 文件会变得越来越大，为此，redis 提供了 AOF 文件重写（rewrite）机制，即当 AOF 文件的大小超过所设定的阈值时，redis 就会启动 AOF 文件的内容压缩，只保留可以恢复数据的最小指令集。举个例子或许更形象，假如我们调用了 100 次 INCR 指令，在 AOF 文件中就要存储 100 条指令，但这明显是很低效的，完全可以把这 100 条指令合并成一条 SET 指令，这就是重写机制的原理。 在进行 AOF 重写时，仍然是采用先写临时文件，全部完成后再替换的流程，所以断电、磁盘满等问题都不会影响 AOF 文件的可用性，这点大家可以放心。 AOF 方式的另一个好处，我们通过一个“场景再现”来说明。某同学在操作 redis 时，不小心执行了 FLUSHALL，导致 redis 内存中的数据全部被清空了，这是很悲剧的事情。不过这也不是世界末日，只要 redis 配置了 AOF 持久化方式，且 AOF 文件还没有被重写（rewrite），我们就可以用最快的速度暂停 redis 并编辑 AOF 文件，将最后一行的 FLUSHALL 命令删除，然后重启 redis，就可以恢复 redis 的所有数据到 FLUSHALL 之前的状态了。是不是很神奇，这就是 AOF 持久化方式的好处之一。但是如果 AOF 文件已经被重写了，那就无法通过这种方法来恢复数据了。 虽然优点多多，但 AOF 方式也同样存在缺陷，比如在同样数据规模的情况下，AOF 文件要比 RDB 文件的体积大。而且，AOF 方式的恢复速度也要慢于 RDB 方式。 如果你直接执行 BGREWRITEAOF 命令，那么 redis 会生成一个全新的 AOF 文件，其中便包括了可以恢复现有数据的最少的命令集。 如果运气比较差，AOF 文件出现了被写坏的情况，也不必过分担忧，redis 并不会贸然加载这个有问题的 AOF 文件，而是报错退出。这时可以通过以下步骤来修复出错的文件： 1.备份被写坏的 AOF 文件\\ 2.运行 redis-check-aof –fix 进行修复\\ 3.用 diff -u 来看下两个文件的差异，确认问题点\\ 4.重启 redis，加载修复后的 AOF 文件 redis持久化 – AOF重写AOF 重写的内部运行原理，我们有必要了解一下。 在重写即将开始之际，redis 会创建（fork）一个“重写子进程”，这个子进程会首先读取现有的 AOF 文件，并将其包含的指令进行分析压缩并写入到一个临时文件中。 与此同时，主工作进程会将新接收到的写指令一边累积到内存缓冲区中，一边继续写入到原有的 AOF 文件中，这样做是保证原有的 AOF 文件的可用性，避免在重写过程中出现意外。 当“重写子进程”完成重写工作后，它会给父进程发一个信号，父进程收到信号后就会将内存中缓存的写指令追加到新 AOF 文件中。 当追加结束后，redis 就会用新 AOF 文件来代替旧 AOF 文件，之后再有新的写指令，就都会追加到新的 AOF 文件中了。 redis持久化 – 如何选择RDB和AOF对于我们应该选择 RDB 还是 AOF，官方的建议是两个同时使用。这样可以提供更可靠的持久化方案。"},{"title":"PHP 使用 Redis","path":"/wiki/redis/php-redis.html","content":"php 操作 Redis开始在PHP 中连接 Redis 前， 需要确保你的机器上已经安装了 redis PHP 驱动并配置了 PHP 环境。 接下来让我们安装 PHP redis驱动：下载地址为:https://github.com/phpredis/phpredis/releases。 安装PHP 如何安装配置 Redis PHP 驱动。 PHP redis 驱动下载地址为:https://github.com/phpredis/phpredis/releases。下载完成后，解压文件到 phpredis 目录。 cd phpredis sudo phpize sudo ./configure sudo make sudo make install 拷贝“modules” 目录中的内容到 PHP extension 目录，并修改 php.ini 增加 extension = redis.so Redis PHP 驱动安装完成。 连接到 Redis 服务?php //Connecting to Redis server on localhost $redis = new Redis(); $redis-connect(127.0.0.1, 6379); echo Connection to server sucessfully; //check whether server is running or not echo Server is running: .$redis-ping(); ? 执行，输出如下： Connection to server sucessfully Server is running: PONG Redis PHP String 实例?php //Connecting to Redis server on localhost $redis = new Redis(); $redis-connect(127.0.0.1, 6379); echo Connection to server sucessfully; //set the data in redis string $redis-set(tutorial-name, Redis tutorial); // Get the stored data and print it echo Stored string in redis:: .$redis-get(tutorial-name); ? 执行，输出如下： Connection to server sucessfully Stored string in redis:: Redis tutorial Redis php List 实例?php //Connecting to Redis server on localhost $redis = new Redis(); $redis-connect(127.0.0.1, 6379); echo Connection to server sucessfully; //store data in redis list $redis-lpush(tutorial-list, Redis); $redis-lpush(tutorial-list, Mongodb); $redis-lpush(tutorial-list, Mysql); // Get the stored data and print it $arList = $redis-lrange(tutorial-list, 0 ,5); echo Stored string in redis:: ; print_r($arList); ? 执行，输出如下： Connection to server sucessfully Stored string in redis:: Redis Mongodb Mysql Redis PHP Keys 实例?php //Connecting to Redis server on localhost $redis = new Redis(); $redis-connect(127.0.0.1, 6379); echo Connection to server sucessfully; // Get the stored keys and print it $arList = $redis-keys(*); echo Stored keys in redis:: print_r($arList); ? 执行，输出如下： Connection to server sucessfully Stored string in redis:: tutorial-name tutorial-list"},{"title":"Redis 流水线","path":"/wiki/redis/pipelining.html","content":"Redis Pipelining 流水线在了解流水线之前，首先要了解 Redis 的概念： Redis 是一个支持请求响应协议的 TCP 服务器。在 Redis 中，请求分两步完成： 客户端通常以阻塞方式向服务器发送命令。 服务器处理该命令并将响应发送回客户端。 什么是流水线流水线操作有助于客户端向服务器发送多个请求，而无需等待回复，最后只需一步即可读取回复。 例 让我们看一下 Redis 流水线的例子。在这个例子中，我们将向 Redis 提交一次命令，Redis 将在一个步骤中提供所有命令的输出。 打开 Redis 终端并使用以下命令： （echo -en PING \\r SET sssit javatraining \\r GET sssit \\r INCR visitor \\r INCR visitor \\r INCR visitor \\r ; sleep 10 ）| nc localhost 6379 这里： PING 命令用于检查 Redis 连接。 设置名为“sssit”的字符串，其值为“javatraining”。 获得了 key 值并将访问者数量增加了三倍。 每次增加值时都可以看到。 流水线的优势Redis 流水线操作的主要优点是提高了 Redis 的性能。由于多个命令同时执行，它极大地提高了协议性能。 Pipelining vs ScriptingRedis Scripting 可在 Redis 2.6 或更高版本中使用。 脚本的主要优点是它可以以最小的延迟同时读取和写入数据。它使读取，计算，写入等操作变得非常快。 在流水线操作中，客户端在调用 write 命令之前需要 read 命令的回复。"},{"title":"Redis 和 Elasticsearch","path":"/wiki/redis/redis-vs-elasticsearch.html","content":"redis 和 Elasticsearch 比较Redis和Elasticsearch是两个不同类型的数据存储和搜索引擎，它们在数据模型、搜索功能、性能和适用场景等方面有明显的区别。下面是Redis和Elasticsearch之间的一些比较： 数据模型： Redis：Redis是一个键值存储系统，支持多种数据结构如字符串、哈希、列表、集合和有序集合。数据以键值对的形式存储，适合用于缓存和快速数据读写。 Elasticsearch：Elasticsearch是一个分布式搜索和分析引擎，以文档的形式存储数据。每个文档都是一个结构化的JSON对象，可以进行全文搜索和复杂的查询。 搜索和查询功能： Redis：Redis提供基本的查询功能，如对字符串的模糊匹配和对集合的交并差等操作。然而，它并不是一个专门的搜索引擎，不支持全文搜索和复杂的查询。 Elasticsearch：Elasticsearch是一个专门为搜索和查询而设计的引擎。它支持全文搜索、关键字搜索、复杂的查询语法、聚合和分析等功能。具有高效的搜索性能和强大的查询语言。 分布式和扩展性： Redis：Redis可以通过主从复制和分片来实现水平扩展和高可用性。但是，它的分布式能力相对有限，主要用于缓存和简单的数据存储。 Elasticsearch：Elasticsearch是为分布式环境设计的，可以轻松扩展到多个节点。它使用分片和复制机制来实现数据的分布和冗余存储，支持大规模数据存储和高吞吐量的搜索。 文本分析和聚合： Redis：Redis不提供文本分析和聚合功能，适合于简单的数据存储和缓存。 Elasticsearch：Elasticsearch提供丰富的文本分析和聚合功能，可以处理复杂的数据结构和大规模的数据集。支持对文本进行分词、语义分析、聚合操作等。 实时性： Redis：Redis以内存为基础，具有非常快速的读写速度，适合于实时数据的存储和访问。 Elasticsearch：Elasticsearch将数据持久化到磁盘，并提供近实时的索引和搜索能力。适合于大规模数据的搜索和分析，并支持实时数据流的处理。 总体来说，Redis适用于快速数据存储、缓存和简单查询的场景，而Elasticsearch适用于全文搜索、复杂查询、实时数据分析和聚合的场景。具体选择应根据实际需求和数据处理的复杂性进行评估。"},{"title":"Redis 和 Memcached","path":"/wiki/redis/redis-vs-memcached.html","content":"redis 和 memcached 比较Redis和Memcached都是常见的键值对存储系统，用于缓存数据。下面是Redis和Memcached之间的一些对比： 数据结构支持： Redis：支持多种数据结构，如字符串、哈希、列表、集合和有序集合等。这使得Redis在处理复杂数据和实现更多功能方面更加灵活。 Memcached：仅支持简单的键值对结构，只能存储字符串类型的数据。 持久化： Redis：提供持久化机制，支持快照（snapshotting）和AOF（Append-only file）两种方式。这样可以在服务器重启后恢复数据，防止数据丢失。 Memcached：不提供持久化支持，数据只存在于内存中。服务器重启后，所有数据将被清空。 内存管理： Redis：采用灵活的内存管理策略，可以将数据持久化到磁盘上，并在需要时从磁盘中加载数据。可以设置最大内存限制，并支持内存淘汰策略，如LRU（最近最少使用）。 Memcached：将所有数据存储在内存中，并且没有内存淘汰机制。当内存满时，新的数据无法存储，需要通过删除旧的数据来释放内存。 多线程支持： Redis：采用单线程模型，通过异步IO来实现高性能。它可以处理并发请求，并且没有锁竞争，因此具有较低的线程开销。 Memcached：采用多线程模型，使用线程池来处理并发请求。在高并发情况下，可以通过多线程处理请求提高吞吐量。 数据一致性： Redis：支持主从复制和Sentinel哨兵机制，可以实现数据的自动备份和故障转移，提供更高的可用性和数据一致性。 Memcached：不支持自动备份和故障转移，不具备数据一致性保障。 生态系统和社区支持： Redis：拥有庞大的开源社区和丰富的生态系统，提供了许多工具、扩展和解决方案。有大量的文档和教程可用于参考。 Memcached：社区相对较小，生态系统相对简单。文档和教程相对较少。 综上所述，Redis相对于Memcached具有更多的功能和灵活性，支持多种数据结构、持久化机制、数据一致性和更丰富的生态系统。然而，对于简单的键值对缓存需求，Memcached的性能可能更高。选择Redis还是Memcached取决于具体的使用场景和需求。****"},{"title":"Redis 和 MongoDB","path":"/wiki/redis/redis-vs-mongodb.html","content":"redis 和 mongodb 比较Redis和MongoDB是两种不同类型的数据库，它们在数据存储和查询方式、数据模型以及适用场景等方面有一些明显的区别。下面是Redis和MongoDB之间的一些比较： 数据模型： Redis：Redis是一个键值存储系统，支持多种数据结构如字符串、哈希、列表、集合和有序集合。数据以键值对的形式存储，可以通过键快速访问数据。Redis适合用于缓存、会话存储和快速查询等场景。 MongoDB：MongoDB是一个面向文档的数据库，数据以类似JSON的BSON文档格式存储。每个文档都有一个唯一的ID，并且文档可以嵌套。MongoDB适合存储和查询复杂的数据结构和大规模数据集。 数据持久化： Redis：Redis支持持久化，可以将数据保存到磁盘上，以防止数据丢失。它提供了快照（snapshotting）和AOF（Append-only file）两种持久化方式。 MongoDB：MongoDB也支持持久化，将数据写入磁盘文件中。它使用写时复制（write-ahead logging）机制来保证数据的一致性和持久性。 查询功能： Redis：Redis提供了一些查询功能，如对字符串的模糊匹配、对集合的交并差等操作。然而，它并不是一个完整的查询语言，不支持复杂查询和索引，适合用于简单的数据检索。 MongoDB：MongoDB提供了强大的查询功能，支持丰富的查询语法和索引，可以进行复杂的查询操作，包括范围查询、正则表达式、聚合管道等。 扩展性： Redis：Redis采用单线程模型，通过异步IO来实现高性能。它可以通过主从复制和分片来扩展读性能和存储容量。 MongoDB：MongoDB采用分布式架构，支持水平扩展和分片。它可以在集群中添加更多的节点来扩展存储和处理能力。 事务支持： Redis：Redis支持事务，可以将多个操作组合成一个原子性的操作序列。但是，Redis的事务是非严格的，即事务中的某个操作失败不会回滚其他操作。 MongoDB：MongoDB支持多文档事务，可以对多个文档进行原子性操作，保证事务的一致性。 数据一致性： Redis：Redis默认情况下是单机数据库，数据复制和故障恢复依赖于主从复制和Sentinel哨兵机制。在主节点故障时，可能会出现一段时间的数据不一致。 MongoDB：MongoDB支持复制集和分片集群，在故障时可以实现数据的自动备份和故障转移，提供更高的数据一致性和可用性。 总体来说，Redis适用于高性能的键值存储和缓存场景，而MongoDB适用于更复杂的数据存储和查询需求，特别是对复杂数据结构和丰富查询功能的支持。具体选择应根据实际应用需求和数据模型的特点进行评估。"},{"title":"Redis 安全","path":"/wiki/redis/security.html","content":"redis 设置密码对于数据库来说，安全性是非常必要的，以确保数据的安全性。它提供身份验证，因此如果客户端想要建立连接，则需要在执行命令之前进行身份验证。 您需要在配置文件中设置密码以保护 Redis 数据库。 例我们来看看如何保护您的 Redis 实例。 使用config get command config get requirepass 您可以看到上面的属性为空，表示我们没有此实例的任何密码。您可以通过执行以下命令来更改此属性并为此实例设置密码。 config set requirepass rediscomcn123 CONFIG get requirepass 当您设置此密码时，如果客户端在未经身份验证的情况下运行该命令，则会收到错误”NOAUTH Authentication required”。因此，客户端需要使用 AUTH 命令来验证自己。 AUTH命令的用法127.0.0.1:6379 AUTH rediscomcn123 OK 127.0.0.1:6379 SET mykey hindi100 OK 127.0.0.1:6379 GET mykey hindi100 127.0.0.1:6379 Redis 设置密码如何设置Redis密码并使用密码连接到Redis服务器？ Redis服务器默认不受密码保护，也就是没有设置密码。 有两种方法可以设置redis服务器的密码。 使用命令行 直接修改redis.conf文件 Redis设置或更改密码首先，检查是否使用auth-Password命令设置了密码 127.0.0.1:6379 auth password(error) ERR Client sent AUTH, but no password is set 返回错误表示没有为Redis服务器设置密码。 使用命令行设置密码 使用交互式cli，您可以使用CONFIG SET 更改密码 CONFIG SET requirepass 12345 requirepass 是用于更改密码的配置参数，设置密码实时生效。 重启失效，用永久生效需要保存设置到配置文件。 要保存这些更改,运行以下命令 CONFIG REWRITE 重新启动Redis后生效 使用redis.conf文件 Redis.conf文件包含与安全相关的带注释配置，如下所示 # requirepass foobared 需求注释,设置密码未1234567 requirepass 123467 保存文件。 重新启动或停止并启动服务器以重新加载更改。 现在，Redis服务器是受密码保护的。 任何想要与服务器通信的客户端都需要提供-a 密码选项。 redis-cli -h 127.0.0.1 -p 6379 -a 1234567"},{"title":"Redis 客户端连接","path":"/wiki/redis/client-connection.html","content":"Redis客户端连接Redis 可以在配置的监听 TCP 端口和 Unix 套接字上接受不同类型的客户端连接。 接受新客户端连接时，它将执行以下操作： 由于 Redis 使用多路复用和非阻塞 IO，因此客户端套接字处于非阻塞状态。 设置 TCP_NODELAY 选项是为了确保我们的连接没有延迟。 创建可读文件事件，以便一旦可以在套接字上读取新数据，Redis 就能够收集客户端查询。 最大客户端数在 Redis config（redis.conf）中，有一个名为 maxclients 的属性，它指定可以连接到 Redis 的客户端数量。 以下是命令的基本语法。 Config get maxclients maxclients 4064 最大客户端数取决于 OS 的最大文件描述符数限制。它的默认值为 10000，但您可以更改此属性。 例我们举一个例子，在启动服务器时将最大客户端数设置为 100000。 redis-server --maxclients 100000 Redis 客户端命令 命令 描述 CLIENT LIST 返回连接到 redis 服务的客户端列表 CLIENT SETNAME 设置当前连接的名称 CLIENT GETNAME 获取通过 CLIENT SETNAME 命令设置的服务名称 CLIENT PAUSE 挂起客户端连接，指定挂起的时间以毫秒计 CLIENT KILL 关闭客户端连接"},{"title":"2. Docker 核心技术","path":"/wiki/docker/coretech.html","content":"2. Docker 核心技术Docker核心是一个操作系统级虚拟化方法, 理解起来可能并不像VM那样直观。我们从虚拟化方法的四个方面： 隔离性 Namespace 可配额可度量 Cgroups 便携性 AUFS 安全性 AppArmor、SELinux、GRSEC 接下来将详细介绍Docker的技术细节。 2.1 隔离性 Linux namespace每个用户实例之间相互隔离, 互不影响。 一般的硬件虚拟化方法给出的方法是VM，而LXC给出的方法是container，更细一点讲就是kernel namespace。其中pid、net、ipc、mnt、uts、user等namespace将container的进程、网络、消息、文件系统、UTS(“UNIX Time-sharing System”)和用户空间隔离开。 pid namespace 不同用户的进程就是通过pid namespace隔离开的，且不同 namespace 中可以有相同pid。所有的LXC进程在docker中的父进程为docker进程，每个lxc进程具有不同的namespace。同时由于允许嵌套，因此可以很方便的实现 Docker in Docker。 net namespace 有了 pid namespace, 每个namespace中的pid能够相互隔离，但是网络端口还是共享host的端口。网络隔离是通过net namespace实现的， 每个net namespace有独立的 network devices, IP addresses, IP routing tables, procnet 目录。这样每个container的网络就能隔离开来。docker默认采用veth的方式将container中的虚拟网卡同host上的一个docker bridge: docker0连接在一起。 ipc namespace container中进程交互还是采用linux常见的进程间交互方法(interprocess communication - IPC), 包括常见的信号量、消息队列和共享内存。然而同 VM 不同的是，container 的进程间交互实际上还是host上具有相同pid namespace中的进程间交互，因此需要在IPC资源申请时加入namespace信息 - 每个IPC资源有一个唯一的 32 位 ID。 mnt namespace 类似chroot，将一个进程放到一个特定的目录执行。mnt namespace允许不同namespace的进程看到的文件结构不同，这样每个 namespace 中的进程所看到的文件目录就被隔离开了。同chroot不同，每个namespace中的container在procmounts的信息只包含所在namespace的mount point。 uts namespace UTS(“UNIX Time-sharing System”) namespace允许每个container拥有独立的hostname和domain name, 使其在网络上可以被视作一个独立的节点而非Host上的一个进程。 user namespace 每个container可以有不同的 user 和 group id, 也就是说可以在container内部用container内部的用户执行程序而非Host上的用户。 2.2 控制组 - Control Groups (cgroups) 可配额、可度量cgroups 实现了对资源的配额和度量。 cgroups 的使用非常简单，提供类似文件的接口，在 cgroup目录下新建一个文件夹即可新建一个group，在此文件夹中新建task文件，并将pid写入该文件，即可实现对该进程的资源控制。groups可以限制blkio、cpu、cpuacct、cpuset、devices、freezer、memory、net_cls、ns九大子系统的资源，以下是每个子系统的详细说明： blkio 这个子系统设置限制每个块设备的输入输出控制。例如:磁盘，光盘以及usb等等。 cpu 这个子系统使用调度程序为cgroup任务提供cpu的访问。 cpuacct 产生cgroup任务的cpu资源报告。 cpuset 如果是多核心的cpu，这个子系统会为cgroup任务分配单独的cpu和内存。 devices 允许或拒绝cgroup任务对设备的访问。 freezer 暂停和恢复cgroup任务。 memory 设置每个cgroup的内存限制以及产生内存资源报告。 net_cls 标记每个网络包以供cgroup方便使用。 ns 名称空间子系统。 以上九个子系统之间也存在着一定的关系.详情请参阅官方文档。 2.3 便携性: AUFSAUFS (AnotherUnionFS) 是一种 Union FS。 简单来说就是支持将不同目录挂载到同一个虚拟文件系统下(unite several directories into a single virtual filesystem)的文件系统, 更进一步的理解, AUFS支持为每一个成员目录(类似Git Branch)设定readonly、readwrite 和 whiteout-able 权限, 同时 AUFS 里有一个类似分层的概念, 对 readonly 权限的 branch 可以逻辑上进行修改(增量地, 不影响 readonly 部分的)。 通常 Union FS 有两个用途, 一方面可以实现不借助 LVM、RAID 将多个disk挂到同一个目录下, 另一个更常用的就是将一个 readonly 的 branch 和一个 writeable 的 branch 联合在一起，Live CD正是基于此方法可以允许在 OS image 不变的基础上允许用户在其上进行一些写操作。 Docker 在 AUFS 上构建的 container image 也正是如此，接下来我们从启动 container 中的 linux 为例来介绍 docker 对AUFS特性的运用。 典型的启动Linux运行需要两个FS: bootfs + rootfs: bootfs (boot file system) 主要包含 bootloader 和 kernel, bootloader主要是引导加载kernel, 当boot成功后 kernel 被加载到内存中后 bootfs就被umount了. rootfs (root file system) 包含的就是典型 Linux 系统中的 dev, proc,bin, etc 等标准目录和文件。 对于不同的linux发行版, bootfs基本是一致的, 但rootfs会有差别, 因此不同的发行版可以公用bootfs 如下图: 典型的Linux在启动后，首先将 rootfs 设置为 readonly, 进行一系列检查, 然后将其切换为 “readwrite” 供用户使用。在Docker中，初始化时也是将 rootfs 以readonly方式加载并检查，然而接下来利用 union mount 的方式将一个 readwrite 文件系统挂载在 readonly 的rootfs之上，并且允许再次将下层的 FS(file system) 设定为readonly 并且向上叠加, 这样一组readonly和一个writeable的结构构成一个container的运行时态, 每一个FS被称作一个FS层。如下图: 得益于AUFS的特性, 每一个对readonly层文件目录的修改都只会存在于上层的writeable层中。这样由于不存在竞争, 多个container可以共享readonly的FS层。 所以Docker将readonly的FS层称作 “image” - 对于container而言整个rootfs都是read-write的，但事实上所有的修改都写入最上层的writeable层中, image不保存用户状态，只用于模板、新建和复制使用。 上层的image依赖下层的image，因此Docker中把下层的image称作父image，没有父image的image称作base image。因此想要从一个image启动一个container，Docker会先加载这个image和依赖的父images以及base image，用户的进程运行在writeable的layer中。所有parent image中的数据信息以及 ID、网络和lxc管理的资源限制等具体container的配置，构成一个Docker概念上的container。如下图: 2.4 安全性: AppArmor, SELinux, GRSEC安全永远是相对的，这里有三个方面可以考虑Docker的安全特性: 由kernel namespaces和cgroups实现的Linux系统固有的安全标准; Docker Deamon的安全接口; Linux本身的安全加固解决方案,类如AppArmor, SELinux; 由于安全属于非常具体的技术，这里不在赘述，请直接参阅Docker官方文档。"},{"title":"3. Docker 服务安装","path":"/wiki/docker/install.html","content":"3. Docker 服务安装3.1 CentOS系统3.1.1 参考官方文档地址：https://docs.docker.com/engine/install/centos/ 3.1.2 如果存在旧版docker请先卸载sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 3.1.3 设置docker yum源（二选一）设置为阿里云的源速度可以快一点（推荐） sudo yum install -y yum-utilssudo yum-config-manager \\--add-repo \\http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 如果不想阿里云的源，也可用官方源（可能遇到网络问题） sudo yum install -y yum-utilssudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo 3.1.4 安装dockersudo yum install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin 3.1. 5 启动dockersudo systemctl start docker 3.1.6 设置开机自启动sudo systemctl enable docker 3.1.7 查看版本docker -vdocker info 3.2 Ubuntu系统在Ubuntu 20.04上使用国内源安装Docker，可以使用清华大学源或阿里云源，具体如下。 3.2.1 先更新软件包，安装备要apt软件# 更新软件包索引sudo apt-get update # 安装需要的软件包以使apt能够通过HTTPS使用仓库sudo apt-get install ca-certificates curl gnupg lsb-release 3.2.2 选择安装源 使用清化大学源 # 添加Docker官方的GPG密钥curl -fsSL https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg # 设置稳定版仓库echo deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/ubuntu $(lsb_release -cs) stable | sudo tee /etc/apt/sources.list.d/docker.list /dev/null 使用阿里云源 # 添加阿里云官方GPG密钥curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add - # 写入阿里云Docker仓库地址sudo sh -c echo deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable /etc/apt/sources.list.d/docker.list 3.2.3 更新源并安装Dockersudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io# 验证是否成功安装了dockersudo systemctl status dockerdocker --version 3.2.4 修改docker的配置文件修改docker的/etc/docker/daemon.json配置文件，如果在不存在则手动创建，文件内容如下： # 修改daemon.json文件，vim /etc/docker/daemon.json# daemon.json内容如下： registry-mirrors: [ https://dockerproxy.com, https://docker.m.daocloud.io, https://cr.console.aliyun.com, https://ccr.ccs.tencentyun.com, https://hub-mirror.c.163.com, https://mirror.baidubce.com, https://docker.nju.edu.cn, https://docker.mirrors.sjtug.sjtu.edu.cn, https://github.com/ustclug/mirrorrequest, https://registry.docker-cn.com ] 3.2.5 重载配置文件，并重启 dockersudo systemctl daemon-reloadsudo systemctl restart docker 3.2.6 查看 Registry Mirrors 配置是否成功sudo docker info"},{"title":"1. Docker 简介","path":"/wiki/docker/introduction.html","content":"1. Docker 简介1.1 由PaaS到Container2013年2月，前Gluster的CEO Ben Golub 和 dotCloud 的 CEO Solomon Hykes 坐在一起聊天时，Solomon谈到想把 dotCloud 内部使用的Container容器技术单独拿出来开源，然后围绕这个技术开一家新公司提供技术支持。28岁点Solomon在使用python开发dotCloud的PaaS云时发现，使用LXC（Linux Container）技术可以打破产品发布过程中应用工程师和系统工程师两者之间无法轻松协作发布产品的难题。这个Container容器技术可以把开发者从日常部署的繁杂工作中解脱出来，让开发者能专心写好程序；从系统工程师到角度来看也是一样的，他们迫切需要从各种混乱的部署中解脱出来，让系统工程师专注在应用的水平扩展、稳定发布的解决方案上。他们深入交谈，觉得这是一次云技术的变革，紧接着在2013年3月Docker0.1发布，拉开来基于云计算平台发布产品方式的变革序幕。 1.2 Docker 简介 Docker时Docker.lnc公司开源的一个基于LXC技术之上搭建的Container容器引擎，源代码托管在Github上，基于Go语言并遵从Apache2.0协议开源。Docker在2014年6月召开DockerConf2014技术大会吸引了IBM、Google、RedHat等业界知名公司的关注和技术支持，无论是从Github上到代码活跃度，还是RedHat宣布REHL7中正式支持Docker，都给业界一个信号，这是一项创新的技术解决方案。就连Google公司的Computer Engine 也支持Docker在其中之上运行，国内BAT先锋企业百度 Baidu App Engine（BAE）平台也是以 Docker作为PasS云基础。 1.3 Docker产生的目的就是要解决以下问题：1）环境管理复杂：从各种OS到各种中间件再到各种App，一款产品能够成功发布，作为开发者需要关心的东西太多，且难于管理，这个问题在软件行业中普遍存在并需要直接面对。Docker可以简化部署多种应用实例工作，比如Web应用、后台应用、数据库应用、大数据应用比如Hadoop集群、消息队列等等都可以打包成一个image部署。如下图所示： 2）云时代的到来：AWS的成功，引到开发者将应用转移到云上，解决来硬件管理的问题，然而软件配置和管理香瓜的问题依然存在。Docker的出现正好能帮助软件开发者开阔思路，尝试新的软件管理方法来解决这个问题。 3）虚拟化手段的变化：云时代采用标配硬件来降低成本，采用虚拟化手段来满足用户按需分配的资源需求以及保证可用性和隔离性。然而无论是KVM还是Xen，在Docker卡来都是在浪费资源，因为用户需要的是高校运行环境而非OS，GuestOS即浪费资源，又难于管理，更加轻量级大LXC更佳灵活和快速： 4）LXC的便携性: LXC在 Linux 2.6 的 Kernel 里就已经存在了，但是其设计之初并非为云计算考虑的，缺少标准化的描述手段和容器的可便携性，决定其构建出的环境难于分发和标准化管理(相对于KVM之类image和snapshot的概念)。Docker就在这个问题上做出了实质性的创新方法。"},{"title":"4. Docker 镜像管理","path":"/wiki/docker/images.html","content":"4. Docker 镜像管理镜像是 Docker 的三大组件之一。 Docker 运行容器前需要本地存在对应的镜像，如果镜像不存在本地，Docker 会从镜像仓库下载（默认是 Docker Hub 公共注册服务器中的仓库），我们也可以搭建一个本地的镜像仓库，但这不是本文的重点。本文将以镜像为中心介绍： 如何构建基础镜像 Dockerfile的基本结构以及详解 利用Dockerfile构建镜像 4.1 构建基础镜像我将应用打包到镜像中形成我们所需的镜像，往往需要一个基础的镜像作为我们应用服务的外部环境，那么问题来了，基础镜像从何而来？官方推荐的是直接从官网仓库pull一个，但由于官网被墙的比较厉害，所以这里介绍一些官方提供以及个人方法。 1.使用Debootstrap来创建Ubuntu的base image $ sudo debootstrap raring raring /dev/null$ sudo tar -C raring -c . | docker import - raringa29c15f1bf7a$ docker run raring cat /etc/lsb-releaseDISTRIB_ID=UbuntuDISTRIB_RELEASE=13.04DISTRIB_CODENAME=raringDISTRIB_DESCRIPTION=Ubuntu 13.04 在docker github上有更多有关基础镜像的介绍 BusyBox CentOS Scientific Linux CERN (SLC) on DebianUbuntu or on CentOSRHELSLCetc. Debian Ubuntu 2.使用scratch创建base image 在Docker registry中有一个scratch，你可以pull拉取下来， $ sudo docker pull scratch 甚至可以自己制作 $ tar cv --files-from /dev/null | docker import - scratch Scratch镜像很赞，它简洁、小巧而且快速， 它没有bug、安全漏洞、延缓的代码或技术债务。这是因为它基本上是空的。除了Docker添加了点的metadata (译注：元数据为描述数据的数据)。总之它是非常小的一个Docker镜像。 为Scratch镜像创建内容，具体Dockerfile命令如下: FROM scratchADD hello /CMD [/hello] 3.下载官方提提供的OS的tar文件 到OPENVZ上下载基础包然后使用docker limport 加载到本地镜像，这里以ubuntu14.04 为例，从openvz下载一个ubuntu14.04的模板： wget http://download.openvz.org/template/precreated/ubuntu-14.04-x86_64.tar.gzcat ubuntu-14.04-x86_64-minimal.tar.gz | docker import - ubuntu:base 4.2 Dockerfile文件结构Dockerfile 由一行行命令语句组成，并且支持以 # 开头的注释行。 一般的，Dockerfile 分为四部分：基础镜像信息、维护者信息、镜像操作指令和容器启动时执行指令。 例如: # This dockerfile uses the ubuntu image# VERSION 2 - EDITION 1# Author: docker_user# Command format: Instruction [arguments / command] ..# Base image to use, this must be set as the first lineFROM ubuntu# Maintainer: docker_user docker_user at email.com (@docker_user)MAINTAINER docker_user [email protected]# Commands to update the imageRUN echo deb http://archive.ubuntu.com/ubuntu/ raring main universe /etc/apt/sources.listRUN apt-get update apt-get install -y nginxRUN echo daemon off; /etc/nginx/nginx.conf# Commands when creating a new containerCMD /usr/sbin/nginx 其中，一开始必须指明所基于的镜像名称，接下来推荐说明维护者信息。 后面则是镜像操作指令，例如 RUN 指令，RUN 指令将对镜像执行跟随的命令。每运行一条 RUN 指令，镜像添加新的一层，并提交。 最后是 CMD 指令，来指定运行容器时的操作命令。 下面是一个更复杂的例子 # Nginx## VERSION 0.0.1FROM ubuntuMAINTAINER Victor Vieux [email protected]RUN apt-get update apt-get install -y inotify-tools nginx apache2 openssh-server# Firefox over VNC## VERSION 0.3FROM ubuntu# Install vnc, xvfb in order to create a fake display and firefoxRUN apt-get update apt-get install -y x11vnc xvfb firefoxRUN mkdir /.vnc# Setup a passwordRUN x11vnc -storepasswd 1234 ~/.vnc/passwd# Autostart firefox (might not be the best way, but it does the trick)RUN bash -c echo firefox /.bashrcEXPOSE 5900CMD [x11vnc, -forever, -usepw, -create]# Multiple images example## VERSION 0.1FROM ubuntuRUN echo foo bar# Will output something like === 907ad6c2736fFROM ubuntuRUN echo moo oink# Will output something like === 695d7793cbe4# You᾿ll now have two images, 907ad6c2736f with /bar, and 695d7793cbe4 with# /oink. 4.3 Dockerfile 操作建议Docker可以读取一个Dockerfile文件来构建所需的镜像，这个文件里包含所有所需要的指令。Dockerfile文件用特有的格式来设置镜像信息，更多基础知识在 Dockerfile 参数详解 会详细展示。 本文包含Docker官方提供的一些践以及方法，我们强烈建议你去参照这些建议。 官方建议： 一个Dockerfile文件尽量越简洁越好，这意味着 它可以被停止销毁，然后被最小化配置安装到另一个地方。 在通常情况下，最好把Dockerfile文件放到一个空目录，然后，将构建镜像所需要动文件添加到该目录。为了提高构建性能，你也可以通过添加.dockerignore文件到该目录以排除文件和目录，该文件支持排斥的模式类似于.gitignore文件。 为了减少镜像复杂度、依赖、文件大小和构建时间，应该尽量避免安装多余的不需要包，例如：你不需要在一个数据库镜像中添加一个文本编辑器。 在绝大多数情况下，每一个镜像只跑一个process，应用于多个容器中可以方边应用横向扩展和重复利用容器。如果该服务依赖于其他服务，请使用容器互联。 你需要在Dockerfile的可读性和镜像层次最小化之间取得平衡，要有目的且非常谨慎的控制使用分层的数量 尽可能缓解由字母数字排序的多行参数后的变化。这将帮助你避免包的重复，使列表更容易更新。这也使得PRs更容易审查。在一个空格前面加一个反斜杠能起到帮助。 下面是来自buildpack-DEPS镜像中的例子： RUN apt-get update apt-get install -y \\bzr \\cvs \\git \\mercurial \\subversion 构建缓存 在构建镜像时，进程将为Dockerfile内每一个指定的执行步骤构建一个镜像 。由于执行每条指令都会对它缓存内现有镜像进行检查，所以镜像可以重复利用 ，而不是创建一个重复的镜像。如果你不想使用缓存，请在docker build 时使用--no-cach=true 选项。 但是，如果你让Docker使用构建缓存找到匹配的镜像，你应该了解它什么时候需要，什么时候不需要，所以要遵循以下规则： 从缓存中启动一个基础镜像，执行下一条指令，比与上一层所有子镜像对比，查看是否有与已经存在的镜像相同 ，如果不同，缓存将失效。 在大多数情况下，只需要简单地比较Dockerfile指令与其中一个子镜像就够了，但是，某些指令需要更多解释： 对于ADD和COPY指令，镜像中的文件每个的内容将全部检查 。文件的某些信息是不检查的：最近更新时间和最后访问时间。在查找缓存期间，Docker会与已经存在的镜像文件进行校验，如果文件被更改，例如内容或元数据，那么缓存也将失效 。除此之外，ADD和COPY指令缓存将不会查看容器内文件来匹配缓存。例如，当执行一个 RUN apt-get -y 指令时，不会检查容器内文件更新来确定缓存是否存在。在这种情况下，将使用指令字符串本身来查找缓存匹配。 上文所提到动缓存失效，是指后续指令将会产生新的镜像文件，缓存将不会被使用 。 4.3.1 镜像文件的大小Dockerfile 与镜像 Dockerfile 由多条指令构成，随着深入研究 Dockerfile 与镜像的关系，很快大家就会发现，Dockerfile 中的每一条指令都会对应于 Docker 镜像中的一层 。 以如下 Dockerfile 为例： FROM ubuntu:14.04ADD run.sh /VOLUME /dataCMD [./run.sh] 通过 docker build 以上 Dockerfile 的时候，会在 ubuntu:14.04 镜像基础上，添加三层独立的镜像，依次对应于三条不同的命令。镜像示意图如下： 有了 Dockerfile 与镜像关系的初步认识之后，我们再进一步联系到每一层镜像的大小。 不得不说，在层级化管理的 Docker 镜像中，有不少层大小都为 0。那些镜像层大小不为 0 的情况，归根结底的原因是：构建 Docker 镜像时，对当前的文件系统造成了修改更新 。而修改更新的情况主要有两种： ADD或 COPY 命令：ADD 或者 COPY 的作用是在docker build 构建镜像时向容器中添加内容 ，只要内容添加成功，当前构建的那层镜像就是添加内容的大小 ，如以上命令 ADD run.sh ，新构建的那层镜像大小为文件 run.sh 的大小。 RUN 命令：RUN 命令的作用是在当前空的镜像层内运行一条命令 ，倘若运行的命令需要更新磁盘文件，那么所有的更新内容都在存储在当前镜像层中。举例说明：RUN echo Hello world 命令不涉及文件系统内容的修改 ，故命令运行完之后当前镜像层的大小为 0 ；RUN wget http://abc.com/def.tar 命令会将压缩包下载至当前目录下，因此当前这一层镜像的大小为：对文件系统内容的增量修改部分，即 def.tar 文件的大小 （在成功执行的情况下）。 联合文件系统 Dockerfile 中命令与镜像层一一对应 ，那么是否意味着 docker build 完毕之后，镜像的总大小是否等于每一层镜像的大小总和 呢？答案是肯定的 。依然以上图为例：如果 ubuntu:14.04 镜像的大小为 200 MB，而 run.sh 的大小为 5 MB，那么以上三层镜像从上到下，每层大小依次为 0、0 以及 5 MB，那么最终构建出的镜像大小的确为 0 + 0 + 5 + 200 205 MB。 虽然最终镜像的大小是每层镜像的累加 ，但是需要额外注意的是：Docker 镜像的大小并不等于容器中文件系统内容的大小 （不包括挂载文件，proc、sys 等虚拟文件）。个中缘由，就和联合文件系统有很大的关系了。 首先来看一下这个简单的 Dockerfile 例子（假如在 Dockerfile 当前目录下有一个 100 MB 的压缩文件 compressed.tar）： FROM ubuntu:14.04ADD compressed.tar /RUN rm /compressed.tarADD compressed.tar / FROM ubuntu:14.04：镜像 ubuntu:14.04 的大小为 200 MB ； ADD compressed.tar ： compressed.tar 文件为 100 MB，因此当前镜像层的大小为 100 MB ，镜像总大小为 300 MB ； RUN rm compressed.tar：删除文件 compressed.tar，此时的删除并不会删除下一层的 compressed.tar 文件 ，只会在当前层产生一个 compressed.tar 的删除标记 ，确保通过该层将看不到 compressed.tar，因此当前镜像层的大小也为 0 ，镜像总大小为 300 MB ； ADD compressed.tar ：compressed.tar 文件为 100 MB，因此当前镜像层的大小为 300 MB + 100 MB ，镜像总大小为 400 MB ； 分析完毕之后，我们发现镜像的总大小为 400 MB，但是如果运行该镜像 的话，我们很快可以发现在容器根目录下执行 du -sh 之后，显示的数值并非 400 MB，而是 300 MB 左右 。主要的原因还是：联合文件系统的性质保证了两个拥有 compressed.tar 文件的镜像层，容器仅能看到一个 。同时这也说明了一个现状，当用户基于一个非常大，甚至好几个 GB 的镜像运行容器时，在容器内部查看根目录大小，发现竟然只有 500 MB 不到，甚至更小。 分析至此，有一点大家需要非常注意：镜像大小和容器大小有着本质的区别 。 镜像共享关系 Docker 镜像说大不大，说小不小，但是一旦镜像的总数上来 之后，岂不是对本地磁盘造成很大的存储压力？平均每个镜像 500 MB，岂不是 100 个镜像就需要准备 50 GB 的存储空间？ 结果往往不是我们想象的那样，Docker 在镜像复用 方面设计得非常出色，大大节省镜像占用的磁盘空间。Docker 镜像的复用主要体现在：多个不同的 Docker 镜像可以共享相同的镜像层 。 假设本地镜像存储中只有一个 ubuntu:14.04 的镜像，我们以两个 Dockerfile 来说明镜像复用： FROM ubuntu:14.04RUN apt-get updateFROM ubuntu:14.04ADD compressed.tar / 假设最终 docker build 构建出来的镜像名分别为 image1 和 image2，由于两个 Dockerfile 均基于 ubuntu:14.04 ，因此，image1 和 image2 这两个镜像均复用了镜像 ubuntu:14.04 。 假设 RUN apt-get update 修改的文件系统内容为 20 MB，最终本地三个镜像的大小关系应该如下： ubuntu:14.04： 200 MBimage1：200 MB（ubuntu:14.04 的大小）+ 20 MB = 220 MBimage2：200 MB（ubuntu:14.04 的大小）+ 100 MB = 300 MB 如果仅仅是单纯的累加三个镜像的大小，那结果应该是：200 + 220 + 300 = 720 MB ，但是由于镜像复用的存在，实际占用的磁盘空间大小是：200 + 20 + 100 + 320 MB ，足足节省了 400 MB 的磁盘空间。在此，足以证明镜像复用的巨大好处。 4.4 Dockerfile 参数详解指令的一般格式为 INSTRUCTION arguments ，指令包括 FROM、MAINTAINER、RUN 等。 FROM格式为 FROM image或FROM image:tag。 第一条指令必须为FROM 指令。并且，如果在同一个Dockerfile中创建多个镜像时，可以使用多个FROM 指令（每个镜像一次）。 MAINTAINER格式为 MAINTAINER name，指定维护者信息。 RUN格式为 RUN command 或 RUN [executable, param1, param2]。前者将在 shell 终端中运行命令` ，即 /bin/sh -c；`后者则使用 exec 执行` 。指定使用其它终端可以通过第二种方式实现，例如 `RUN [/bin/bash, -c, echo hello]。 每条 RUN 指令将在当前镜像基础上执行指定命令，并提交为新的镜像。当命令较长时可以使用 \\ 来换行。 CMD支持三种格式 CMD [executable,param1,param2] 使用 exec 执行，推荐方式；CMD command param1 param2 在 /bin/sh 中执行，提供给需要交互的应用；CMD [param1,param2] 提供给 ENTRYPOINT 的默认参数； 指定启动容器时执行的命令，每个 Dockerfile 只能有一条CMD 命令。如果指定了多条命令，只有最后一条会被执行。 如果用户启动容器时候指定了运行的命令，则会覆盖掉 CMD 指定的命令。 EXPOSE格式为 EXPOSE port [port...]。 告诉 Docker 服务端容器暴露的端口号，供互联系统使用。在启动容器时需要通过 -P ，Docker 主机会自动分配一个端口转发到指定的端口。 ENV格式为 ENV key value。 指定一个环境变量，会被后续 RUN 指令使用，并在容器运行时保持。 例如 ENV PG_MAJOR 9.3ENV PG_VERSION 9.3.4RUN curl -SL http://example.com/postgres-$PG_VERSION.tar.xz | tar -xJC /usr/src/postgress …ENV PATH /usr/local/postgres-$PG_MAJOR/bin:$PATH ADD格式为 ADD src dest。 该命令将复制指定的 到容器中的 。 其中 可以是Dockerfile所在目录的一个相对路径；也可以是一个 URL；还可以是一个 tar 文件（自动解压为目录）。 COPY格式为 COPY src dest。 复制本地主机的 （为 Dockerfile 所在目录的相对路径）到容器中的 。 当使用本地目录为源目录时，推荐使用 COPY。 ENTRYPOINT两种格式： ENTRYPOINT [executable, param1, param2]ENTRYPOINT command param1 param2（shell中执行）。 配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖。 每个 Dockerfile 中只能有一个 ENTRYPOINT ，当指定多个时，只有最后一个起效。 VOLUME格式为 VOLUME [/data]。 创建一个可以从本地主机或其他容器挂载的挂载点，一般用来存放数据库和需要保持的数据等。 USER格式为 USER daemon。 指定运行容器时的用户名或 UID，后续的 RUN 也会使用指定用户。 当服务不需要管理员权限时，可以通过该命令指定运行用户。并且可以在之前创建所需要的用户，例如：RUN groupadd -r postgres useradd -r -g postgres postgres 。要临时获取管理员权限可以使用 gosu，而不推荐 sudo 。 WORKDIR格式为 WORKDIR /path/to/workdir。 为后续的 RUN、CMD、ENTRYPOINT 指令配置工作目录。 可以使用多个WORKDIR 指令，后续命令如果参数是相对路径，则会基于之前命令指定的路径。例如 WORKDIR /aWORKDIR bWORKDIR cRUN pwd 则最终路径为 /a/b/c 。 ONBUILD格式为 ONBUILD [INSTRUCTION]。 配置当所创建的镜像作为其它新创建镜像的基础镜像时，所执行的操作指令。 例如，Dockerfile 使用如下的内容创建了镜像 image-A。 [...]ONBUILD ADD . /app/srcONBUILD RUN /usr/local/bin/python-build --dir /app/src[...] 如果基于 image-A 创建新的镜像时，新的Dockerfile中使用 FROM image-A指定基础镜像时，会自动执行 ONBUILD 指令内容，等价于在后面添加了两条指令。 FROM image-A#Automatically run the followingADD . /app/srcRUN /usr/local/bin/python-build --dir /app/src 使用 ONBUILD 指令的镜像，推荐在标签中注明，例如 ruby:1.9-onbuild 。 4.5 创建镜像编写完成 Dockerfile 之后，可以通过 docker build 命令来创建镜像。 基本的格式为 docker build [选项] 路径，该命令将读取指定路径下（包括子目录）的 Dockerfile，并将该路径下所有内容发送给 Docker 服务端，由服务端来创建镜像。因此一般建议放置 Dockerfile 的目录为空目录。也可以通过 .dockerignore 文件（每一行添加一条匹配模式）来让 Docker 忽略路径下的目录和文件。 要指定镜像的标签信息，可以通过 -t 选项，例如 $ sudo docker build -t myrepo/myapp /tmp/test1/"},{"title":"5. Docker 容器使用","path":"/wiki/docker/container.html","content":"5. Docker 容器容器是 Docker 又一核心概念。 简单的说，容器是独立运行的一个或一组应用，以及它们的运行态环境。对应的，虚拟机可以理解为模拟运行的一整套操作系统（提供了运行态环境和其他系统环境）和跑在上面的应用。本章节着重介绍了容器的基础使用方法，以及如何管理容器的数据、如何管理容器的网络，相信你读完本章节将会有一个大致的了解。 5.1 容器使用入门使用info命令检查docker安装程序是否正常运行： # 检查是否安装好docker$ docker info 如果提示如下信息: command not found 或者 类似于varlibdockerrepositories: permission denied 可能安装有问题或者尝试在前面加上sudo。 此外，基于docker系统配置，命令行前面应该加上sudo，来确保正常执行命令，并且此时系统会为Administrar创建一个名叫docker的Unix 用户组来让其他用户加入该组。 5.1.1 下载一个已经制作好的镜像 $ docker pull ubuntu 这条命令会从Docker Hub上搜索ubuntu镜像，然后下载到本里镜像缓存中去。 *Note:When the image is successfully downloaded, you see a 12 character hash 539c0211cd76: Download complete which is the short form of the image ID. These short image IDs are the first 12 characters of the full image ID - which can be found using docker inspect or docker images –no-trunctrue.* 5.1.2 创建一个带有交互窗口的container $ docker run -i -t ubuntu /bin/bash —i参数表示启动了一个可以交互的容器，—t参数表示创建了一个附带标准输入和输出的pseudo－TTY窗口 如果想要退出tty窗口，使用 Ctrl-p + Ctrl-q指令，容器将会退出并且会持续保持一个停止的状态。如果想查看所有状态的容器，可以使用docker ps －a 指令。 5.1.3 绑定容器到另外一个主机端口或者一个Unix Socket *Warning: Changing the default docker daemon binding to a TCP port or Unix docker user group will increase your security risks by allowing non-root users to gain root access on the host. Make sure you control access to docker. If you are binding to a TCP port, anyone with access to that port has full Docker access; so it is not advisable on an open network.* 使用 -H 能够让Docker deamon监听特殊的IP和端口。默认情况下，它将监听unix:varrundocker.sock以仅允许root进行本地连接。你可以将它设置为0.0.0.0:2375或者是指定的主机IP以供所有人连接，但是并不建议这么做，因为这将使某些无聊的人也获得deamon运行主机root的访问权限。 类似的，Docker客户端也可以使用 —H 连接一个指定端口 -H 使用以下格式来分配主机和端口 : tcp:host[path] or unix:path 例如: tcp:host:2375 - TCP connection on host:2375 tcp:host:2375path - TCP connection on host:2375 and prepend path to all requests unix:pathtosocket - Unix socket located at pathtosocket 当—H参数为空时，将被默认认为没有—H参数传进来 -H also accepts short form for TCP bindings: host[:port] or :port Docker以daemon模式运行: $ sudo path to/docker daemon -H 0.0.0.0:5555 下载一个ubuntu镜像: $ docker -H :5555 pull ubuntu 如果你想同时监听TCP和Unix Socket 你可以添加多个 －H # Run docker in daemon mode$ sudo path to/docker daemon -H tcp://127.0.0.1:2375 -H unix:///var/run/docker.sock # Download an ubuntu image, use default Unix socket$ docker pull ubuntu# OR use the TCP port$ docker -H tcp://127.0.0.1:2375 pull ubuntu 5.1.4 起一个持续工作的进程 # Start a very useful long-running process$ JOB=$(docker run -d ubuntu /bin/sh -c while true; do echo Hello world; sleep 1; done)# Collect the output of the job so far$ docker logs $JOB# Kill the job$ docker kill $JOB 5.1.5 监听容器 $ docker ps # Lists only running containers$ docker ps -a # Lists all containers 5.1.6 管理容器 # Start a new container$ JOB=$(docker run -d ubuntu /bin/sh -c while true; do echo Hello world; sleep 1; done)# Stop the container$ docker stop $JOB# Start the container$ docker start $JOB# Restart the container$ docker restart $JOB# SIGKILL a container$ docker kill $JOB# Remove a container$ docker stop $JOB # Container must be stopped to remove it$ docker rm $JOB 5.1.7 在一个TCP端口上绑定一个服务 # Bind port 4444 of this container, and tell netcat to listen on it$ JOB=$(docker run -d -p 4444 ubuntu:12.10 /bin/nc -l 4444)# Which public port is NATed to my container?$ PORT=$(docker port $JOB 4444 | awk -F: print $2 )# Connect to the public port$ echo hello world | nc 127.0.0.1 $PORT# Verify that the network connection worked$ echo Daemon received: $(docker logs $JOB) 5.1.8 提交（保存）一个容器的状态到一个镜像文件中 当提交（commit）容器时，docker仅保存源镜像与当前镜像的差异，如果想列出镜像，请使用docker images指令 # Commit your container to a new named image$ docker commit container some_name# List your images$ docker images 5.2 管理容器工作5.2.1 概览 我们用docker run指令来运行一个容器: 交互容器跑在前端. 守护进程跑在后台. 一些常用管理容器的命令: docker ps - 列出容器. docker logs - 输出容器日志. docker stop - 停止运行容器. Docker客户端非常简单，你只需要需要输入一些带有一系列参数的指令就可以： # Usage: [sudo] docker [command] [flags] [arguments] ..# Example:$ docker run -i -t ubuntu /bin/bash 我们以docker version为例查看当前安装的docker客户端以及deamon进程信息 $ docker version 这条指令不仅提供啦docker客户端以及deamon进程的版本信息，同时也提供了所用go语言的信息。 Client: Version: 1.8.1 API version: 1.20 Go version: go1.4.2 Git commit: d12ea79 Built: Thu Aug 13 02:35:49 UTC 2015 OS/Arch: linux/amd64Server: Version: 1.8.1 API version: 1.20 Go version: go1.4.2 Git commit: d12ea79 Built: Thu Aug 13 02:35:49 UTC 2015 OS/Arch: linux/amd64 5.2.2 获取docker命令行帮助 如果你想展示一些帮助信息，可以使用： $ docker --help 如果你想了解具体参数的使用方法，可以参照如下使用： $ docker attach --helpUsage: docker attach [OPTIONS] CONTAINERAttach to a running container--help=false Print usage--no-stdin=false Do not attach stdin--sig-proxy=true Proxy all received signals to the process 5.2.3 在docker中跑一个web应用程序 现在你已经掌握了一些基础了，来深入一下吧。之前跑的一些应用没什么实际用途，让们来跑一个web应用试试吧。 这个web应用包含里 python 应用： $ docker run -d -P training/webapp python app.py 以上指令中包含两个参数： －d 让容器在后台运行－P 分配一个主机端口到容器端口的映射以供外部访问 trainingwebapp是一个构建好的镜像，里面包含了一个简单的Python Flask web应用程序。 5.2.4 查看web应用程序状态 我们利用docker ps 来查看容器状态 $ docker ps -lCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbc533791f3f5 training/webapp:latest python app.py 5 seconds ago Up 2 seconds 0.0.0.0:49155-5000/tcp nostalgic_morse 其中指令包含了一个－l参数，这将展示最近一次创建的容器的状态。 Note: 默认的 docker ps 不加参数将只会展现正在运行对容器，使用docker ps －a 将展现所有状态的容器 在POTS栏中，我们可以查看到端口映射。 PORTS0.0.0.0:49155-5000/tcp 当我们使用－P参数时，docker将会给主机指定容器暴露的所有端口。 在这个例子中，容器暴露里5000端口，主机随机分配了一个49155端口与之映射。 网络端口绑定在Docker是可配置性非常高的。—P参数是随机指定一个32768～61000的主机端口与容器绑定，而－p则是指定一个端口与容器绑定： $ docker run -d -p 80:5000 training/webapp python app.py 这条指令将绑定主机的80端口与容器的5000端口。 我们来看看49155端口上的web应用吧！ 5.2.5 快捷查看网络端口 用docker ps命令可以查看端口映射，此外，docker海提供了另一种便捷的方式，用docker port命令 $ docker port nostalgic_morse 50000.0.0.0:49155 5.2.6 查看web应用日志 使用docker logs 可以查案容器内部的日志记录这样可以让我们清楚地看到容器运行的状态和历史纪录： $ docker logs -f nostalgic_morse* Running on http://0.0.0.0:5000/10.0.2.2 - - [23/May/2014 20:16:31] GET / HTTP/1.1 200 -10.0.2.2 - - [23/May/2014 20:16:31] GET /favicon.ico HTTP/1.1 404 - 这里加了一个－f参数，可以查看容器标准输出。这里展现了该web应用在5000端口上的日志信息。 5.2.7 查看web应用容器中的进程 根据容器的日志信息，我们可以利用 docker top 指令查看容器内的进程信息 $ docker top nostalgic_morsePID USER COMMAND854 root python app.py 这里我们在容器里看到了刚才我们运行的 python app.py命令。 5.2.8 审查（inspect）web应用容器 利用docker inspect 查看一个容器的详细信息（包括运行状态）或者镜像的配置信息，展现出来的是一个json文件。 $ docker inspect nostalgic_morseLet’s see a sample of that JSON output.[ ID: bc533791f3f500b280a9626688bc79e342e3ea0d528efe3a86a51ecb28ea20, Created: 2014-05-26T05:52:40.808952951Z, Path: python, Args: [ app.py ], Config: Hostname: bc533791f3f5, Domainname: , User: , . . . 我们可以使用－f参数里筛选出需要的信息 $ docker inspect -f .NetworkSettings.IPAddress nostalgic_morse172.17.0.5 5.2.9 停止web应用容器 现在我们尝试停止我们刚才启用的容器，容器名称: nostalgic_morse. $ docker stop nostalgic_morsenostalgic_morse 我们可以使用docker ps 来查看是否成功 $ docker ps -l 5.2.10 重启web应用容器 重启一下试试： $ docker start nostalgic_morsenostalgic_morse 用docker ps －l命令或者打开浏览器产看变化 5.2.11 删除web应用容器 我们可以利用docker rm来删除一个容器，但有时候会出现以下错误： $ docker rm nostalgic_morseError: Impossible to remove a running container, please stop it first or use -f2014/05/24 08:12:56 Error: failed to remove one or more containers 怎么回事? 原来删除的是一个正在运行的容器. 所以我们要做的是stop itremove it $ docker stop nostalgic_morsenostalgic_morse$ docker rm nostalgic_morsenostalgic_morse 官方建议 Note: Always remember that removing a container is final! 5.3 管理容器数据到目前为止，我们已经介绍了一些基本的docker概念，如何管理docker 镜像，以及了解网络和容器之间的联系。 在这一节中，我们将介绍如何管理容器数据。 docker管理数据的两种主要方式。 数据卷，以及数据卷容器。 数据卷是在一个或多个容器，它绕过Union File System的一个专门指定的目录。数据卷为持续共享数据提供了一些有用的功能： 在创建容器时，卷被初始化。如果容器的基础映像包含指定的数据装入点，现有的数据复制到在卷初始化新卷。 数据卷可以共享和容器之间重复使用。 改变数据卷将立刻生效（在所有挂载该容器中） 改变数据卷数据不会影响到容器。 即使容器本身被删除。但是数据卷依然存在。 数据卷的目的是持久化数据，独立于容器的生命周期。Docker因此不会自动删除卷，当你删除一个容器，也不会“垃圾回收”直到没有容器再使用。 5.3.1 添加一个数据卷 你可以在docker run时加上－v参数来添加一个数据卷，－v参数也可以使用多次，以挂载多个数据卷。 $ docker run -d -P --name web -v /webapp training/webapp python app.py 这条命令将在容器中的／webapp文件夹创建一个数据卷存储数据。 你也可以在构建镜像时在Dockerfile里面定义。 数据卷默认的权限时读写，你也可以定义成只读。 $ docker run -d -P --name web -v /opt/webapp:ro training/webapp python app.py 查找数据卷路径用docker inspect命令定位 $ docker inspect web 我们可以看到保存在主机上数据卷的路径： ...Mounts: [ Name: fac362...80535, Source: /var/lib/docker/volumes/fac362...80535/_data, Destination: /webapp, Driver: local, Mode: , RW: true ] … 并切看到权限RW是ture 5.3.2 挂载一个主机目录作为数据卷 挂载主机目录为数据卷，必须参照 －v hostPATH:containerPATH 这种格式 路径必须为绝对路径，以保证容器的 可移植性。 $ docker run -d -P --name web -v /src/webapp:/opt/webapp training/webapp python app.py 上面的命令加载主机的 srcwebapp 目录到容器的 optwebapp 目录 docker数据卷的权限是读写，你也可以指定只读： $ docker run -d -P --name web -v /src/webapp:/opt/webapp:ro training/webapp python app.py 5.3.3 挂载一个数据文件作为数据卷 -v 标记也可以从主机挂载单个文件到容器中 $ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash 这样就可以记录在容器输入过的命令了。 如果直接挂载一个文件，很多文件编辑工具，包括 vi 或者 sed –in-place，可能会造成文件 inode 的改变，从 Docker 1.1 .0起，这会导致报错误信息。所以最简单的办法就直接挂载文件的父目录。 5.3.4 创建和挂载数据卷容器 如果你有一些持续更新的数据需要在容器之间共享，最好创建数据卷容器。 数据卷容器，其实就是一个正常的容器，专门用来提供数据卷供其它容器挂载的。 首先，创建一个命名的数据卷容器 dbdata： $ sudo docker run -d -v /dbdata --name dbdata training/postgres echo Data-only container for postgres 然后，在其他容器中使用 –volumes-from 来挂载 dbdata 容器中的数据卷。 $ sudo docker run -d --volumes-from dbdata --name db1 training/postgres$ sudo docker run -d --volumes-from dbdata --name db2 training/postgres 还可以使用多个 –volumes-from 参数来从多个容器挂载多个数据卷。 也可以从其他已经挂载了数据卷的容器来挂载数据卷。 $ sudo docker run -d --name db3 --volumes-from db1 training/postgres *注意：使用 –volumes-from 参数所挂载数据卷的容器自己并不需要保持在运行状态。 如果删除了挂载的容器（包括 dbdata、db1 和 db2），数据卷并不会被自动删除。如果要删除一个数据卷，必须在删除最后一个还挂载着它的容器时使用 docker rm -v 命令来指定同时删除关联的容器。 这可以让用户在容器之间升级和移动数据卷。 5.3.5 备份、存储、移动数据卷 另一个非常有用大功能是利用数据卷容器进行备份、存储以及迁移操作。 备份 $ docker run --volumes-from dbdata -v $(pwd):/backup ubuntu tar cvf /backup/backup.tar /dbdata 然后新创建一个新的容器 $ docker run -v /dbdata --name dbdata2 ubuntu /bin/bash 然后解压数据卷挂载到容器 $ docker run --volumes-from dbdata2 -v $(pwd):/backup ubuntu cd /dbdata tar xvf /backup/backup.tar 5.4 容器间的通信容器的通信相当重要，这里讲解了一通信方式。 5.4.1 容器与宿主机器采用端口映射的方式通信 之前的例子 $ docker run -d -P training/webapp python app.py 我们可以看到端口映射状态： $ docker ps nostalgic_morseCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbc533791f3f5 training/webapp:latest python app.py 5 seconds ago Up 2 seconds 0.0.0.0:49155-5000/tcp nostalgic_morse 我们也可以指定端口映射： $ docker run -d -p 80:5000 training/webapp python app.py －p参数还有其他指定方法： ip:hostPort:containerPort 映射指定IP的指定端口ip::containerPort 映射指定IP任意端口hostPort:containerPort。 映射所有主机IP的指定端口 5.4.2 采用link方式通信 名字的重要性 为了方便建立连接，通常需要为容器起一个name ，如果不起，你会发现系统会自动分配一个名字。 此外，起一个自定义的名字让你很容易地记住它并切可以方便的管理 $ docker run -d -P --name web training/webapp python app.py 查看容器 $ docker ps -lCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESaed84ee21bde training/webapp:latest python app.py 12 hours ago Up 2 seconds 0.0.0.0:49154-5000/tcp web 你也可以使用docker inspect 命令查看容器名称。 Note: Container names have to be unique. That means you can only call one container web. If you want to re-use a container name you must delete the old container (with docker rm) before you can create a new container with the same name. As an alternative you can use the --rm flag with the docker run command. This will delete the container immediately after it is stopped. Links 允许容器发现另一个容器，并在期间建立一个安全的通道以便交换数据。 使用－－link参数来创建一个连接。 $ docker run -d --name db training/postgres 创建一个web连接到db数据库容器. $ docker run -d -P --name web --link db:db training/webapp python app.py 参数格式如下: --link name or id:alias alias代表你 为这个链接起的一个别名。 --link name or id 该参数将匹配容器name 并建立连接 $ docker run -d -P --name web --link db training/webapp python app.py 使用docker inspect 定位: $ docker inspect -f .HostConfig.Links web[/db:/web/db] 你可以看到web容器已经与db容器连接 连接容器docker究竟做了什么？目前已经知道，一个创建在源容器与目标容器间的连接允许源容器提供信息给目标容器。在上述例子中，目标容器web可以获取源容器db提供的信息。为了实现这项功能，docker在这两个容器之间创建了一个稳定的通道，并且不会暴露任何端口，你不需要在创建容器时加上－p或－P参数。这就是link方式的最大好处。 docker通过以下两种方式完成此项工作 环境变量当link容器时，docker会创建许多环境变量. Docker会自动创建环境变量到目标容器中去. 它也将通过docker暴露源容器的所有环境变量. 这些变量来自: Dockerfile中ENV命令定义的环境变量 在启动源容器中使用 －e 、–env以及 –env－file参数附加的环境变量。 这些环境变量使程序从相关的目标容器中发现源容器。 Warning: It is important to understand that all environment variables originating from Docker within a container are made available to any container that links to it. This could have serious security implications if sensitive data is stored in them. Docker为每一个在–link参数中的容器设置了一个 _NAME 环境变量 。例如，一个web容器通过–link db：webdb连 接db容器，将会在web容器中创建一个WEBDB_NAMEwebwebdb环境变量 Docker为源容器暴露的端口限定了一组环境变量，每一个环境变量具有唯一前缀形式： name_PORT_port_protocol 前缀的构成: 是–link :后面的参数(例如, webdb) 就是暴露的端口号 TCP／UDP Docker 利用这前缀格式定义了三个不同的环境变量: prefix_ADDR 变量包含了来自URL的IP地址, for example WEBDB_PORT_5432_TCP_ADDR=172.17.0.82. prefix_PORT 变量仅包含了URL的端口号, for example WEBDB_PORT_5432_TCP_PORT=5432. prefix_PROTO 参数包含URL的传输协议, for example WEBDB_PORT_5432_TCP_PROTO=tcp. 如果容器暴露多个端口，Docker将会为每个端口创建三个环境变量。算术题：如果容器暴露4个端口，将会创建多少个环境变量？答对了，是12个哦！每个端口三个环境变量。 另外，Docker也要创建一个叫 _PORT 的环境变量。这个变量包含源容器URL首次暴露的IP和端口。该端口的“首次”定义为最低级数字的端口。例如，思考WEBDB_PORTtcp:172.17.0.82:5432 变量，如果该端口同时用语TCP和UDP，则TCP将会被指定。（原文：Additionally, Docker creates an environment variable called _PORT. This variable contains the URL of the source container’s first exposed port. The ‘first’ port is defined as the exposed port with the lowest number. For example, consider the WEBDB_PORTtcp:172.17.0.82:5432 variable. If that port is used for both tcp and udp, then the tcp one is specified.） 最后，Docker会把源容器中的环境变量暴露给目标容器作为环境变量。并且Docker会在目标容器为每个变量创建一个ENV变量。这个变量的值被设置为启动源容器Docker所用到的值。（原文：Finally, Docker also exposes each Docker originated environment variable from the source container as an environment variable in the target. For each variable Docker creates an *ENV* variable in the target container. The variable’s value is set to the value Docker used when it started the source container.） 回到之前的例子 database ,你可以使用env命令列出具体的容器环境变量： $ docker run --rm --name web2 --link db:db training/webapp env. . .DB_NAME=/web2/dbDB_PORT=tcp://172.17.0.5:5432DB_PORT_5432_TCP=tcp://172.17.0.5:5432DB_PORT_5432_TCP_PROTO=tcpDB_PORT_5432_TCP_PORT=5432DB_PORT_5432_TCP_ADDR=172.17.0.5. . . 你可以看到Docker利用许多有关源容器的信息创建了一些列的环境变量。每一环境变量都会带有指点定义的别名，DB前缀。如果别名是db1，那么变量前缀也会变成DB1。利用这线环境变量来配置应用用来在db容器上连接数据库。这样的连接方式稳定安全私有化。只有已获得连接的web容器才会有对db容器的访问权限。 关于环境变量的一些注意事项： 与修改etchosts文件不同，在环境变量中存储的IP地址信息不回随着容器的重启而更新，建议利用hosts文件来解决连接容器的IP地址问题。 这些环境变量只是为容器的第一个process设置，某些deamon后台服务，例如sshd，只有当产生连接需求时才会设置。（原文：These environment variables are only set for the first process in the container. Some daemons, such as sshd, will scrub them when spawning shells for connection.） 更新 etchosts 文件处理环境变量, docker在源文件中追加了host信息，这里向web容器追加: $ docker run -t -i --rm --link db:webdb training/webapp /bin/bashroot@aed84ee21bde:/opt/webapp# cat /etc/hosts172.17.0.7 aed84ee21bde. . .172.17.0.5 webdb 6e5cdeb2d300 db 我们可以在容器中使用ping命令测试链接： root@aed84ee21bde:/opt/webapp# apt-get install -yqq inetutils-pingroot@aed84ee21bde:/opt/webapp# ping webdbPING webdb (172.17.0.5): 48 data bytes56 bytes from 172.17.0.5: icmp_seq=0 ttl=64 time=0.267 ms56 bytes from 172.17.0.5: icmp_seq=1 ttl=64 time=0.250 ms56 bytes from 172.17.0.5: icmp_seq=2 ttl=64 time=0.256 ms 如果你重启源容器，连接依然存在： $ docker restart dbdb$ docker run -t -i --rm --link db:db training/webapp /bin/bashroot@aed84ee21bde:/opt/webapp# cat /etc/hosts172.17.0.7 aed84ee21bde. . .172.17.0.9 db"},{"title":"7. Docker 参数用法详解","path":"/wiki/docker/referuse.html","content":"7. Docker 参数用法详解7.1 deamon 参数Docker对使用者来讲是一个C/S模式的架构，而Docker的后端是一个非常松耦合的架构，模块各司其职，并有机组合，支撑Docker的运行,如下图所示： 不难看出，用户是使用Docker Client与Docker Daemon建立通信，并发送请求给后者。 而Docker Daemon作为Docker架构中的主体部分，首先提供Server的功能使其可以接受Docker Client的请求；而后Engine执行Docker内部的一系列工作，每一项工作都是以一个Job的形式的存在。 Job的运行过程中，当需要容器镜像时，则从Docker Registry中下载镜像，并通过镜像管理驱动graphdriver将下载镜像以Graph的形式存储；当需要为Docker创建网络环境时，通过网络管理驱动networkdriver创建并配置Docker容器网络环境；当需要限制Docker容器运行资源或执行用户指令等操作时，则通过execdriver来完成。 而libcontainer是一项独立的容器管理包，networkdriver以及execdriver都是通过libcontainer来实现具体对容器进行的操作。 当执行完运行容器的命令后，一个实际的Docker容器就处于运行状态，该容器拥有独立的文件系统，独立并且安全的运行环境等。 Docker ClientDocker Client是Docker架构中用户用来和Docker Daemon建立通信的客户端。用户使用的可执行文件为docker，通过docker命令行工具可以发起众多管理container的请求。 Docker Client可以通过以下三种方式和Docker Daemon建立通信：tcp:host:port，unix:path_to_socket和fd:socketfd。为了简单起见，本文一律使用第一种方式作为讲述两者通信的原型。与此同时，与Docker Daemon建立连接并传输请求的时候，Docker Client可以通过设置命令行flag参数的形式设置安全传输层协议(TLS)的有关参数，保证传输的安全性。 Docker Client发送容器管理请求后，由Docker Daemon接受并处理请求，当Docker Client接收到返回的请求相应并简单处理后，Docker Client一次完整的生命周期就结束了。当需要继续发送容器管理请求时，用户必须再次通过docker可执行文件创建Docker Client。 Docker DaemonDocker Daemon是Docker架构中一个常驻在后台的系统进程，功能是：接受并处理Docker Client发送的请求。该守护进程在后台启动了一个Server，Server负责接受Docker Client发送的请求；接受请求后，Server通过路由与分发调度，找到相应的Handler来执行请求。 Docker Daemon启动所使用的可执行文件也为docker，与Docker Client启动所使用的可执行文件docker相同。在docker命令执行时，通过传入的参数来判别Docker Daemon与Docker Client。 deamon的参数选项： Usage: docker daemon [OPTIONS]A self-sufficient runtime for linux containers.Options: --api-cors-header= Set CORS headers in the remote API -b, --bridge= Attach containers to a network bridge --bip= Specify network bridge IP -D, --debug=false Enable debug mode --default-gateway= Container default gateway IPv4 address --default-gateway-v6= Container default gateway IPv6 address --dns=[] DNS server to use --dns-search=[] DNS search domains to use --default-ulimit=[] Set default ulimit settings for containers -e, --exec-driver=native Exec driver to use --exec-opt=[] Set exec driver options --exec-root=/var/run/docker Root of the Docker execdriver --fixed-cidr= IPv4 subnet for fixed IPs --fixed-cidr-v6= IPv6 subnet for fixed IPs -G, --group=docker Group for the unix socket -g, --graph=/var/lib/docker Root of the Docker runtime -H, --host=[] Daemon socket(s) to connect to -h, --help=false Print usage --icc=true Enable inter-container communication --insecure-registry=[] Enable insecure registry communication --ip=0.0.0.0 Default IP when binding container ports --ip-forward=true Enable net.ipv4.ip_forward --ip-masq=true Enable IP masquerading --iptables=true Enable addition of iptables rules --ipv6=false Enable IPv6 networking -l, --log-level=info Set the logging level --label=[] Set key=value labels to the daemon --log-driver=json-file Default driver for container logs --log-opt=[] Log driver specific options --mtu=0 Set the containers network MTU -p, --pidfile=/var/run/docker.pid Path to use for daemon PID file --registry-mirror=[] Preferred Docker registry mirror -s, --storage-driver= Storage driver to use --selinux-enabled=false Enable selinux support --storage-opt=[] Set storage driver options --tls=false Use TLS; implied by --tlsverify --tlscacert=~/.docker/ca.pem Trust certs signed only by this CA --tlscert=~/.docker/cert.pem Path to TLS certificate file --tlskey=~/.docker/key.pem Path to TLS key file --tlsverify=false Use TLS and verify the remote --userland-proxy=true Use userland proxy for loopback traffic 如果你想要运行守护态进程，你可以输入 docker -d（之前版本是 docker deamon）。如果想加入Debug模式，输入docker -d -D即可。 Deamon socket 选项 Docker deamon 通过三种不同的socket方式监听docker remote API请求，分别是：unix、tcp、以及fd。 默认情况下，通过创建在/var/run/docer.sock文件内的unix domain socket（或者 IPC socket）来接收root或者docker用户组的请求。如果你想远程通信你需要打开tcpSocket。 要注意的是，默认的方式提供了一个未加密未验证直接连接deamon。应该使用内置的HTTPS加密的socket或者在前面使用一个安全的web代理。使用-H tcp://0.0.0.0:2375来监听所有ip地址接口的2375端口，或者指定一个主机IP监听-H 192.168.2.160:2375。通常情况下2375端口是 未加密的，而2376用于与deamon通信的加密端口。 注意：如果你使用HTTPS加密socket ，目前支持TLS1.0或更高级的协议，不支持Protocols SSLv3或者低于此版本的协议。 在Systemd基础的系统中，使用docker -d -H fd://,通过Systemd socket activation与deamon通信。对于大多数设置，使用fd:将很好的运作，你也可以指定单个socket：docker -d -H fd://3。如果没有找到指定的激活的文件，Docker 将会退出进程。 Server端 -H参数可以多次指定监听不同的端口： 例如指定监听主机默认的unix socket以及指定的IP地址： $ sudo docker -d -H unix:///var/run/docker.sock -H tcp://192.168.2.160:2375 Client端 为客户端设置-H参数，将使客户端监听DOCKER_HOST环境变量指定的参数： $ docker -H tcp://0.0.0.0:2375 ps 或者 $ export DOCKER_HOST=tcp://0.0.0.0:2375$ docker ps 设置 DOCKER_TLS_VERIFY环境变量相当于设置--tlsverify参数： $ docker --tlsverify ps 或者 $ export DOCKER_TLS_VERIFY=1$ docker ps 以上设置是等效的 Docker客户端会遵守HTTP_PROXY,HTTPS_PROXY以及NO_PROXY这三个环境变量运行。其中HTTPS_PROXY优先权大于HTTP_PROXY storage-driver 选项 Docker deamon 支持许多不同的镜像层存储驱动：aufs、devicemapper、btrfs、zfs以及overlay。 aufs是最老的，但是由于它是基于linux 内核patch-set,不太可能被合并到主内核中。这也会导致一些严重的系统崩溃。但是，aufs也是唯一允许容器共享可执行文件以及共享类库内存的存储驱动，所以对于那些需要运行数以千计运行相同程序或类库的容器会非常有用。 devicemapper使用自动精简配置以及Copy on Write(COW)快照。对于每一个graph位置通常是在varlibdockerdevicemapper中，通常被分为两块设备，一块给数据，一块给metadata。默认的，这些块设备是通过使用自动创建的零散文件回送挂载来自动创建的。Refer to Storage driver options below for a way how to customize this setup.~jpetazzoResizing Docker containers with the Device Mapper plugin article explains how to tune your existing setup without the use of options. Btrfs 对于docker build构建镜像时会非常快，但是和devicemapper一样不会共享可执行文件以及类库的内存。使用方法： docker -d -s btrfs -g /mnt/btrfs_partition Zfs 没有btrfs那么快，但是对相对较长记录有更稳定地支持。由于克隆之间的单一副本ARC共享块将被一次缓存，使用方法： docker -d -s zfs Use docker daemon -s zfs. To select a different zfs filesystem set zfs.fsname option as described in Storage driver options. Overlay 是一个非常快的联合文件系统，它现在被并入了3.18.0的Linux内核中，使用方法： docker -d -s overlay storage-opt选项 ***dm.thinpooldev***,指定块存储设备所使用的thin pool。 docker -d --storage-opt dm.thinpooldev=/dev/mapper/thin-pool ***dm.basesize*** 指定基础存储大小，同时限制镜像以及容器。默认值时100G。 修改此值需要执行以下操作才生效： $ sudo service docker stop$ sudo rm -rf /var/lib/docker$ sudo service docker start 使用方法： $ docker -d --storage-opt dm.basesize=20G ***dm.loopdatasize*** 这个选项配置devicemapper looback，这不应该在生产中使用。默认值是100G，用于设定thin pool为数据产生的回送的零散文件存储大小，通常不会占用那么多空间。 使用方法： $ docker -d --storage-opt dm.loopdatasize=200G ***dm.loopmetadatasize*** 与上面类似，只是设定元数据存储大小。 使用方法 $ docker -d --storage-opt dm.loopmetadatasize=4G ***dm.fs*** 设定文件系统基础设备类型，支持的类型是ext4和xfs，默认是ext4 使用方法： $ docker -d –storage-opt dm.fsxfs ***dm.mkfsarg*** 设定在创建基础设备时mkfs所用到的参数 使用方法： $ docker -d --storage-opt dm.mkfsarg=-O ^has_journal ***dm.mountopt*** 挂载设备时设置挂载选项。 使用方法： $ docker -d --storage-opt dm.mountopt=nodiscard ***dm.blocksize*** 为thin pool 设置块大小。默认是64K 使用方法： $ docker -d –storage-opt dm.blocksize512K ***dm.blkdiscard*** 当删除devicemapper设备时允许或禁止使用blkdiscard 默认是允许（enable）。如果禁止，将会时删除容器更加快速，但是不会返回其中文件的使用空间。 使用说明： $ docker -d --storage-opt dm.blkdiscard=false ***dm.override_udev_sync_check*** 设置该参数为true，可以协调devicemapper 与 udev的资源利用。当其设置为false时，将会在devicemapper与udev产生竞争，有可能导致错误或者失败。 使用方法： $ docker -d --storage-opt dm.override_udev_sync_check=true Docker execdriver选项 目前zfs支持的选项zfs.fsname 使用方法： $ docker daemon -s zfs --storage-opt zfs.fsname=zroot/docker 另外，可以使用 -e lxc 来启用lxcexecution 设备 Daemon DNS选项 设置dns 服务器 $ docker -d --dns 8.8.8.8$ docker -d --dns-search example.com 不安全仓库登记 一个安全的私有仓库通过使用TLS和CA证书的副本来替换/etc/docker/certs.d/myregistry:5000/ca.crt文件。不使用TLS，或者使用未知CA证书的TLS都将是不安全的。如果CA证书验证实效或者在/etc/docker/certs.d/myregistry:5000/找不到证书将会报错。使用--insecure-registry参数可以标记一个不安全的仓库： --insecure-registry myregistry:5000 将告诉 deamon 这个myregistry:5000仓库应该标记为不安全状态。 --insecure-registry 10.1.0.0/16 告诉deamon通过CIDR语法解析出来的IP地址是10.1.0.0/16的仓库标记为不安全。 如果没有使用参数--insecure-registry标记，那么docker pull 、docker push、docker search 从指定仓库执行时将会报错。 7.2 atttach 参数 用法 Usage: docker attach [OPTIONS] CONTAINERAttach to a running container --help=false Print usage --no-stdin=false Do not attach STDIN --sig-proxy=true Proxy all received signals to the proces 例子 在使用-d参数时，容器启动后会进入后台。 某些时候需要进入容器进行操作，有很多种方法，包括使用 docker attach命令或 nsenter 工具等。 $ sudo docker run -i -t -d centos911207826f4da78cb8b8a233dea6120a7d2939eea389a94eef2c0b1320572628$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES911207826f4d centos:latest /bin/bash 46 seconds ago Up 45 seconds silly_poitras$ sudo docker attach 911207826f4d[root@911207826f4d /]#[root@911207826f4d /]# 此时，我们以及进入一个正在运行的容器中去执行命令。 总结 使用 attach 命令有时候并不方便。当多个窗口同时 attach 到同一个容器的时候，所有窗口都会同步显示。当某个窗口因命令阻塞时,其他窗口也无法执行操作了。 扩展工具 nsenter 说明 nsenter可以访问一个进程大名字空间。 指令时包含在untli-linux（2.23版本之后才会包含）软件包里。这里需要安装一下： $ sudo yum -y install util-linux 完成后检验： $ nsenter -Vnsenter from util-linux 2.23.2 如果要进入容器内需要知道进程的pid。 $ sudo docker run -idt --name=test1 centos f629fa879a34af902a259e831de1cbc298db2b0f469aa49f80b80a0f81869943$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf629fa879a34 centos /bin/bash 6 seconds ago Up 5 seconds test1$ sudo PID=$(docker inspect --format .State.Pid f629fa879a34)$ sudo echo $PID$ sudo nsenter --target 22109 --mount --uts --ipc --net --pid[root@f629fa879a34 /]#[root@f629fa879a34 /]#[root@f629fa879a34 /]# 这样就完成了进入容器内访问的目的。 此外，为了方便进入容器，牛人已经为我们封装好指令，我们只需利用简单的两行代码就可完成操作。 下载这个脚本.bashrc_docker，并将内容放到 .bashrc 中： $ sudo wget -P ~ https://github.com/yeasy/docker_practice/raw/master/_local/.bashrc_docker;$ sudo echo [ -f ~/.bashrc_docker ] . ~/.bashrc_docker ~/.bashrc; source ~/.bashrc 执行完后我们只需： $ sudo echo $(docker-pid f629fa879a34)$ sudo docker-enter f629fa879a34[root@f629fa879a34 ~]#实际上也是使用nsenter进入容器，只不过更简洁罢了。 7.3 build 参数 用法 Usage: docker build [OPTIONS] PATH | URL | -Build a new image from the source code at PATH -f, --file= Name of the Dockerfile (Default is PATH/Dockerfile) --force-rm=false Always remove intermediate containers --no-cache=false Do not use cache when building the image --pull=false Always attempt to pull a newer version of the image -q, --quiet=false Suppress the verbose output generated by the containers --rm=true Remove intermediate containers after a successful build -t, --tag= Repository name (and optionally a tag) for the image -m, --memory= Memory limit for all build containers --memory-swap= Total memory (memory + swap), `-1` to disable swap -c, --cpu-shares CPU Shares (relative weight) --cpuset-mems= MEMs in which to allow execution, e.g. `0-3`, `0,1` --cpuset-cpus= CPUs in which to allow execution, e.g. `0-3`, `0,1` --cgroup-parent= Optional parent cgroup for the container --ulimit=[] Ulimit options 例子 使用该命令，将会从参数指定的路径中的 Dockerfile的文件执行构建镜像，文件的指向可以是一个本地文件PATH或者是一个URL。 例如： $ sudo docker build https://github.com/docker/rootfs.git#container:docker 或者用标准输入： $ sudo docker build - Dockerfile 如果你采用以上两种方式构建镜像，-f 或者－file参数将失效。 默认情况下，docker build 指令将会在指定根目录下查找Dockerfile文件，如果指定-f-file参数，将指定该构建目录文件，这样的好处是可以多次构建。需要注意的是，路径必须包含构建信息的文件。 在多数情况下，最好保证构建目录为空。然后添加所需要的软件包到该文件夹。为了提高构建效率，可以加入 .dockerignore 文件排除一些不需要的文件。 返回值 如果构建成功，将会返回0，当失败时，将会返回相应错误返回值： $ docker build -t fail .Sending build context to Docker daemon 2.048 kBSending build context to Docker daemonStep 0 : FROM busybox --- 4986bf8c1536Step 1 : RUN exit 13 --- Running in e26670ec7a0aINFO[0000] The command [/bin/sh -c exit 13] returned a non-zero code: 13$ echo $? 一般例子： $ docker build .Uploading context 10240 bytesStep 1 : FROM busyboxPulling repository busybox --- e9aa60c60128MB/2.284 MB (100%) endpoint: https://cdn-registry-1.docker.io/v1/Step 2 : RUN ls -lh / --- Running in 9c9e81692ae9total 24drwxr-xr-x 2 root root 4.0K Mar 12 2013 bindrwxr-xr-x 5 root root 4.0K Oct 19 00:19 devdrwxr-xr-x 2 root root 4.0K Oct 19 00:19 etcdrwxr-xr-x 2 root root 4.0K Nov 15 23:34 liblrwxrwxrwx 1 root root 3 Mar 12 2013 lib64 - libdr-xr-xr-x 116 root root 0 Nov 15 23:34 proclrwxrwxrwx 1 root root 3 Mar 12 2013 sbin - bindr-xr-xr-x 13 root root 0 Nov 15 23:34 sysdrwxr-xr-x 2 root root 4.0K Mar 12 2013 tmpdrwxr-xr-x 2 root root 4.0K Nov 15 23:34 usr --- b35f4035db3fStep 3 : CMD echo Hello world --- Running in 02071fceb21b --- f52f38b7823eSuccessfully built f52f38b7823eRemoving intermediate container 9c9e81692ae9Removing intermediate container 02071fceb21b 上面例子中，指定路径是 .,这个路径告诉docker构建的目录为当前目录，里面包含构建文件的信息，以及所要添加的文件。如果想保留构建过程中的容器，可以使用–rmfalse ，这样操作不会影响构建缓存。 下面这个例子使用了.dockerignore文件来排除.git文件的使用方法，将会影响上下文文件大小。 $ docker build .Uploading context 18.829 MBUploading contextStep 0 : FROM busybox --- 769b9341d937Step 1 : CMD echo Hello world --- Using cache --- 99cc1ad10469Successfully built 99cc1ad10469 $ echo .git .dockerignore$ docker build .Uploading context 6.76 MBUploading contextStep 0 : FROM busybox --- 769b9341d937Step 1 : CMD echo Hello world --- Using cache --- 99cc1ad10469Successfully built 99cc1ad10469 使用-t参数指定name以及tag： $ docker build -t vieux/apache:2.0 . 从标准输入读取Dockerfile： $ docker build - Dockerfile 使用压缩文件，目前支持的格式是bzip2, gzip and xz $ docker build - context.tar.gz 从克隆的GitHub仓库作为上下文构建镜像，在仓库根目录下的Dockerfile文件将作为构建文件。 $ docker build github.com/creack/docker-firefox 注意，若要加前缀必须是 git: 或者 git@ 。 使用-f参数指定文件构建 $ docker build -f Dockerfile.debug . 在.目录下从不同文件构建镜像： $ docker build -f dockerfiles/Dockerfile.debug -t myapp_debug .$ docker build -f dockerfiles/Dockerfile.prod -t myapp_prod . 我们在观察下面例子： $ cd /home/me/myapp/some/dir/really/deep$ docker build -f /home/me/myapp/dockerfiles/debug /home/me/myapp$ docker build -f ../../../../dockerfiles/debug /home/me/myapp 这个例子执行的两次构建操作所做事情是一模一样的，都会寻找debug文件作为Dockerfile来构建镜像。 7.4 commit 参数 用法 Usage: docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]Create a new image from a containers changes-a, --author= Author (e.g., John Hannibal Smith [email protected])-c, --change=[] Apply Dockerfile instruction to the created image--help=false Print usage-m, --message= Commit message-p, --pause=true Pause container during commit 例子 $ sudo docker psID IMAGE COMMAND CREATED STATUS PORTSc3f279d17e0a ubuntu:12.04 /bin/bash 7 days ago Up 25 hours197387f1b436 ubuntu:12.04 /bin/bash 7 days ago Up 25 hours$ sudo docker commit c3f279d17e0a SvenDowideit/testimage:version3f5283438590d$ sudo docker images | headREPOSITORY TAG ID CREATED VIRTUAL SIZESvenDowideit/testimage version3 f5283438590d 16 seconds ago 335.7 M 提交一个重新配置过的容器到镜像 $ sudo docker psID IMAGE COMMAND CREATED STATUS PORTSc3f279d17e0a ubuntu:12.04 /bin/bash 7 days ago Up 25 hours197387f1b436 ubuntu:12.04 /bin/bash 7 days ago Up 25 hours$ sudo docker inspect -f .Config.Env c3f279d17e0a[HOME=/ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin]$ sudo docker commit --change ENV DEBUG true c3f279d17e0a SvenDowideit/testimage:version3f5283438590d$ sudo docker inspect -f .Config.Env f5283438590d[HOME=/ PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin DEBUG=true] 总结 这个命令的用处在于把有修改的container提交成新的Image，然后导出此Imange分发给其他场景中调试使用。Docker官方的建议是，当你在调试完Image的问题后，应该写一个新的Dockerfile文件来维护此Image。commit命令仅是一个临时创建Imange的辅助命令。 7.5 cp 参数 用法 Usage: docker cp [OPTIONS] CONTAINER:PATH HOSTDIR|-Copy files/folders from a PATH on the container to a HOSTDIR on the host running the command. Use - to write the data as a tar file to STDOUT. --help=false Print usage 例子 $ sudo docker cp hopeful_feynman:/etc /home 这将会在主机的home目录下多一个etc文件夹，该文件夹就是从容器中复制出来的。 总结 使用cp可以把容器內的文件复制到Host主机上。这个命令在开发者开发应用的场景下，会需要把运行程序产生的结果复制出来的需求，在这个情况下就可以使用这个cp命令。 7.6 diff 参数 用法 Usage: docker diff [OPTIONS] CONTAINERInspect changes on a containers filesystem --help=false Print usage 例子 $ sudo docker diff b448f729a0b0C /runA /run/secrets 总结 diff会列出3种容器内文件状态变化（A - Add, D - Delete, C - Change ）的列表清单。构建Image的过程中需要的调试指令。 7.7 events 参数 用法 Usage: docker events [OPTIONS]Get real time events from the server-f, --filter=[] Filter output based on conditions provided--help=false Print usage--since= Show all events created since timestamp--until= Stream events until this timestamp 例子 第一个窗口用来监听事件 $ docker events 第二个窗口 起停容器 $ docker start 4386fb97867d$ docker stop 4386fb97867d$ docker stop 7805c1d35632 执行完后，shell窗口会同步打印如下信息： 2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) start2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) die2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) stop2014-05-10T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) die2014-05-10T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) stop 使用since参数按时间筛选 $ sudo docker events --since 13782161692014-03-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) die2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) stop2014-05-10T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) die2014-03-10T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) stop$ sudo docker events --since 2013-09-032014-09-03T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) start2014-09-03T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) die2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) stop2014-05-10T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) die2014-09-03T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) stop$ sudo docker events --since 2013-09-03T15:49:292014-09-03T15:49:29.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) die2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) stop2014-05-10T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) die2014-09-03T15:49:29.999999999Z07:00 7805c1d35632: (from redis:2.8) stop 只保留三分钟内的事件 $ sudo docker events --since 3m2015-05-12T11:51:30.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) die2015-05-12T15:52:12.999999999Z07:00 4 4386fb97867d: (from ubuntu-1:14.04) stop2015-05-12T15:53:45.999999999Z07:00 7805c1d35632: (from redis:2.8) die2015-05-12T15:54:03.999999999Z07:00 7805c1d35632: (from redis:2.8) stop 也可以使用过滤器筛选 $ docker events --filter event=stop2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) stop2014-09-03T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) stop$ docker events --filter image=ubuntu-1:14.042014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) start2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) die2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) stop$ docker events --filter container=7805c1d356322014-05-10T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) die2014-09-03T15:49:29.999999999Z07:00 7805c1d35632: (from redis:2.8) stop$ docker events --filter container=7805c1d35632 --filter container=4386fb97867d2014-09-03T15:49:29.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) die2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) stop2014-05-10T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) die2014-09-03T15:49:29.999999999Z07:00 7805c1d35632: (from redis:2.8) stop$ docker events --filter container=7805c1d35632 --filter event=stop2014-09-03T15:49:29.999999999Z07:00 7805c1d35632: (from redis:2.8) stop$ docker events --filter container=container_1 --filter container=container_22014-09-03T15:49:29.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) die2014-05-10T17:42:14.999999999Z07:00 4386fb97867d: (from ubuntu-1:14.04) stop2014-05-10T17:42:14.999999999Z07:00 7805c1d35632: (from redis:2.8) die2014-09-03T15:49:29.999999999Z07:00 7805c1d35632: (from redis:2.8) stop 总结 打印容器实时的系统事件。 7.8 export 参数 用法 Usage: docker export [OPTIONS] CONTAINERExport a filesystem as a tar archive (streamed to STDOUT by default) --help=false Print usage -o, --output= Write to a file, instead of STDOUT 例子 $ sudo docker export b448f729a0b0 centos.tar 总结 把容器系统文件打包并导出来，方便分发给其他场景使用。 7.9 import 参数 用法 Usage: docker import [OPTIONS] URL|- [REPOSITORY[:TAG]]Create an empty filesystem image and import the contents of thetarball (.tar, .tar.gz, .tgz, .bzip, .tar.xz, .txz) into it, thenoptionally tag it. -c, --change=[] Apply Dockerfile instruction to the created image --help=false Print usage 例子 从网络上导入： $ sudo docker import http://example.com/exampleimage.tgz 从本地文件导入: 通过标准输入和pipe导入到docker. $ cat exampleimage.tgz | sudo docker import - exampleimagelocal:new 从本地目录导入： $ sudo tar -c . | docker import - exampleimagedir 带配置信息从本地目录导入： $ sudo tar -c . | docker import --change ENV DEBUG true - exampleimagedir 7.10 history 参数 用法 Usage: docker history [OPTIONS] IMAGEShow the history of an image-H, --human=true Print sizes and dates in human readable format--help=false Print usage--no-trunc=false Dont truncate output-q, --quiet=false Only show numeric IDs 例子 $ sudo docker history postgresIMAGE CREATED CREATED BY SIZE COMMENT730d1d72bda2 4 weeks ago /bin/sh -c #(nop) CMD [postgres] 0 B3e840dbb5474 4 weeks ago /bin/sh -c #(nop) EXPOSE 5432/tcp 0 B4df8a54cf33a 4 weeks ago /bin/sh -c #(nop) ENTRYPOINT [/docker-entr 0 B09e02a9f8afe 4 weeks ago /bin/sh -c #(nop) COPY file:090d83d34addb45c3 2.761 kB39172f8b90f2 4 weeks ago /bin/sh -c #(nop) VOLUME [/var/lib/postgresql 0 B3fa84fbfdec9 4 weeks ago /bin/sh -c #(nop) ENV PGDATA=/var/lib/postgre 0 Bc5d75e7f9094 4 weeks ago /bin/sh -c #(nop) ENV PATH=/usr/lib/postgresq 0 Ba95070c23e86 4 weeks ago /bin/sh -c mkdir -p /var/run/postgresql ch 0 B64957633c267 4 weeks ago /bin/sh -c apt-get update apt-get install 116.4 MBa814508841fa 4 weeks ago /bin/sh -c echo deb http://apt.postgresql.or 66 B49915906faae 4 weeks ago /bin/sh -c #(nop) ENV PG_VERSION=9.4.4-1.pgdg 0 Bb41b53da5fba 4 weeks ago /bin/sh -c #(nop) ENV PG_MAJOR=9.4 0 B02fa71f1fa38 4 weeks ago /bin/sh -c apt-key adv --keyserver ha.pool.sk 3.212 kB0b82f508e063 4 weeks ago /bin/sh -c mkdir /docker-entrypoint-initdb.d 0 Be07b5a739ed9 4 weeks ago /bin/sh -c #(nop) ENV LANG=en_US.utf8 0 Bc783ebe7a1d4 4 weeks ago /bin/sh -c apt-get update apt-get install 19.54 MB8b6b2a3b7f9c 4 weeks ago /bin/sh -c apt-get update apt-get install 3.758 MB22ed955cce18 5 weeks ago /bin/sh -c gpg --keyserver pool.sks-keyserver 98.87 kB26a84c436db4 5 weeks ago /bin/sh -c groupadd -r postgres useradd -r 330.4 kB9a61b6b1315e 5 weeks ago /bin/sh -c #(nop) CMD [/bin/bash] 0 B902b87aaaec9 5 weeks ago /bin/sh -c #(nop) ADD file:e1dd18493a216ecd0c 125.2 MB 总结 打印指定Image中每一层Image命令行的历史记录。 7.11 images 参数 使用方法 docker images [OPTIONS] [REPOSITORY]List images -a, --all=false Show all images (default hides intermediate images) --digests=false Show digests -f, --filter=[] Filter output based on conditions provided --help=false Print usage --no-trunc=false Dont truncate output -q, --quiet=false Only show numeric IDs 例子： 查询本里存储的镜像 $ sudo docker imgaesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEdocker.io/ubuntu latest 63e3c10217b8 7 days ago 188.3 MBdocker.google/etcd 2.1.1 2c319269dd15 8 days ago 23.32 MBdocker.io/postgres latest 730d1d72bda2 2 weeks ago 265.3 MBcentos latest 770327a1e9e7 2 weeks ago 418.9 MB… 将ID完整展现 $ sudo docker images --no-truncREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEscratch1 latest dc869bfd3085af05a1a070c7409193e8be88de00ff4560e2e9af80ffa9d2041d 58 minutes ago 0 Bregistry.liugang/centos latest 770327a1e9e746cf8d4449a7134e87917982b33c7f5cea584d941350f5ead7ac 4 weeks ago 418.9 MBregistry.liugang/busybox latest 8c2e06607696bd4afb3d03b687e361cc43cf8ec1a4a725bc96e39f05ba97dd55 4 months ago 2.43 MBdocker.io/scratch latest 511136ea3c5a64f264b78b5433614aec563103b4d4702f3ba7d4d2698e22c158 2 years ago 0 B 使用该命令将展现没有tag的镜像 $ sudo docker images --filter dangling=trueREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEnone none b133995b6291 About an hour ago 0 Bnone none 6fae83243a01 About an hour ago 0 Bnone none 4c6412305cfa About an hour ago 0 B 总结 其中第一字段是image镜像的名称；TAG一般表示为版本号，也可以自己定义 ；IMAGE ID 表示镜像的唯一ID ，这也是判断两个镜像文件是否为同一个的判断标准。 7.12 info 参数 用法 Usage: docker info [OPTIONS]Display system-wide information --help=false Print usage 例子 $ sudo docker -D infoContainers: 6Images: 30Storage Driver: devicemapper Pool Name: docker-8:3-28326-pool Pool Blocksize: 65.54 kB Backing Filesystem: xfs Data file: /dev/loop0 Metadata file: /dev/loop1 Data Space Used: 1.37 GB Data Space Total: 107.4 GB Data Space Available: 44.49 GB Metadata Space Used: 2.245 MB Metadata Space Total: 2.147 GB Metadata Space Available: 2.145 GB Udev Sync Supported: true Deferred Removal Enabled: false Data loop file: /var/lib/docker/devicemapper/devicemapper/data Metadata loop file: /var/lib/docker/devicemapper/devicemapper/metadata Library Version: 1.02.93-RHEL7 (2015-01-28)Execution Driver: native-0.2Logging Driver: json-fileKernel Version: 3.10.0-229.el7.x86_64Operating System: CentOS Linux 7 (Core)CPUs: 1Total Memory: 979.7 MiBName: localhost.localdomainID: PRVB:3SDE:YL4E:JT5P:5BIR:BUC5:PHXI:HG4B:P753:Y2BI:U7OU:YPGC 总结 这个命令在开发者报告Bug时会非常有用，结合docker vesion一起，可以随时使用这个命令把本地的配置信息提供出来，方便Docker的开发者快速定位问题。 7.13 inspect 参数 用法 Usage: docker inspect [OPTIONS] CONTAINER|IMAGE [CONTAINER|IMAGE...]Return low-level information on a container or image-f, --format= Format the output using the given go template--help=false Print usage-r, --remote=false Inspect remote images 例子 $ sudo docker inspect centos[ Id: 770327a1e9e746cf8d4449a7134e87917982b33c7f5cea584d941350f5ead7ac, Parent: 67c02c69a0fc420e781b9a1c676f19306e999aac2cf3ba24dfa4e0b9a5e34b5e, Comment: , Created: 2015-07-24T01:06:38.020790544Z, Container: 9163378b9f7fe2887bce56cb726c3845ce9af8ebc9cbef30d3af6315429a27ad,ContainerConfig: Hostname: 9163378b9f7f, Domainname: , User: , AttachStdin: true, ... ... ... 取出某一个值： $ sudo docker inspect --format=.Id centos770327a1e9e746cf8d4449a7134e87917982b33c7f5cea584d941350f5ead7ac 总结 查看容器运行时详细信息的命令。了解一个Image或者Container的完整构建信息就可以通过这个命令实现。 7.14 login 参数 用法 Usage: docker login [OPTIONS] [SERVER]Register or log in to a Docker registry server, if no server isspecified https://index.docker.io/v1/ is the default.-e, --email= Email--help=false Print usage-p, --password= Password-u, --username= Username 例子 root@liugang:~# docker loginUsername: usernamePassword: ****Email: [email protected]Login Succeeded 如果你有一个自己的仓库，你也可以连接到指定主机： $ sudo docker login localhost:8080 7.15 logout 参数 用法 Usage: docker logout [OPTIONS] [SERVER]Log out from a Docker registry, if no server isspecified https://index.docker.io/v1/ is the default.--help=false Print usage 例子 $ sudo docker logout localhost:8080 7.16 logs 参数 用法 Usage: docker logs [OPTIONS] CONTAINERFetch the logs of a container-f, --follow=false Follow log output--help=false Print usage--since= Show logs since timestamp-t, --timestamps=false Show timestamps--tail=all Number of lines to show from the end of the logs 例子：打印某个容器日志 $ sudo docker logs 60095325e584 例子：实时监控容器某个容器日志输出 $ sudo docker logs -f 60095325e584 总结 批量打印出容器中进程的运行日志。 7.17 network 参数network connect你可以使用容器名称或者ID，将一个正在运行的容器介入网络。连接成功后容器酒可以与处于同一个网络中的容器通信。 docker network connect multi-host-network coantainer1 你也可以使用 docker run –net 选项来启动一个容器直接连接到一个已知网络。 docker run -idt --net=multi-host-network busybox 你可以暂停，重启甚至终止已连接网络的容器。暂停容器将保持网络连接以及网络发现（ by a network inspect）。终止容器，将使容器在该网络上消失，直到重启才可以被发现。当容器重启以后，容器重新加入该网络将不保证IP地址保持与原来一致。 使用 docker network inspect 命令来验证容器的网络是否已连接，而使用 docker network disconnect 来从网络上断开与容器的连接、 当容器连接到网络时，容器职能使用容器IP地址或者容器name来通信。对于overlay网络或者其它通过插件配置的跨主机环境的网络，然可以使用这种方式运行。 你可以使容器连接一个活多个网络，这些网络不要是相同类型的。例如：你可以连接一个容器网桥和overlay网络。 network create该命令用于创建一个网络。使用 -d参数允许使用bridge或者overlay类型的网络构建与网络驱动中。如果你有第三种网络结构或者其它通用网络驱动，你也可以使用该参数特别说明。 如果不指定 –driver 参数，该命令将自动为你创建一个bridge类型的网络。该网络对应与传统的docker0网桥。当使用 docker run 启动一个容器时，它将自动连接到这个bridge网络。你不能删除这个默认的网络但是可以使用docker network create 命令创建一个新的： docker network create -d bridge my-bridge-network birdge网络是单docker引擎的隔离网络（Bridge networks are isolated networks on a single Engine installation）。如果你想创建一个跨越多个docker主机引擎的网络，你必须创建一个overlay类型的网络。与birdge网络不同，overlay网络创建需要提前准备一些配置： 1、需要连接一个 key－value 存储，目前支持Consul，Etcd以及Zookeeper（分布式存储）key－value 存储。2、一个连接到 key－value 存储的云主机3、每一台机器上的 docker deamon 都要配置相同参数 docker deamon 支持overlay选项的参数有： --cluster-store--cluster-store-opt--cluster-advertise 想要了解更多有关配置以上参数的信息，请阅读 “Get started with multi-host network“ 你可以安装 docker swarm 来管理集群建立自己的网络，这是一个不错的想法，但不是必须的。 Swarm提供先进的服务发现以及节点管理来帮助你实现。 当你准备好你的overlay网络时，你只需选择集群中的一个docker主机并执行以下命令： docker network create -d overlay my-multihost-network 网络名称必须是唯一的，docker deamon 会尝试验证命名冲突，但并不保证（我就呵呵了）。用户有责任去避免命名冲突（呵呵呵。。。）。 connect containers当你使用 –net 参数连接到一个网络时，这将会使目标容器连接到自定义网络中去： docker run -idt --net=mynet busybox 如果你想在一个容器运行之后添加到一个网络中去，可以使用 docker network connect 命令。 你可以将多个容器连接到相同的网络中去。一旦连接，容器将只能通过IP或者容器名称进行通信。对于overlay网络或者其它通过插件配置的跨主机环境的网络，然可以使用这种方式运行。 使用 docker network disconnect 可以断开容器与网络的连接 Specifying advanced options当创建一个网络时，docker Engine 会默认为该网络创建一个非重叠子网。这个子网并不是已存在子网的划分，它纯粹为了IP寻址（It is purely for ip-addressing purposes）。你可以覆盖这个默认的，然后使用 –subnet 选项来特别定义。在bridge网络上你可以这样定义： docker network create -d --subnet=192.168.0.0/16 此外，你还可以指定 –gateway –ip-range 以及 –aux-addressoptions。 docker network create --driver=bridge --subnet=172.28.0.0/16 --ip-range=172.28.5.0 --gateway=172.28.5.154 如果你省略了 –gateway 选项，docker Engine 将会从内置的 preferred pool 为你选择一个。 对于overlay网络，你可以创建多个子网： docker network create -d overlay--subnet=192.168.0.0/16 --subnet=192.170.0.0/16--gateway=192.168.0.100 --gateway=192.170.0.100--ip-range=192.168.1.0/24--aux-address a=192.168.1.5 --aux-address b=192.168.1.6--aux-address a=192.170.1.5 --aux-address b=192.170.1.6my-multihost-newtork 但是确保你的子网不要重叠，否则，创建网络就会失败，Engine 将会反悔错误。 network disconnect断开容器与网络的连接。 docker network disconnect multi-host-network container1 network ls列出deamon知道的所有的网络，包括跨多主机的集群网络。 sudo docker network lsNETWORK ID NAME DRIVER7fca4eb8c647 bridge bridge9f904ee27bf5 none nullcf03ee007fb4 host host78b03ee04fc4 multi-host overlay 使用 –no-trunc 选项来显示整个网络的ID docker network ls --no-truncNETWORK ID NAME DRIVER18a2866682b85619a026c81b98a5e375bd33e1b0936a26cc497c283d27bae9b3 none null c288470c46f6c8949c5f7e5099b5b7947b07eabe8d9a27d79a9cbf111adcbf47 host host 7b369448dccbf865d397c8d2be0cda7cf7edc6b0945f77d2529912ae917a0185 bridge bridge 95e74588f40db048e86320c6526440c504650a1ff3e9f7d60a497c4d2163e5bd foo bridge network rm删除一个网络，在删除该网络之前，必须断开与该网络连接的任何容器。 docker network rm my-network 7.18 search 参数说明：搜索镜像仓库 用法 Usage: docker search [OPTIONS] TERMSearch the Docker Hub for images --automated=false Only show automated builds --help=false Print usage --no-index=false Dont prepend index to output --no-trunc=false Dont truncate output -s, --stars=0 Only displays with at least x stars 例子 $ sudo docker search ubuntu 从官方仓库中搜索出含有关键字ubuntu的镜像： INDEX NAM DESCRIPTION STARS OFFICIAL AUTOMATEDdocker.io docker.io/ubuntu Ubuntu is a Debian-based Linux operating s... 2046 [OK]docker.io docker.io/ubuntu-upstart Upstart is an event-based replacement for ... 30 [OK]docker.io docker.io/torusware/speedus-ubuntu Always updated official Ubuntu docker imag... 25 [OK]docker.io docker.io/dorowu/ubuntu-desktop-lxde-vnc Ubuntu with openssh-server and NoVNC on po... 20 [OK]docker.io docker.io/sequenceiq/hadoop-ubuntu An easy way to try Hadoop on Ubuntu 19 [OK]docker.io docker.io/tleyden5iwx/ubuntu-cuda Ubuntu 14.04 with CUDA drivers pre-installed 16 [OK]docker.io docker.io/ubuntu-debootstrap debootstrap --variant=minbase --components... 12 [OK]… 总结 在使用docker创建容器时，必然要用到镜像文件。这时我们就得从仓库中拉取我们所需要的image文件。 7.19 pull 参数说明：拉取镜像仓库 用法 Usage: docker pull [OPTIONS] NAME[:TAG|@DIGEST]Pull an image or a repository from the registry-a, --all-tags=false Download all tagged images in the repository--help=false Print usage 例子 找到所需要的镜像： $ sudo docker pull docker.io/ubuntu:12.04 这里是从官方仓库中拉取下来版本号(TAG)为12.04的镜像，其中“docker.io” 可以不写，默认是从官方仓库下载。版本号(TAG)不写的话默认会拉取一个版本号为latest的镜像文件： Trying to pull repository docker.io/ubuntu ...d0e008c6cf02: Download completea69483e55b68: Download completebc99d1f906ec: Download complete3c8e79a3b1eb: Download completeStatus: Downloaded newer image for docker.io/ubuntu:12.04 见到如上类似结果说明镜像拉取成功。现在看一下自己的仓库，多了一个12.04的镜像。 $ sudo docker imagesREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEdocker.io/ubuntu latest 63e3c10217b8 7 days ago 188.3 MBdocker.io/ubuntu 12.04 d0e008c6cf02 7 days ago 134.7 MBdocker.google/etcd 2.1.1 2c319269dd15 8 days ago 23.32 MBdocker.io/postgres latest 730d1d72bda2 2 weeks ago 265.3 MB… 7.20 push 参考说明：将镜像上传到仓库 用法 Usage: docker push [OPTIONS] NAME[:TAG]Push an image or a repository to the registry -f, --force=false Push to public registry without confirmation --help=false Print usage 例子 $ sudo docker push docker.io/ubuntu:latest 总结 镜像的上传，push 默认是向官方仓库上传，由于服务器在国外，传输速度非常慢，就没试验成功过。注意的是，需要在docker hub上注册过后才可以上传镜像哦。关于私有仓库的上传将在后面章节详细讲解。 7.21 ps 参数 用法 Usage: docker ps [OPTIONS] List containers -a, --all=false Show all containers (default shows just running)--before= Show only container created before Id or Name-f, --filter=[] Filter output based on conditions provided--help=false Print usage-l, --latest=false Show the latest created container, include non-running-n=-1 Show n last created containers, include non-running--no-trunc=false Dont truncate output-q, --quiet=false Only display numeric IDs-s, --size=false Display total file sizes--since= Show created since Id or Name, include non-running 例子 $ sudo docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb448f729a0b0 centos /bin/bash 4 days ago Exited (137) 4 days ago pensive_wilson54c7b6d6632e centos /bin/bash 4 days ago Exited (0) 3 days ago adoring_wozniak 利用筛选器筛选出exied状态时0的容器： $ sudo docker ps -a --filter exited=0CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8d92293a65e9 registry.liugang/centos /bin/bash 7 days ago Exited (0) 5 days ago web8410f389ea65 registry.liugang/centos /bin/bash 7 days ago Exited (0) 7 days ago test_link 总结 -a参数列出所有状态的容器， -l列出最新创建的容器，包括停止运行状态的容器。 7.22 kill 参数 用法 Usage: docker kill [OPTIONS] CONTAINER [CONTAINER...]Kill a running container using SIGKILL or a specified signal --help=false Print usage -s, --signal=KILL Signal to send to the container 例子 $ sudo docker kill pensive_wilsonpensive_wilson 这将停止该容器 总结 结合ps命令，可以做到kill所有正在运行的容器： $ sudo docker kill $(sudo docker ps -a -q) 7.23 rm 参数 用法 Usage: docker rm [OPTIONS] CONTAINER [CONTAINER...]Remove one or more containers -f, --force=false Force the removal of a running container (uses SIGKILL) --help=false Print usage -l, --link=false Remove the specified link -v, --volumes=false Remove the volumes associated with the container 例子 $ sudo docker rm pensive_wilsonpensive_wilson 这将删除一个已经停止运行的容器，若容器正在运行，则将会使docker报错，停止容器再删除，或者加上-f参数强制删除（不建议）。 总结 类似的我们也结合ps删除所有容器： $ sudo docker kill $(sudo docker ps -a -q).........$ sudo docker rm $(sudo docker ps -a -q)......... 要清空容器，首先要保证没有容器在运行。 7.24 rmi 参数 用法 Usage: docker rmi [OPTIONS] IMAGE [IMAGE...]Remove one or more images -f, --force=false Force removal of the image --help=false Print usage --no-prune=false Do not delete untagged parents 例子 $ sudo docker rmi centos:6.5......... 总结 要区分rm于rmi多用法。 与docker images命令配合来清空镜像： $ sudo docker rmi $(sudo docker images -a -q) 7.25 port 参数 用法 Usage: docker port [OPTIONS] CONTAINER [PRIVATE_PORT[/PROTO]]List port mappings for the CONTAINER, or lookup the public-facing port thatis NAT-ed to the PRIVATE_PORT --help=false Print usage 例子 $ sudo docker port 60095325e584 总结 打印出Host主机端口与容器暴露出的端口的NAT映射关系 7.26 pause 参数 用法 Usage: docker pause [OPTIONS] CONTAINER [CONTAINER...]Pause all processes within a container --help=false Print usage 例子 $ sudo docker pauese hopeful_feynmanhopeful_feynmanCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc9a12157fed7 centos /bin/bash 9 minutes ago Up 9 minutes (Paused) hopeful_feynman 使容器内进程暂停 7.27 unpause 参数 用法 Usage: docker unpause [OPTIONS] CONTAINER [CONTAINER...]Unpause all processes within a container --help=false Print usage 例子 $ sudo docker pauese hopeful_feynmanhopeful_feynman 恢复暂停 7.28 create 参数 用法 Usage: docker create [OPTIONS] IMAGE [COMMAND] [ARG...]Create a new container -a, --attach=[] Attach to STDIN, STDOUT or STDERR --add-host=[] Add a custom host-to-IP mapping (host:ip) --blkio-weight=0 Block IO (relative weight), between 10 and 1000 -c, --cpu-shares=0 CPU shares (relative weight) --cap-add=[] Add Linux capabilities --cap-drop=[] Drop Linux capabilities --cgroup-parent= Optional parent cgroup for the container --cidfile= Write the container ID to the file --cpu-period=0 Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota=0 Limit the CPU CFS quota --cpuset-cpus= CPUs in which to allow execution (0-3, 0,1) --cpuset-mems= MEMs in which to allow execution (0-3, 0,1) --device=[] Add a host device to the container --dns=[] Set custom DNS servers --dns-search=[] Set custom DNS search domains -e, --env=[] Set environment variables --entrypoint= Overwrite the default ENTRYPOINT of the image --env-file=[] Read in a file of environment variables --expose=[] Expose a port or a range of ports -h, --hostname= Container host name --help=false Print usage -i, --interactive=false Keep STDIN open even if not attached --init= Run container following specified init system container method (systemd) --ipc= IPC namespace to use -l, --label=[] Set meta data on a container --label-file=[] Read in a line delimited file of labels --link=[] Add link to another container --log-driver= Logging driver for container --log-opt=[] Log driver options --lxc-conf=[] Add custom lxc options -m, --memory= Memory limit --mac-address= Container MAC address (e.g. 92:d0:c6:0a:29:33) --memory-swap= Total memory (memory + swap), -1 to disable swap --name= Assign a name to the container --net=bridge Set the Network mode for the container --oom-kill-disable=false Disable OOM Killer -P, --publish-all=false Publish all exposed ports to random ports -p, --publish=[] Publish a containers port(s) to the host --pid= PID namespace to use --privileged=false Give extended privileges to this container --read-only=false Mount the containers root filesystem as read only --restart=no Restart policy to apply when a container exits --security-opt=[] Security Options -t, --tty=false Allocate a pseudo-TTY -u, --user= Username or UID (format: name|uid[:group|gid]) --ulimit=[] Ulimit options --uts= UTS namespace to use -v, --volume=[] Bind mount a volume --volumes-from=[] Mount volumes from the specified container(s) -w, --workdir= Working directory inside the container 例子 $ sudo docker create ubuntu /bin/echo Hello worlda637c1d67506951928be296f2db02fa3e2b6e974ef371b181d9c26d1c8995963$... 若有如上输出则代表容器创建成功 $ sudo docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa637c1d67506 ubuntu:latest /bin/echo Hello wo 4 minutes ago mad_hopper... 然后在启动它 $ sudo docker start a637c1d67506a637c1d67506$... 启动成功后会反回容器ID。 $ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa637c1d67506 ubuntu:latest /bin/echo Hello wo 10 minutes ago Exited (0) 2 minutes ago mad_hopper 总结 当我们去查看容器状态时，容器没有在运行，这时因为我们在创建容器的时候，让容器执行的命令是binecho ‘Hello world’，当容器执行完命令的时候就终止结束了。 7.29 run 参数 用法 Usage: docker run [OPTIONS] IMAGE [COMMAND] [ARG...]Run a command in a new container -a, --attach=[] Attach to STDIN, STDOUT or STDERR --add-host=[] Add a custom host-to-IP mapping (host:ip) --blkio-weight=0 Block IO (relative weight), between 10 and 1000 -c, --cpu-shares=0 CPU shares (relative weight) --cap-add=[] Add Linux capabilities --cap-drop=[] Drop Linux capabilities --cgroup-parent= Optional parent cgroup for the container --cidfile= Write the container ID to the file --cpu-period=0 Limit CPU CFS (Completely Fair Scheduler) period --cpu-quota=0 Limit the CPU CFS quota --cpuset-cpus= CPUs in which to allow execution (0-3, 0,1) --cpuset-mems= MEMs in which to allow execution (0-3, 0,1) -d, --detach=false Run container in background and print container ID --device=[] Add a host device to the container --dns=[] Set custom DNS servers --dns-search=[] Set custom DNS search domains -e, --env=[] Set environment variables --entrypoint= Overwrite the default ENTRYPOINT of the image --env-file=[] Read in a file of environment variables --expose=[] Expose a port or a range of ports -h, --hostname= Container host name --help=false Print usage -i, --interactive=false Keep STDIN open even if not attached --init= Run container following specified init system container method (systemd) --ipc= IPC namespace to use -l, --label=[] Set meta data on a container --label-file=[] Read in a line delimited file of labels --link=[] Add link to another container --log-driver= Logging driver for container --log-opt=[] Log driver options --lxc-conf=[] Add custom lxc options -m, --memory= Memory limit --mac-address= Container MAC address (e.g. 92:d0:c6:0a:29:33) --memory-swap= Total memory (memory + swap), -1 to disable swap --name= Assign a name to the container --net=bridge Set the Network mode for the container --oom-kill-disable=false Disable OOM Killer -P, --publish-all=false Publish all exposed ports to random ports -p, --publish=[] Publish a containers port(s) to the host --pid= PID namespace to use --privileged=false Give extended privileges to this container --read-only=false Mount the containers root filesystem as read only --restart=no Restart policy to apply when a container exits --rm=false Automatically remove the container when it exits --security-opt=[] Security Options --sig-proxy=true Proxy received signals to the process -t, --tty=false Allocate a pseudo-TTY -u, --user= Username or UID (format: name|uid[:group|gid]) --ulimit=[] Ulimit options --uts= UTS namespace to use -v, --volume=[] Bind mount a volume --volumes-from=[] Mount volumes from the specified container(s) -w, --workdir= Working directory inside the container 例子 用法与create类似，只是在创建容器后不需要进行start操作就可以运行。 $ sudo docker run ubuntu /bin/echo Hello worldHello world$... 与上面一样，在运行完Hello world 之后也会退出容器。 Daemonized（守护态） 往往我们需要容器在后台一致执行，这时我们就需要在创建镜像的时候让容器以守护台方式(-d 参数)运行。 $ sudo docker run -d ubuntu /bin/sh -c while true; do echo hello world; sleep 1; done61f37c1940c8ec9f08b107e99655b8a5181ded340415e3c15cf413069d556b73$... 这时，我们查看一下容器状态： $ sudo docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES61f37c1940c8 ubuntu:latest /bin/sh -c while t 4 seconds ago Up 3 seconds prickly_galileo... 查看容器输出的信息 $ sudo docker logs 61f37c1940c8hello worldhello worldhello worldhello world... 总结 让容器以后台方式运行，并不是加一个 -d 参数就可以，命令行COMMAND所执行的动作必须为持续运行的状态。 7.30 save 参数 用法 Usage: docker save [OPTIONS] IMAGE [IMAGE...]Save an image(s) to a tar archive (streamed to STDOUT by default) --help=false Print usage -o, --output= Write to an file, instead of STDOUT 例子 载出镜像到文件 $ sudo docker save -o /home/ubuntu.tar docker.io/ubuntu:latest 这样我们就在home目录下找到ubuntu.tar 文件了 总结 在国内docker.io的下载速度奇慢，基本上下一个500M的image就可以搞你半天时间，这时我们就可以利用载入载出，从好朋友那里获取我们需要的镜像啦！ 7.31 load 参数 用法 Usage: docker load [OPTIONS]Load an image from a tar archive on STDIN --help=false Print usage -i, --input= Read from a tar archive file, instead of STDIN 例子 从文件载入镜像到本地 $ sudo docker load --input /home/ubuntu.tar 或者 $ sudo docker load /home/ubuntu.tar 总结 这种方式将导入镜像以及其相关的元数据信息（包括标签等）。 7.32 start 参数说明：启动容器参数 用法 Usage: docker start [OPTIONS] CONTAINER [CONTAINER...]Start one or more stopped containers-a, --attach=false Attach STDOUT/STDERR and forward signals--help=false Print usage-i, --interactive=false Attach containers STDIN 7.33 stop 参数说明：停止容器参数 用法 Usage: docker stop [OPTIONS] CONTAINER [CONTAINER...]Stop a running container by sending SIGTERM and then SIGKILL after agrace period--help=false Print usage-t, --time=10 Seconds to wait for stop before killing it 7.34 restart 参数说明：重启容器参数 用法 Usage: docker restart [OPTIONS] CONTAINER [CONTAINER...]Restart a running container--help=false Print usage-t, --time=10 Seconds to wait for stop before killing the container 7.34 stats 参数 用法 Usage: docker stats [OPTIONS] CONTAINER [CONTAINER...]Display a live stream of one or more containers resource usage statistics--help=false Print usage--no-stream=false Disable streaming stats and only pull the first result 例子 $ docker stats redis1 redis2CONTAINER CPU % MEM USAGE/LIMIT MEM % NET I/Oredis1 0.07% 796 KB/64 MB 1.21% 788 B/648 Bredis2 0.07% 2.746 MB/64 MB 4.29% 1.266 KB/648 B 总结 该指令将只返回运行状态容器的数据流情况，停止状态的容器将不会返回任何数据。 7.35 tag 参数说明：常用参数，主要用于镜像标签重命名 用法 Usage: docker tag [OPTIONS] IMAGE[:TAG] [REGISTRYHOST/][USERNAME/]NAME[:TAG] docker tag -l [REGISTRYHOST/][USERNAME/]NAME...Tag an image or list remote tags-f, --force=false Force--help=false Print usage-l, --list=false List repository tags-r, --remote=false Force listing of remote repositories only 例子 $ sudo docker tag docker.io/scratch:latest local/scratch:my 总结 组合使用用户名，Image名字，标签名来组织管理Image。 7.36 top 参数 用法 Usage: docker top [OPTIONS] CONTAINER [ps OPTIONS]Display the running processes of a container--help=false Print usage 例子 运行一个之前的例子： $ sudo docker run -d ubuntu /bin/sh -c while true; do echo hello world; sleep 1; done 然后执行docker top 命令，可以查看到容器内进程 $ sudo docker top 52c058ff716dUID PID PPID C STIME TTY TIME CMDroot 6326 1489 0 23:58 ? 00:00:00 /bin/sh -c while true; do echo hello world; sleep 1; doneroot 6410 6326 0 23:59 ? 7.37 wait 参数说明：阻塞对指定容器的其他调用方法，直到容器停止后退出阻塞。 用法 Usage: docker wait [OPTIONS] CONTAINER [CONTAINER...]Block until a container stops, then print its exit code.--help=false Print usage"},{"title":"6. Docker 基本参数说明","path":"/wiki/docker/referdesc.html","content":"6. Docker 基本参数说明Docker官方为了让用户快速了解Docker，提供了一个交互式教程，旨在帮助用户掌握Docker命令行的使用方法。但是由于Docker技术的快速发展，此交互式教程已经无法满足Docker用户的实际使用需求，所以让我们一起开始一次真正的命令行学习之旅。首先，Docker的命令清单可以通过运行 docker ，或者 docker help 命令得到: $ sudo docker --helpUsage: docker [OPTIONS] COMMAND [arg...]A self-sufficient runtime for linux containers.Options:--add-registry=[] Registry to query before a public one --api-cors-header= Set CORS headers in the remote API -b, --bridge= Attach containers to a network bridge --bip= Specify network bridge IP --block-registry=[] Dont contact given registry --confirm-def-push=true Confirm a push to default registry -D, --debug=false Enable debug mode -d, --daemon=false Enable daemon mode --default-gateway= Container default gateway IPv4 address --default-gateway-v6= Container default gateway IPv6 address --default-ulimit=[] Set default ulimits for containers --dns=[] DNS server to use --dns-search=[] DNS search domains to use -e, --exec-driver=native Exec driver to use --exec-opt=[] Set exec driver options --exec-root=/var/run/docker Root of the Docker execdriver --fixed-cidr= IPv4 subnet for fixed IPs --fixed-cidr-v6= IPv6 subnet for fixed IPs -G, --group=docker Group for the unix socket -g, --graph=/var/lib/docker Root of the Docker runtime -H, --host=[] Daemon socket(s) to connect to -h, --help=false Print usage --icc=true Enable inter-container communication --insecure-registry=[] Enable insecure registry communication --ip=0.0.0.0 Default IP when binding container ports --ip-forward=true Enable net.ipv4.ip_forward --ip-masq=true Enable IP masquerading --iptables=true Enable addition of iptables rules --ipv6=false Enable IPv6 networking -l, --log-level=info Set the logging level --label=[] Set key=value labels to the daemon --log-driver=json-file Default driver for container logs --log-opt=map[] Set log driver options --mtu=0 Set the containers network MTU -p, --pidfile=/var/run/docker.pid Path to use for daemon PID file --registry-mirror=[] Preferred Docker registry mirror -s, --storage-driver= Storage driver to use --selinux-enabled=false Enable selinux support --storage-opt=[] Set storage driver options --tls=false Use TLS; implied by --tlsverify --tlscacert=~/.docker/ca.pem Trust certs signed only by this CA --tlscert=~/.docker/cert.pem Path to TLS certificate file --tlskey=~/.docker/key.pem Path to TLS key file --tlsverify=false Use TLS and verify the remote --userland-proxy=true Use userland proxy for loopback traffic -v, --version=false Print version information and quitCommands: attach Attach to a running container build Build an image from a Dockerfile commit Create a new image from a containers changes cp Copy files/folders from a containers filesystem to the host path create Create a new container diff Inspect changes on a containers filesystem events Get real time events from the server exec Run a command in a running container export Stream the contents of a container as a tar archive history Show the history of an image images List images import Create a new filesystem image from the contents of a tarball info Display system-wide information inspect Return low-level information on a container or image kill Kill a running container load Load an image from a tar archive login Register or log in to a Docker registry server logout Log out from a Docker registry server logs Fetch the logs of a container pause Pause all processes within a container port Lookup the public-facing port that is NAT-ed to PRIVATE_PORT ps List containers pull Pull an image or a repository from a Docker registry server push Push an image or a repository to a Docker registry server rename Rename an existing container restart Restart a running container rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save an image to a tar archive search Search for an image on the Docker Hub start Start a stopped container stats Display a stream of a containers resource usage statistics stop Stop a running container tag Tag an image into a repository top Lookup the running processes of a container unpause Unpause a paused container version Show the Docker version information wait Block until a container stops, then print its exit codeRun docker COMMAND --help for more information on a command. 在Docker容器技术不断演化的过程中，Docker的子命令已经达到39个之多，其中核心子命令(例如：run)还会有复杂的参数配置。笔者通过结合功能和应用场景方面的考虑，把命令行划分为4个部分，方便我们快速概览Docker命令行的组成结构： 功能划分 命令 环境信息相关 info version 系统运维相关 attach build commit cp diff export images import saveload inspect kill port pauseunpause ps rm rmi run startstoprestart tag top 日志信息相关 events history logs 仓库服务相关 login pull push search 1.参数约定 单个字符的参数可以放在一起组合配置，例如 $ sudo docker run -t -i --name test centos sh 可以用这样的方式等同： $ sudo docker run -ti --name test centos sh 2.Boolean Boolean参数形式如： -dfalse。注意，当你声明这个Boolean参数时，比如 docker run -dtrue，它将直接把启动的Container挂起放在后台运行。 3.字符串和数字 参数如 –name“” 定义一个字符串，它仅能被定义一次。同类型的如-c0 定义一个数字，它也只能被定义一次。 4.后台进程 Docker后台进程是一个常驻后台的系统进程，值得注意的是Docker使用同一个文件来支持客户端和后台进程，其中角色切换通过-d来实现。这个后台进程是用来管理容器的: 参数 解释 –add-registry[] Registry to query before a public one –api-cors-header Set CORS headers in the remote API -b, –bridge 挂载已经存在的网桥设备到 Docker 容器里。注意，使用 none 可以停用容器里的网络。 –bip 使用 CIDR 地址来设定网络桥的 IP。注意，此参数和 -b 不能一起使用。 –block-registry[] Don’t contact given registry –confirm-def-pushtrue Confirm a push to default registry -D, –debugfalse 开启Debug模式。例如：docker -d -D -d, –daemonfalse 开启Daemon模式。 –default-gateway Container default gateway IPv4 address –default-gateway-v6 Container default gateway IPv6 address –default-ulimit[] Set default ulimits for containers –dns[] 强制容器使用DNS服务器。例如： docker -d –dns 8.8.8.8 –dns-search[] 强制容器使用指定的DNS搜索域名。例如： docker -d –dns-search example.com -e, –exec-drivernative 强制容器使用指定的运行时驱动。例如：docker -d -e lxc –exec-opt[] Set exec driver options –exec-rootvarrundocker Root of the Docker execdriver –fixed-cidr IPv4 subnet for fixed IPs –fixed-cidr-v6 IPv6 subnet for fixed IPs -G, –groupdocker 在后台运行模式下，赋予指定的Group到相应的unix socket上。注意，当此参数 –group 赋予空字符串时，将去除组信息。 -g, –graphvarlibdocker 配置Docker运行时根目录 -H, –host[] Daemon socket(s) to connect to -h, –helpfalse 在后台模式下指定socket绑定，可以绑定一个或多个 tcp:host:port, unix:pathtosocket, fd:* 或 fd:socketfd。例如： $ docker -H tcp:0.0.0.0:2375 ps 或者 $ export DOCKER_HOST”tcp:0.0.0.0:2375” $ docker ps –icctrue 启用内联容器的通信。 –insecure-registry[] Enable insecure registry communication –ip0.0.0.0 容器绑定IP时使用的默认IP地址 –ip-forwardtrue Enable net.ipv4.ip_forward –ip-masqtrue Enable IP masquerading –iptablestrue 启动Docker容器自定义的iptable规则 –ipv6false Enable IPv6 networking -l, –log-levelinfo Set the logging level –label[] Set keyvalue labels to the daemon –log-driverjson-file Default driver for container logs –log-optmap[] Set log driver options –mtu0 设置容器网络的MTU值，如果没有这个参数，选用默认 route MTU，如果没有默认route，就设置成常量值 1500。 -p, –pidfilevarrundocker.pid 后台进程PID文件路径。 –registry-mirror[] Preferred Docker registry mirror -s, –storage-driver 强制容器运行时使用指定的存储驱动，例如,指定使用devicemapper, 可以这样： $ sudo docker -d -s devicemapper –selinux-enabledfalse 启用selinux支持 –storage-opt[] 配置存储驱动的参数 –tlsfalse 启动TLS认证开关 –tlscacert~.dockerca.pem 通过CA认证过的的certificate文件路径 –tlscert~.dockercert.pem TLS的certificate文件路径 –tlskey~.dockerkey.pem TLS的key文件路径 –tlsverifyfalse 使用TLS并做后台进程与客户端通讯的验证 –userland-proxytrue Use userland proxy for loopback traffic -v, –versionfalse 显示版本信息 注意，其中带有[] 的启动参数可以指定多次，例如: $ sudo docker run -a stdin -a stdout -a stderr -i -t ubuntu /bin/bash"},{"title":"8. Docker run 运行容器","path":"/wiki/docker/running.html","content":"8. docker run 运行容器Docker run 作为运行容器的直接入口，命令参数相当丰富，使用它可以启动容器，使容器拥有自己的文件系统、网络以及关系进程树。 Docker run 命令基本结构： $ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...] docker run 命令示例以下是一个比较常见的 Docker run 命令示例，用于创建一个 NGINX 容器： docker run -d \\ --name my_nginx \\ --restart=always \\ -p 80:80 \\ -v /path/to/nginx/conf:/etc/nginx/conf.d \\ -v /path/to/nginx/html:/usr/share/nginx/html \\ nginx:latest -d: 在后台以守护进程模式运行容器。 --name my_nginx: 为容器指定一个名称（可以根据需要更改为您喜欢的名称）。 --restart=always：指定容器在退出时的重启策略。 -p 80:80: 将主机的端口 80 映射到容器的端口 80。这样，您可以通过访问 http://localhost 来访问 NGINX 容器中的网站。 -v /path/to/nginx/conf:/etc/nginx/conf.d: 将主机上的 NGINX 配置文件目录挂载到容器中的 /etc/nginx/conf.d 目录，以便使用自定义的 NGINX 配置。 -v /path/to/nginx/html:/usr/share/nginx/html: 将主机上的 HTML 文件目录挂载到容器中的 /usr/share/nginx/html 目录，以便在容器中提供自定义的静态网页内容。 nginx:latest: 指定要使用的 NGINX 镜像及其标签（可以根据实际情况替换为您自己的镜像名称和标签）。 Docker run 命令是在 Docker 中创建和运行容器的主要命令之一。它允许您根据需要配置容器的各种属性。以下是 Docker run 命令的30个常用参数的详细解释和示例用法，帮助您更好地理解和使用这些参数。 `-d` 或 `--detach`：以后台模式运行容器，将容器放置在后台运行，作为守护进程。示例：`docker run -d image_name``-it`：以交互模式运行容器，允许与容器进行交互。示例：docker run -it image_name --name`：为容器指定一个名称。示例：docker run --name container_name image_name `-p`：将容器的端口映射到主机上的一个端口。示例：docker run -p host_port:container_port image_name`-v`：挂载主机上的文件或目录到容器内部。示例：docker run -v host_path:container_path image_name`-e`：设置容器的环境变量。示例：docker run -e ENV_VARIABLE=value image_name`--restart`：指定容器在退出时的重启策略。示例：docker run --restart=always image_name `--link`：将容器连接到另一个容器，在两个容器之间建立网络连接。示例：docker run --link container_name:image_alias image_name`--dns`：指定容器使用的自定义 DNS 服务器。示例：docker run --dns 8.8.8.8 image_name`--dns-search`：指定容器的 DNS 搜索域。示例：docker run --dns-search example.com image_name`--cap-add` 和 `--cap-drop`：增加或删除容器的 `Linux` 能力，用于控制容器的权限。示例：docker run --cap-add=SYS_ADMIN image_name `--privileged`：给容器赋予特权，可以访问主机的设备。示例：docker run --privileged image_name `--tmpfs`：在容器内创建临时文件系统，用于存储临时数据。示例：docker run --tmpfs /tmp image_name `--ulimit`：设置容器的资源限制，如最大打开文件数、最大进程数等。示例：docker run --ulimit nofile=1024:1024 image_name `--security-opt`：设置容器的安全选项，如 `AppArmor` 配置、`Seccomp` 配置等。示例：docker run --security-opt seccomp:unconfined image_name `--cpu-shares`：设置容器的 CPU 份额，用于控制 CPU 资源的分配。示例：docker run --cpu-shares 512 image_name`--memory`：设置容器可使用的内存限制。示例：docker run --memory 1g image_name`--network`：指定容器使用的网络模式。示例：`docker run --network bridge image_name``--hostname`：设置容器的主机名。示例：docker run --hostname my_container image_name`--user`：指定容器运行时的用户名或 UID。示例：docker run --user username image_name`--volume-driver`：指定容器使用的卷驱动程序。示例：docker run --volume-driver my_driver image_name`--shm-size`：设置容器的共享内存大小。示例：docker run --shm-size 2g image_name`--add-host`：向容器的 `/etc/hosts` 文件添加自定义主机名和 IP 映射。示例：docker run --add-host myhost:192.168.0.100 image_name`--read-only`：将容器的文件系统设置为只读模式。示例：docker run --read-only image_name`–cpu-quota`：设置容器的 CPU 配额，以微秒为单位。示例：docker run --cpu-quota=50000 image_name`--cpu-period`：设置容器的 CPU 周期，以微秒为单位。示例：docker run --cpu-period=100000 image_name`--dns-option`：为容器的 DNS 配置添加自定义选项。示例：docker run --dns-option=timeout:5 image_name`--sysctl`：设置容器的内核参数。示例：docker run --sysctl net.ipv4.ip_forward=1 image_name`--label`：为容器添加标签，用于识别和组织容器。示例：docker run --label env=production image_name`--workdir`：设置容器的工作目录。示例：docker run --workdir /app image_name 为了更好理解，我们将参数分为以下几类： 容器管理： 后台程序和前台交互程序 器的定义 网络设置 CPU和内存的runtime 权限和LXC配置 8.1 容器管理8.1.1 守护态运行 Detached当我们启动一个container时，首先需要确定这个container是运行在前台模式还是运行在后台模式。 如果在docker run 后面追加-dtrue或者-d，则containter将会运行在后台模式(Detached mode)。此时所有IO数据只能通过网络资源或者共享卷组来进行交互。因为container不再监听你执行docker run的这个终端命令行窗口。正如之前的例子： $ sudo docker run -d ubuntu /bin/sh -c while true; do echo hello world; sleep 1; done61f37c1940c8ec9f08b107e99655b8a5181ded340415e3c15cf413069d556b73$... 但你可以通过执行docker attach 来重新挂载这个container里面。 $ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0409679f511a ubuntu /bin/sh -c while t 5 seconds ago Up 3 seconds thirsty_perlman$ sudo docker attach 0409679f511ahello worldhello worldhello world… 需要注意的是，如果你选择执行-d使container进入后台模式，那么将无法配合”–rm”参数。 8.1.2 带控制窗口运行与Detached（－d）对应的是Foregroud 如果在docker run后面没有追加-d参数，则container将默认进入前台模式(Foregroud mode)。Docker会启动这个container，同时将当前的命令行窗口挂载到container的标准输入，标准输出和标准错误中。也就是container中所有的输出，你都可以再当前窗口中查看到。甚至docker可以虚拟出一个TTY窗口，来执行信号中断。这一切都是可以配置的： -a=[] : Attach to `STDIN`, `STDOUT` and/or `STDERR`-t=false : Allocate a pseudo-tty--sig-proxy=true : Proxify all received signal to the process (non-TTY mode only)-i=false : Keep STDIN open even if not attached 如果在执行run命令时没有指定-a，那么docker默认会挂载所有标准数据流，包括输入输出和错误。你可以特别指定挂载哪个标准流。 $ sudo docker run -a stdin -a stdout -i -t ubuntu /bin/bash (只挂载标准输入输出) 对于执行容器内的交互式操作，例如shell脚本。我们必须使用 -i -t来申请一个控制台同容器进行数据交互。但是当通过管道与容器进行交互时，就不能使用-t. 例如下面的命令： $ echo test | docker run -i busybox cat 若强行加上-t 就会报出cannot enable tty mode on non tty input错误。 8.1.3 给容器命名给container 命名有三种方式： 使用UUID长命 (“f78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778”)，在创建容器时返回的id就是这个。 使用UUID短命令(“f78375b1c487”)，当执行查询时，查到的dockerID就是这个。 使用–nameevil_ptolemy”,若不加此指令，docker会自动给新创建出来的容器分配一个唯一的name $ sudo docker run -d --name=test_name registry.liugang/centos:latestf78375b1c487e03c9438c729345e54db9d20cfa2ac1fc3494b6eb60872e74778$ sudo docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESf78375b1c487 registry.liugang/centos:latest /bin/bash 17 seconds ago Exited (0) 17 seconds ago test_name 8.1.4 清除容器Clean up (–rm) 指在容器运行完之后自动清除 --rm=false: Automatically remove the container when it exits (incompatible with -d) 默认情况下，每个container在退出时，它的文件系统也会保存下来。这样一方面调试会方便些，因为你可以通过查看日志等方式来确定最终状态。另外一方面，你也可以保存container所产生的数据。但是当你仅仅需要短期的运行一个前台container，这些数据同时不需要保留时。你可能就希望docker能在container结束时自动清理其所产生的数据。 这个时候你就需要–rm这个参数了。 $ sudo docker run --rm centos:latest$ docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES(无) 注意：–rm 和 -d不能共用！ 8.2 数据管理8.2.1 数据卷参数的作用就是挂载一个文件目录到指定容器中去，实现容器中数据持久化。 数据卷是一个可以供一个或多个使用的特殊目录，它绕过UFS，可以提供很多有用的特性 数据卷可以在容器之间共享和重用 对数据卷的修改会立马生效 对数据卷的更新，不会影响镜像 卷会一直存在，直到没有容器使用 8.2.2 挂载目录在使用docker run时，加上-v参数可以创建一个数据卷挂载到目标容器中去，也可以多次使用该参数挂载多个数据卷。下面创建一个容器，挂载一个数据卷。 $ sudo docker run --name=test -it -v /home/test_volume/:/home/test centos[root@6a7818f6290b /]# cd /home/[root@6a7818f6290b home]# lstest 发现容器中已经成功挂载数据卷，但是如果你对系统是CentoOS7系统，你会发现，无法访问test，说明权限不够，是因为CentOS7中的安全模块selinux把权限禁掉了，所以要在运行的时候加上特权： $ sudo docker run --name=test -it --privileged=true -v /home/test_volume/:/home/test centos 这样我们就有了对容器的读写权利。（解决方法还有好多种，在后面问题总结中有所介绍。） Docker 挂载数据卷的默认权限是读写，用户也可以通过 :ro 指定为只读。 $ sudo docker run -d -P --name web -v /src/webapp:/opt/webapp:rotraining/webapp python app.py 注意：也可以在 Dockerfile 中使用 VOLUME 来添加一个或者多个新的卷到由该镜像创建的任意容器。这将在仓库服务中详细讲解。 8.2.3 挂载文件-v 标记也可以从主机挂载单个文件到容器中 $ sudo docker run --rm -it -v ~/.bash_history:/.bash_history ubuntu /bin/bash 这样就可以记录在容器输入过的命令了。 注意：如果直接挂载一个文件，很多文件编辑工具，包括 vi 或者 sed –in-place，可能会造成文件 inode 的改变，从 Docker 1.1 .0起，这会导致报错误信息。所以最简单的办法就直接挂载文件的父目录。 8.3 资源配置8.3.1 内存资源设置设置内存我们可以有四种方式： memoryinf, memory-swapinf (default) 默认的方式设置最低值，容器可以使用大于此最低值的内存数 memoryLinf, memory-swapinf 设置memory不能使用超过L的值。 memoryLinf, memory-swap2*L memoryLinf, memory-swapSinf, LS memory不能超过L，swap＋memory总使用量不能超过S 例子： $ sudo docker run -ti centos binbash 默认不设置任何限制。(第一种情况) $ sudo docker run -ti -m 300M --memory-swap -1 centos /bin/bash memory最多使用300M，swap没有限制 $ docker run -ti -m 300M centos /bin/bash 我们只设置了memory限制时300M，swap没有指定，默认被设置为与memory一样的值。memory＋swap一共是600M $ docker run -ti -m 300M --memory-swap 1G centos /bin/bash 这里我们同时设置了memory和swap ，对应第四种情况 如果发生内存溢出错误，内核讲kill掉容器中的进程。如果你想控制，可以配合使用- -oom-kill-disable参数。如果没有制定-m参数，可能导致当内存溢出时内核会杀死主机进程。 例子： 设置容器内存限制100M，并且阻止 OOM killer $ docker run -ti -m 100M --oom-kill-disable centos /bin/bash 如果不使用-m参数制定限制，官方说很危险！ 8.3.2 CPU资源设置默认情况下，所有容器获得CPU周期的比例相同。可以通过改变容器的CPU加权占有率相对于其他正在运行容器的加权占有率的比例来调整。 修改1024的比例，使用-c或–cpu-sharesflag的权重设置为2或更高。 该比例只适用在CPU密集型进程运行时。当在一个容器中的任务处于空闲状态，其他容器可以使用剩余空闲CPU时间。实际CPU时间将根据在系统上运行的容器的数目而变化。 例如，考虑三个容器的情况，一个拥有cpu的1024和另外两个有512 CPU共享时间，三个容器进程都尝试使用100％的CPU，第一个容器将获得的50％总的CPU时间。如果您添加CPU值为1024的第四个容器中，第一个容器只得到了CPU的33％。剩余的容器将分别占用CPU的16.5％，16.5％和33％。 在多核心系统中，CPU时间的份额分布在所有CPU核心。即使容器被限制为CPU时间小于100％时，它可以使用每个单独的CPU核心的100％。例如，在一个拥有超过三个核心的系统中， 如果启动一个容器设置-c＝512跑一个进程，另外一个设置-c1024,跑2个进程，内存分配将会如下配置： PID container CPU CPU share100 C0 0 100% of CPU0101 C1 1 100% of CPU1102 C1 2 100% of CPU2 –cpu-period参数 默认设置为100ms，当然我们也可以自己设置cpu周期，限制容器CPU用量。通常该参数伴随–cpu-quota参数使用。 –cpu-quota参数 限制CPU用量。默认值0，意味着允许容器获得1个CPU的100%的资源量。设置50000限制CPU资源的50%。 $ sudo docker run -ti --cpu-period=50000 --cpu-quota=25000 centos /bin/bash 如果是单核心系统，将意味着容器将每50ms获得50%运行周期。 –cpuset参数 设置容器允许运行的cpu号（在多核心系统中）： 设置容器在CPU1和CPU3上运行 $ sudo docker run -ti --cpuset-cpus=1,3 centos /bin/bash 设置容器在CPU0、CPU1、CPU2上运行 $ sudo docker run -ti --cpuset-cpus=0-2 centos /bin/bash 设置容器在指定mems上执行（只在NUMA系统中有效）： 容器只能在memory nodes 1和2上运行 $ sudo docker run -ti --cpuset-mems=1,3 centos /bin/bash –bkio-weight参数 默认情况下，所有容器获得相同比例的blokIO带宽，这个比例值是500。要修改此比例，使用–blkio-weight设置容器的blkio相对于其他运行容器权重。它的取值范围是10～1000。 下面的例子中，设置了两个不同blkio: $ sudo docker run -ti --name c1 --blkio-weight 300 centos /bin/bash$ sudo docker run -ti --name c2 --blkio-weight 600 centos /bin/bash 如果同时设置两个容器blockIO，利用如下指令： $ time dd if=/mnt/zerofile of=test.out bs=1M count=1024 oflag=direct You’ll find that the proportion of time is the same as the proportion of blkio weights of the two containers. Note: The blkio weight setting is only available for direct IO. Buffered IO is not currently supported. 8.4 访问互联8.4.1 外部访问容器有时候，容器要运行一些网络应用，需要外部能访问到这些应用，就需要使用-pP 参数指定一个主机端口，映射到容器端口中。其中使用P系统会分配一个随机的端口到内部容器开放的网络端口。 就拿仓库服务镜像来做例子： $ sudo docker run -d -P registryb89fc89e061dee24ac532af1890cd26e6e016545e0978b01d3d4eadca67119aa$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb89fc89e061d registry:latest docker-registry 5 seconds ago Up 4 seconds 0.0.0.0:32768-5000/tcp focused_brown$ curl 192.168.4.100:32768/v1/searchnum_results: 0, query: , results: [][root@registry liugang]#$ sudo docker logs b89fc89e061d[2015-08-18 00:11:41 +0000] [1] [INFO] Starting gunicorn 19.1.1[2015-08-18 00:11:41 +0000] [1] [INFO] Listening at: http://0.0.0.0:5000 (1) 我们可以看到，当我们加上-P时，docker会任意指定一个一个端口指定到容器的开放端口5000上。从容器到运行日志也是可以看出，在容器的5000端口会有一个监听。当我们通过外网的，也就是宿主机的IP 和端口就可以访问到该容器内提供的服务，这里是仓库服务。 -p（小写的）则可以指定要映射的端口，并且，在一个指定端口上只可以绑定一个容器。支持的格式有 ip:hostPort:containerPort | ip::containerPort | hostPort:containerPort。 映射所有接口地址我们用到的是 hostPort:containerPort，也就是将制定端口映射到主机地址的任意地址的指定端口： $ sudo docker run -d -p 80:5000 registrya7abe89606427e3cb90698a6d302e8$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa7abe8960642 registry:latest docker-registry 4 seconds ago Up 3 seconds 0.0.0.0:80-5000/tcp ecstatic_wright2abb0f04066999adff36b13be2e380c3de 我们将主机80端口映射到容器，这样我们直接用主机地址就可以访问到容器了。 映射到指定地址的指定端口可以使用 ip:hostPort:containerPort 格式指定映射使用一个特定地址，比如 localhost 地址 127.0.0.1 $ sudo docker run -d -p 127.0.0.1:5000:5000 registry9f11390c1e9d048f7d82ff6bfb7e65f5531865343a5a2e6b660c0634e90eda26$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9f11390c1e9d registry:latest docker-registry 6 seconds ago Up 5 seconds 127.0.0.1:5000-5000/tcp romantic_carson 映射到指定地址的任意端口使用 ip::containerPort 绑定 localhost 的任意端口到容器的 5000 端口，本地主机会自动分配一个端口。 $ sudo sudo docker run -d -p 127.0.0.1::5000 registryd8cd77ecc45f434ab9edc0a7e83514ef7cb019fabc9bdbc0b522bb916b309789$ sudo docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESd8cd77ecc45f registry:latest docker-registry 4 seconds ago Up 3 seconds 127.0.0.1:32768-5000/tcp grave_carson 从上面看出，此时docker默认的传输协议是tcp方式，我们也可以改为其他方式标记： $ sudo docker run --name=test_port -d -p 127.0.0.1:5000:5000/udp registry 使用 docker port 查看端口信息$ docker port test_port5000/udp - 127.0.0.1:5000 注意： 容器有自己的内部网络和 ip 地址（使用 docker inspect 可以获取所有的变量，Docker 还可以有一个可变的网络配置。） -p 标记可以多次使用来绑定多个端口 8.4.2 容器间通信容器在使用Docker的时候我们会常常碰到这么一种应用，就是我需要两个或多个容器，其中某些容器需要使用另外一些容器提供的服务。所以，我们要考虑的问题时如何建立两个容器间通信。 容器的连接（linking） 系统是除了端口映射外，另一种跟容器中应用交互的方式。 该系统会在源和接收容器之间创建一个隧道，接收容器可以看到源容器指定的信息。 首先我们先创建一个容器(这里我只是用作示范,没有使用官方示例的镜像，所谓但数据容器内并没有提供数据服务，官方例子我举出来也没啥意思) 创建数据访问容器db： $ sudo docker run -idt --name=db centos600886c7c69dc4979bdfee19d82331879d71835f794db110eb3b5ea3c164bd30 使用–linkname:alias name就是要访问的目标机器，alias就是自定的别名 $ sudo docker run -it --name=web --link=db:test_link centos[root@8d92293a65e9 /]# cat /etc/hosts172.17.0.12 8d92293a65e9127.0.0.1 localhost::1 localhost ip6-localhost ip6-loopbackfe00::0 ip6-localnetff00::0 ip6-mcastprefixff02::1 ip6-allnodesff02::2 ip6-allrouters172.17.0.11 test_link 600886c7c69d db 我们看到容器内的hosts 内多了一条信息 172.17.0.11 test_link 600886c7c69d db 这就意味着我们可以访问到db容器进行通信。"},{"title":"9. Docker 高级网络配置","path":"/wiki/docker/network.html","content":"9. Docker 高级网络配置当docker启动时，它会在宿主机器上创建一个名为docker0的虚拟网络接口。它会从RFC 1918定义的私有地址中随机选择一个主机不用的地址和子网掩码，并将它分配给docker0。 例如我启动docker几分钟后它选择了172.17.42.116－一个16位的子网掩码为主机和它的容器提供了65,534个ip地址。 注意: 本文讨论了Docker的高级网络配置和选项。通常你不会用到这些。如果你想查看一个较为简单的Docker网络介绍和容器概念介绍来着手，请参见Dockers快速入门. 但docker0并不是正常的网络接口。它只是一个在绑定到这上面的其他网卡间自动转发数据包的虚拟以太网桥。它可以使容器与主机相互通信。每次Docker创建一个容器，它就会创建一对对等接口(peer interface)，类似于一个管子的两端－在这边可以收到另一边发送的数据包。Docker会将对等接口中的一个做为eth0接口连接到容器上，并使用类似于vethAQI2QT这样的惟一名称来持有另一个，该名称取决于主机的命名空间。通过将所有veth＊接口绑定到docker0桥接网卡上，Docker在主机和所有Docker容器间创建一个共享的虚拟子网。 本文将会讲解使用Docker选项的所有方式，并且在高级模式下使用纯linux网线配置命令来调整，补充，或完全替代Docker的默认网络配置。 Docker选项快速指南 这里有一份关于Docker网络配置的命令行选项列表，省去您查找相关资料的麻烦。 一些网络配置的命令行选项只能在服务器启动时提供给Docker服务器。并且一旦启动起来就无法改变。 一些网络配置命令选项只能在启动时提供给Docker服务器，并且在运行中不能改变: -b BRIDGE或–bridgeBRIDGE –bipCIDR -H SOCKET…或–hostSOCKET…— 它看起来像是在设置容器的网络，但实际却恰恰相反：它告诉Docker服务器要接收命令的通道，例如“run container”和”stop container”。 –icctrue|false –ipIP_ADDRESS –ip-forwardtrue|false –iptablestrue|false –mtuBYTES 有两个网络配置选项可以在启动时或调用docker run时设置。当在启动时设置它会成为docker run的默认值: –dnsIP_ADDRESS… –dns-searchDOMAIN… 最后，一些网络配置选项只能在调用docker run时指出，因为它们要为每个容器做特定的配置: –linkCONTAINER_NAME:ALIAS –netbridge|none|container:NAME_or_ID|host -p SPECor–publishSPEC -P或–publish-alltrue|false 9.1 Docker 创建网络步骤Docker是正在发展中的，并会持续提升网络配置的逻辑。当前命令行是很难满足Docker新建容器时所需要的网络配置。 让我们回顾一些基础知识。 通讯的时候使用网际协议（IP），一个机器需要访问至少一个网络接口用来发送和接收包，路由表定义了通过接口可达IP地址范围。网络接口不一定非是物理设备。实际上，在每一个Linux机器（和每个Docker容器内部）的lo回环接口都是有效的而且完全是虚拟的——Linux内核简单地拷贝回环（数据）包，直接从发送者的内存放入接收者的内存。 Docker使用特殊的虚拟接口让容器在主机间通讯——成对的虚拟接口被叫做“peers”，它被链接到主机内核的内部，因此（数据）包能在他们之间传输。他们简单创建，待会儿我们将会看到。 Docker配置容器的步骤是： 创建一对虚拟接口 在主Docker主机内部给它一个唯一的名称，比如veth65f9，绑定它到docker0或者Docker使用的任何网桥上 让其他的接口翻墙进入新的容器（已经提供了lo接口），在容器的独立和唯一网络接口命名空间内，重新命名它为更漂亮的名字eth0，名称不要和其他的物理接口冲突。 设置接口的MAC地址，具体使用–mac-address 命令指定或者随机一个。 在网桥的网络地址访问内给容器的eth0一个新的IP地址，**设置它的缺省路由为Docker主机在网桥上拥有的IP地址。**使用–default-gateway 设置默认路由来允许该地址向Docker deamon 来转发数据，否则将使用网桥定义的IP地址来转发（docker0）。除非自定义，否则MAC地址是根据IP来生成的。当一个新的容器使用已经分配过的IP（另一个具有不同MAC地址的容器）地址启动的时候，这将可以有效防止ARP缓存失效的问题。 这些步骤结束后，容器将立即拥有一个eth0（虚拟）网卡，并会发现它自己可以和其他的容器以及互联网通讯。 你可以使用 –net 这个选项来执行 docker run 启动一个容器，这个选项有一下可选参数。 --net=bridge— 默认选项，用网桥的方式来连接docker容器。 --net=host— 高数docker跳过配置容器的独立网络栈。本质上来说，这个参数告诉docker不去打包容器的网络层。当然，docker 容器的进程仍然被限制在它自己独有的文件系统、进程列表以及其他资源中。一个快速命令 ip addr 将像你展示docker的网络，它是建立在docker 宿主主机上的，有完整的权限去访问宿主主机的网络接口。注意这不意味着docker容器可以去重新配置宿主主机的网络栈，重新配置是需要 –privalegedtrue 这个选项参数的，但是这个选项参数会让docker容器打开大量的端口以及其他的系统的超级管理权限的进程。这也会允许容器去访问宿主主机的网络服务，比如 D-bus。这会使docker容器里的进程有有权限去做一些意想不到的事，比如重启你的宿主主机。所以要谨慎使用这个选项参数。 --net=container:NAME_or_ID— 告诉docker让这个新建的容器使用已有容器的网络配置。这个新建的容器将配置新的自己的文件系统和进程列表以及其他资源限制，但是将共享这个指定的容器的网络IP地址以及端口号，使得这两个容器可以通过 loopback接口相互访问。 --net=none— 告诉docker为新建的容器建立一个网络栈，但不对这个网络栈进行任何配置，在这个文档的最后将介绍如何让你去建立自定义的网络配置。 去了解以下这一步是非常必要的，如果你在建立容器的时候使用 --net=none 这个选项参数。以下是一些命令去去配置自定义网络，就好像你让docker完全去自己配置一样。 创建一个不带任何网络配置的网络： $ docker run -i -t --rm --net=none base /bin/bashroot@63f36fc01b5f:/# 重新开启一个窗口，获取容器的pid以在var/run/netns/下便创建网络，以下会用到ip netns命令： $ docker inspect -f .State.Pid 63f36fc01b5f$ pid=2778$ sudo mkdir -p /var/run/netns$ sudo ln -s /proc/$pid/ns/net /var/run/netns/$pid 检查主机的网桥是否启用： $ ip addr show docker021: docker0: ...inet 172.17.42.1/16 scope global docker0... 创建一对（peers）网络接口A和B并绑定，然后启动，其中A是在主机上，B放在容器里： $ sudo ip link add A type veth peer name B$ sudo brctl addif docker0 A$ sudo ip link set A up 覆盖容器的网络名字空间，并将B更改为eth0，以下步骤每执行完一次都可以到第一个窗口中查看网络配置状态（ip addr）： $ sudo ip link set B netns $pid$ sudo ip netns exec $pid ip link set dev B name eth0$ sudo ip netns exec $pid ip link set eth0 address 12:34:56:78:9a:bc$ sudo ip netns exec $pid ip link set eth0 up$ sudo ip netns exec $pid ip addr add 172.17.42.99/16 dev eth0$ sudo ip netns exec $pid ip route add default via 172.17.42.1 到这一步你的容器应该可以正常运行网络操作了。 当你最后退出shell以及清理掉这个容器的时候，这个容器的虚拟网络 eth0 将在网络接口A 被清除后被消除，也会自动在网桥docker0上销毁。所以不用你执行其他的命令，所有的东西将被清理。当然，是几乎所有的东西： # Clean up dangling symlinks in /var/run/netnsfind -L /var/run/netns -type l -delete 还要注意上面的脚本使用了现代的ip命令行替代旧的弃用的封装，类似ipconfig和route，些老的命令行还是会一直呆在我们的容器内部工作。如果你嫌麻烦，ip addr命令行也可以只键入ip a。 总之，**注意这个ip netns exec重要的命令行，它让我们以root用户进入内部并配置一个网络命名空间。**如果在容器内部运行，类似的命令行可能不会工作，因为安全容器化的部分是Docker剥离容器的处理过程，这个过程要正确地配置自己的网络。 *使用ip netns exec可以让我们完成配置，还避免了运行容器自身--privileged=true的危险步骤。 9.2 Docker 定制网桥9.2.1 定制网桥docker0默认地，docker服务会在linux内核新建一个网络桥接docker0，使得物理主机和其他虚拟网络接口之间可以传递发送数据包，因此，这表现如一个独立的网络。 docker0有一个IP地址和子网掩码，使得物理主机可以从容器的桥接网络接收和发送数据包。并且给这个桥接网络一个MTU（最大传输单元）或者说网络接口允许的最大包长度-例如1,500 bytes 或者从docker的宿主主机上的网络接口拷贝的数值。在服务启动的时候两者都是可配置的： –bipCIDR— 为docker0桥接网络提供一个特殊的IP地址和一个子网掩码, 使用标准的 CIDR 记法例如192.168.1.524. –mtuBYTES— 从写docker0的最大数据包长度。 在ubuntu系统上，你可以增加以上的配置到 etcdefaultdocker 文件中的DOCKER_OPTS参数中，然后重启docker服务。 当你有一个或多个正常运行的容器时，你可以通过在主机上运行brct1命令，观察interfaces列的输出，来确定Docker已经将这些容器正确地连接到docker0网桥。下面是一个连接了两个不同容器的主机： $ sudo brctl showbridge name bridge id STP enabled interfacesdocker0 8000.3a1d7362b4ee no veth65f9 vethdda6 最后，每次新建一个容器的时候都会用到docker0 桥接网络。每次在执行docker run命令新建一个容器的时候，docker从可利用的桥接网络中随机选择一个未被使用的IP地址，以及使用桥接网络的子网掩码，用来配置容器 eth0网络接口。docker宿主主机的IP地址被docker容器作为默认的网关。 $ docker run -i -t --rm base /bin/bash[root@e623fd7cf734 /] ip addr show eth024: eth0: BROADCAST,UP,LOWER_UP mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 32:6f:e0:35:57:91 brd ff:ff:ff:ff:ff:ff inet 172.17.0.3/16 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::306f:e0ff:fe35:5791/64 scope link valid_lft forever preferred_lft forever[root@e623fd7cf734 /] ip routedefault via 172.17.42.1 dev eth0172.17.0.0/16 dev eth0 proto kernel scope link src 172.17.0.3[root@e623fd7cf734 /] exit 9.2.2 建立你自己的桥接网络如果你希望建立完整的自己的桥接网络，你可以在启动docker之前用 -b BRIDGE 或者 –bridgeBRIDGE选项参数高数docker使用你自己的桥接网络。 如果你已经用docker0启动docker了，你需要停止docker服务然后移除docker0. $ sudo service docker stop$ sudo ip link set dev docker0 down$ sudo brctl delbr docker0$ sudo iptables -t nat -F POSTROUTING 然后，在启动docker服务之前，新建你自己的桥接网络，写上你想要的配置。接下来我们新建一个简单的桥接网络，刚好用这些选项来定做docker0 ，这刚好足够说明这个技术。 $ sudo brctl addbr bridge0$ sudo ip addr add 192.168.4.1/24 dev bridge0$ sudo ip link set dev bridge0 upChain POSTROUTING (policy ACCEPT)target prot opt source destinationMASQUERADE all -- 192.168.4.0/24 0.0.0.0/0 创建好网桥之后在docker配置文件中写入启动参数，或者手动指定： $ sudo docker -d --bridge=bridge0 这样我们自己定义的网桥就做好了，当利用docker run启动容器时，会自动绑定网络到bridge0上： $ sudo docker run -it --rm centos[root@e623fd7cf734 /]# ip addr1: lo: LOOPBACK,UP,LOWER_UP mtu 65536 qdisc noqueue state UNKNOWN link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever40: eth0: BROADCAST,MULTICAST,UP,LOWER_UP mtu 1500 qdisc noqueue state UP link/ether 02:42:c0:a8:04:02 brd ff:ff:ff:ff:ff:ff inet 192.168.4.2/24 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::42:c0ff:fea8:402/64 scope link valid_lft forever preferred_lft forever 我们可以看到新的网桥已经生效。 9.3 Docker 容器通信9.3.1 容器与外部网络通信决定容器是否可以访问外网取决于两个因素： 主机是否会转发IP数据包。这取决于转发系统内的ip_forward这个参数的配置。如果ip_forward值为1，数据包就可以被转发。Docker会使用–ip_forwardtrue的默认设置，一旦你docker服务启动docker会将系统的ip_forward的值修改为1。使用-ip_forwardfalse对系统没有改变。通常设置方法如下： $ sysctl net.ipv4.conf.all.forwardingnet.ipv4.conf.all.forwarding = 0$ sysctl net.ipv4.conf.all.forwarding=1$ sysctl net.ipv4.conf.all.forwardingnet.ipv4.conf.all.forwarding = 1 设置这个值很重要，它将决定你的容器是否可以与外部通信以及容器间的通信。在多网桥系统中，内嵌的容器也需要配置此项。 你的iptables防火墙是否允许特殊连接。当deamon启动的时候，如果你设置–iptablesfalse，Docker将不会改变主机的iptables的防火墙规则。否则，Docker将追加规则到DOCKER filter chain Docker 不会删除或修改已经存在在DOCKER filter chain中的规则。这允许用户进一步创建限制访问容器的任何规则。 Docker的默认规则是允许所有的外部IPs。如果只是想允许一个IP连接到容器，在DOCKER filter chain的顶部增加一条否定规则： $ iptables -I DOCKER -i ext_if ! -s 8.8.8.8 -j DROP 这将只允许 8.8.8.8这个IP连接到容器。 9.3.2 容器间互相访问决定容器能否互相访在系统层面上问取决于两个因素： 网络的拓扑结构是否已经连接到容器的网络接口。默认情况下，Docker会把所有的容器附加到docker0网桥下，并为两个容器间的包传输提供路径。 iptables是否允许特殊连接?如果你把设置 –iptablesfalse,当守护进程启动时，Docker不会改变你的系统iptables规则。另外，如果你保留默认设置 –icctrue，Docker服务器或向FORWARD链添加一个带有全局ACCEPT策略的默认规则。如果不保留默认设置即–iccfalse，系统会把策略设为DROP. 使用docker都希望ip_forward 是打开的，至少使容器间的通讯成为可能。 但是否同意 –icctrue 或者更改为 –iccfalse 使得iptables 可以保护容器以及宿主主机不被任意地端口扫描、避免被已经被渗透的容器所访问，这是一个策略问题。 （在ubuntu，是编辑etcdefaultdocker文件中的DOCKER_OPTS参数，然后重启docker服务） 如果你选择最安全的设置 –iccfalse ，那么当你想让它们彼此提供服务的时候如何让它们相互通讯？ **答案是：**使用前文提到的 –linkCONTAINER_NAME:ALIAS 选项。如果docker守护进程正在以 –iccfalse 和 –iptablestrue 参数运行，当以选项 –link 执行 docker run 命令时，docker服务将插入一部分 iptables ACCEPT 规则使得新容器可以连接其他容器所暴露出来的端口（此端口指前文在 Dockerfile 中提到的EXPOSE这一行）。更多详细文档介绍请看：容器互联。 注意: –link 选项中的 CONTAINER_NAME 的值必须是 docker自动分配的容器名称，比如stupefied_pare，或者是在执行docker run 的时候用–name指定的容器名称. 这不能使一个docker无法识别的主机名 你可以在你的Docker主机上运行iptables命令，来观察FORWARD链是否有默认的ACCEPT或DROP策略 # When --icc=false, you should see a DROP rule:$ sudo iptables -L -n...Chain FORWARD (policy ACCEPT)target prot opt source destinationDOCKER all -- 0.0.0.0/0 0.0.0.0/0DROP all -- 0.0.0.0/0 0.0.0.0/0...# When a --link= has been created under --icc=false,# you should see port-specific ACCEPT rules overriding# the subsequent DROP policy for all other packets:$ sudo iptables -L -n...Chain FORWARD (policy ACCEPT)target prot opt source destinationDOCKER all -- 0.0.0.0/0 0.0.0.0/0DROP all -- 0.0.0.0/0 0.0.0.0/0Chain DOCKER (1 references)target prot opt source destinationACCEPT tcp -- 172.17.0.2 172.17.0.3 tcp spt:80ACCEPT tcp -- 172.17.0.3 172.17.0.2 tcp dpt:80 9.4 配置DNS怎样为Docker提供的每一个容器进行主机名和DNS配置，而不必建立自定义镜像并将主机名写 到里面？它的诀窍是覆盖三个至关重要的在etc下的容器内的虚拟文件，那几个文件可以写入 新的信息。你可以在容器内部运行mount看到这个： $$ mount.../dev/disk/by-uuid/1fec...ebdf on /etc/hostname type ext4 .../dev/disk/by-uuid/1fec...ebdf on /etc/hosts type ext4 .../dev/disk/by-uuid/1fec...ebdf on /etc/resolv.conf type ext4 ...... HCP配置之后，保持resolv.conf的数据到所有的容器中。Docker怎样维护在容器内的这些文件从Docker的一个版本到下一个版本的具体细节，你应该抛开这些单独的文件本身并且使用下面的Docker选项代替。 有四种不同的选项会影响容器守护进程的服务名称。 -h HOSTNAME 或 –hostnameHOSTNAME –设置容器的主机名，仅本机可见。这种方式是写到etchostname ，以及etchosts 文件中，作为容器主机IP的别名，并且将显示在容器的bash中。不过这种方式设置的主机名将不容易被容器之外可见。这将不会出现在 docker ps 或者 其他的容器的etchosts 文件中。 $ sudo docker run --hostname myhost -it centos[root@myhost /]# cat /etc/hosts172.17.0.7 myhost… –linkCONTAINER_NAME:ALIAS –使用这个选项去run一个容器将在此容器的etchosts文件中增加一个主机名ALIAS，这个主机名是名为CONTAINER_NAME 的容器的IP地址的别名。这使得新容器的内部进程可以访问主机名为ALIAS的容器而不用知道它的IP。–link 关于这个选项的详细讨论请看：容器互联 –dnsIP_ADDRESS –设置DNS服务器的IP地址，写入到容器的etcresolv.conf文件中。当容器中的进程尝试访问不在etchosts文件中的主机A时，容器将以53端口连接到IP_ADDRESS这个DNS服务器去搜寻主机A的IP地址。 $ sudo docker run -it --dns=192.168.5.1 centos[root@6a38049c9052 /]# cat /etc/resolv.confnameserver 192.168.5.1 –dns-searchDOMAIN –设置DNS服务器的搜索域，以防容器尝试访问不完整的主机名时从中检索相应的IP。这是写入到容器的etcresolv.conf文件中的。当容器尝试访问主机 host，而DNS搜索域被设置为 example.com ,那么DNS将不仅去查寻host主机的IP，还去查询host.example.com的IP。 $ sudo docker run -it --dns-search=www.domain.com centos[root@ae0e9e99596f /]# cat /etc/resolv.confnameserver 192.168.4.1search www.mydomain.com 在docker中，如果启动容器时缺少以上最后两种选项设置时，将使得容器的etcresolv.conf文件看起来和宿主主机的etcresolv.conf文件一致。这些选项将修改默认的设置。(本宿主机在实验时有一行“nameserver 192.168.4.1”，所以默认容器的配置会与宿主机一样。) 9.5 Docker 绑定端口9.5.1 为主机绑定容器端口默认情况下，Docker容器可以连接到外部区域，但外部区域不能连接到容器。在Docker启动时，由于它在主机上创建了一个iptables伪装规则，使得每一个输出连接看起来都是由主机IP地址建立起来的。 # You can see that the Docker server creates a# masquerade rule that let containers connect# to IP addresses in the outside world:$ sudo iptables -t nat -L -n...Chain POSTROUTING (policy ACCEPT)target prot opt source destinationMASQUERADE all -- 172.17.0.0/16 0.0.0.0/0... 当调用docker run的时候，如果你想让容器接受输入连接，你需要提供特殊选项。这些选项的详细说明在 Docker 快速入门. 有两种方法可以实现。 首先，你可以提供 -P 或者–publish-alltrue|false 选项参数来执行 docker run 命令，这将会识别所有在dockerfile中暴露的端口或者–expose参数制定的端口，然后用检查端口映射，临时端口范围由procsysnetipv4ip_local_port_range内核参数配置，并且随机映射到 32768 ～ 61000 之间的主机端口。 更方便的操作是使用 -p SPEC 或者–publishSPEC 选项，这两个选项让你明确的指定docker容器的端口映射到任意的主机端口中，不局限于32768 ～ 61000. 无论如何，你应该通过审查你的NAT表，去看看docker在你的网络占做了什么。 # What your NAT rules might look like when Docker# is finished setting up a -P forward:$ iptables -t nat -L -n...Chain DOCKER (2 references)target prot opt source destinationDNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:49153 to:172.17.0.2:80# What your NAT rules might look like when Docker# is finished setting up a -p 80:80 forward:Chain DOCKER (2 references)target prot opt source destinationDNAT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:80 to:172.17.0.2:80 可以看到，docker暴露了这些容器的端口到通配IP地址：0.0.0.0 ，这个通配IP地址可以匹配宿主主机上任意一个可以进入的端口。如果你希望更多的限制，并且只允许容器服务通过特殊的宿主主机的外部网络接口来相互联系，那么你有两种选择。当你执行 docker run 命令时，你可以使用 -p IP:host_port:container_port 或者 -p IP::port来明确地绑定外部接口。 或者如果你希望dokcer永远转发到一个特殊的IP地址上，你可以编辑你的docker系统设置文件（ubuntu系统的设置方法为：编辑 etcdefaultdocker文件，改写DOCKER_OPTS参数），增加选项 –ipIP_ADDRESS 。修改完之后记得重启你的docker服务。"},{"title":"10. Docker 私有仓库","path":"/wiki/docker/registry.html","content":"10. Docker 私有仓库如果你想玩转docker，一个私有仓库是必不可少的。 本文将会搭建一个简易的私有仓库以供参考。 本文例子的主机地址是 192.168.4.121 第一步 获取官方工具官方为我们提供了一个创建仓库的工具，它是以镜像文件形式存储在官方仓库中，我们可以把它拉下来用。 $ sudo docker pull registry 第二步 启动仓库我们现在启动它,指定主机5000端口绑定 $ sudo docker -d -p 5000:5000 registry 第三步 验证这时 输入 $ curl http://192.168.4.160:5000/v1/searchnum_results: 0, query: , results: [］ 产生如上结果说明仓库服务可用。 至此，仓库的简易配置就结束了。 但是问题来了，我们pull，push的文件在哪？哈哈，原来默认情况下，会将仓库存放于容器内的tmpregistry目录下，这样如果容器被删除，则存放于容器中的镜像也会丢失，所以我们一般情况下会指定本地一个目录挂载到容器内的tmpregistry下： $ sudo docker run -d -p 5000:5000 -v /opt/data/registry:/tmp/registry registry 我们将本机的centos镜像tag一下 $ sudo docker tag centos 192.168.4.160:5000/centos:latest 这时将本地仓库push到私有仓库中去 $ sudo docker push 192.168.4.160:5000/centos 可是失败了 2015/08/05 11:01:17 Error: Invalid registry endpoint https://192.168.4.160:5000/v1/: Get https://192.168.4.160:5000/v1/_ping: dial tcp 192.168.4.160:5000: connection refused. If this private registry supports only HTTP or HTTPS with an unknown CA certificate, please add `--insecure-registry 192.168.4.160:5000` to the daemons arguments. In the case of HTTPS, if you have access to the registrys CA certificate, no need for the flag; simply place the CA certificate at /etc/docker/certs.d/192.168.4.160:5000/ca.crt 这是因为docker采用了安全机制，若想跳过此安全验证，可以在docker配置文件中添加–insecure-registry 192.168.4.160:5000该参数标记该仓库允许不安全连接，这在deamon中提到过。 修改etcsysconfigdocker文件 OPTIONS=--selinux-enabled --insecure-registry 192.168.4.160:5000 这样应该就可以了。 $ sudo docker push 192.168.4.160:5000/progriumThe push refers to a repository [192.168.4.160:5000/progrium] (len: 1)Sending image listPushing repository 192.168.4.160:5000/progrium (1 tags)511136ea3c5a: Image successfully pushedd7ac5e4f1812: Image successfully pushed2f4b4d6a4a06: Image successfully pushed83ff768040a0: Image successfully pushed6c37f792ddac: Image successfully pushede54ca5efa2e9: Image successfully pushed2d07e6ffe5ad: Image successfully pusheda2de3cd83939: Image successfully pushed8d2c32294d38: Image successfully pushed873c28292d23: Image successfully pushedPushing tag for rev [873c28292d23] on http://192.168.4.160:5000/v1/repositories/progrium/tags/latest 查看仓库内容 $ curl 192.168.4.100/v1/searchnum_results: 5, query: , results: [description: null, name: library/centos, description: null, name: library/ubuntu, description: null, name: library/busybox, description: null, name: library/postgres, description: , name: library/progrium] 说明成功了！！"},{"title":"11. DockerHub 国内加速","path":"/wiki/docker/hubproxy.html","content":"11. DockerHub 国内加速11.1 DockerHub是什么Docker Hub是 Docker 提供的一项服务，用于与您的团队查找和共享容器映像。 它是世界上最大的容器映像存储库，其中包含一系列内容源，包括容器社区开发人员，开源项目和独立软件供应商（ISV），它们在容器中构建和分发其代码。 DockerHub镜像加速器为啥不能拉取访问了？ 6月6日，上海交大的 Docker Hub 镜像加速器宣布因监管要求被下架。具体可看此通知 Dockerhub官网 官方网站：https://hub.docker.com/ 11.2 DockerHub国内镜像加速源列表国内使用 Docker 的朋友们，可能都遇到过配置镜像源来加速镜像拉取的操作。然而，最近几个月发现许多曾经常用的国内镜像站（包括各种云服务商和高校镜像站）已经无法使用。 此列表只收录目前可用的 DockerHub 镜像站和镜像加速地址，感谢这些公益服务者。 请注意！有些镜像站仅提供基础镜像或白名单镜像，如果某个加速地址无法拉取到所需的镜像，可以尝试切换到其他地址。有些代理站点是热心网友自费搭建的，请务必合理使用。 推荐镜像代理仓库 DockerHub镜像仓库 镜像加速器地址 本博客镜像站 https://docker.zycloud.tk 毫秒镜像 https://docker.1ms.run DaoCloud 镜像站 https://docker.m.daocloud.io 腾讯云（只支持内网访问，不支持外网域名访问加速） https://mirror.ccs.tencentyun.com 阿里云（需登录，系统分配） https://your_code.mirror.aliyuncs.com 11.3 配置Dockerhub镜像源使用教程方法一：修改配置文件 为了加速镜像拉取，使用以下命令设置 registry mirror 支持系统：Ubuntu 16.04+、Debian 8+、CentOS 7+ sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json EOF registry-mirrors: [ https://docker.zycloud.tk, https://docker.1ms.run, https://docker.m.daocloud.io ]EOFsudo systemctl daemon-reloadsudo systemctl restart docker 方法二：使用 DockerHub代理 以本博客镜像站为例：可以根据列表自行替换来测试是否拉取成功 docker pull docker.zycloud.tk/nginx:latest 说明：国内代理加速网速可能会受到一定限制 11.4 DockerHub containerd的配置文件配置文件参考： sudo tee /etc/containerd/config.toml EOF[plugins.io.containerd.grpc.v1.cri.registry] [plugins.io.containerd.grpc.v1.cri.registry.mirrors] [plugins.io.containerd.grpc.v1.cri.registry.mirrors.docker.io] endpoint = [ https://docker.zycloud.tk, https://docker.1ms.run, https://docker.m.daocloud.io ]EOFsudo systemctl daemon-reloadsudo systemctl restart containerd"},{"title":"12. Docker Compose教程","path":"/wiki/docker/compose.html","content":"12. Docker Compose教程本教程全面概述了用于管理容器的基本 Docker Compose 命令。无论你是 Docker 新手还是有经验的用户，本指南都将为你提供必要的知识，以便使用 Docker Compose 高效地编排和管理你的容器化应用程序。 12.1 开始使用 Docker ComposeDocker Compose 是一个强大的工具，可简化管理和部署多容器应用程序的过程。它允许你使用简单的 YAML 配置文件来定义和运行复杂的应用程序，从而更轻松地管理容器的生命周期。 了解 Docker ComposeDocker Compose 是 Docker 生态系统的一部分。它用于定义和运行多容器 Docker 应用程序。使用 Docker Compose，你可以创建一个单一的配置文件，该文件定义应用程序所需的所有服务、网络和卷，从而轻松地整体部署和管理应用程序。 安装 Docker Compose要在 Ubuntu 22.04 系统上安装 Docker Compose，你可以按照以下步骤操作： sudo curl -L https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose 这将下载最新版本的 Docker Compose 并将其安装到你的系统上。 创建 Docker Compose 文件Docker Compose 的核心是 YAML 配置文件，通常命名为 docker-compose.yml。此文件定义构成应用程序的服务、网络和卷。以下是一个示例： version: 3services: web: image: nginx:latest ports: - 80:80 db: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: password 此配置文件定义了两个服务：运行 Nginx 的 Web 服务器和 MySQL 数据库。 运行 Docker Compose 应用程序创建 docker-compose.yml 文件后，你可以使用以下命令启动应用程序： docker-compose up -d AI讲解 立即练习 这将以分离模式启动配置文件中定义的所有服务，使你能够继续使用终端。 扩展和管理容器Docker Compose 还使你能够通过增加或减少特定服务的副本数量来轻松扩展应用程序。你可以使用 docker-compose scale 命令来实现： docker-compose scale web=3 AI 这将把 web 服务扩展到 3 个副本。 12.2 Docker Compose 命令Docker Compose 提供了一系列用于管理容器的命令。以下是一些你应该了解的最重要的命令： 构建和启动容器 docker-compose build：构建或重新构建服务。 docker-compose up：启动所有服务。 docker-compose up -d：以分离模式启动所有服务。 停止和移除容器 docker-compose stop：停止正在运行的服务。 docker-compose down：停止并移除容器、网络、镜像和卷。 列出和检查容器 docker-compose ps：列出所有正在运行的容器。 docker-compose logs：显示服务的日志输出。 docker-compose config：验证并查看 Compose 文件。 扩展和更新容器 docker-compose scale：向上或向下扩展服务。 docker-compose up --scale web=3：将 web 服务扩展到 3 个副本。 docker-compose pull：拉取服务的最新镜像。 docker-compose push：推送服务镜像。 管理卷和网络 docker-compose volume ls：列出所有卷。 docker-compose volume rm：移除一个或多个卷。 docker-compose network ls：列出所有网络。 docker-compose network rm：移除一个或多个网络。 这些命令提供了一套全面的工具来管理基于 Docker Compose 的应用程序。通过理解和使用这些命令，你可以有效地管理容器的生命周期，并确保多容器应用程序的顺利运行。 12.3 Docker Compose 使用的实际示例在本节中，我们将探讨一些如何使用 Docker Compose 来管理应用程序的实际示例。 示例 1：部署 Web 应用程序和数据库假设我们有一个需要 MySQL 数据库的 Web 应用程序。我们可以创建一个 docker-compose.yml 文件来定义和管理此设置： version: 3services: web: image: myapp/web:latest ports: - 80:8080 depends_on: - db db: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: password volumes: - db-data:/var/lib/mysqlvolumes: db-data: AI 在此示例中，我们有两个服务：web 和 db。web 服务运行我们的 Web 应用程序，而 db 服务运行 MySQL 数据库。depends_on 字段确保 web 服务在 db 服务之后启动。 要部署此应用程序，我们可以运行以下命令： docker-compose up -d AI 这将以分离模式启动应用程序，使你能够继续使用终端。 示例 2：扩展服务假设我们想要扩展我们的 Web 应用程序以处理更多流量。我们可以使用 docker-compose scale 命令来实现： docker-compose scale web=3 这将把 web 服务扩展到 3 个副本，使我们能够将负载分布到多个容器上。 示例 3：部署多层应用程序Docker Compose 对于管理多层应用程序特别有用，例如具有前端、后端和数据库的 Web 应用程序。以下是一个示例： version: 3services: frontend: image: myapp/frontend:latest ports: - 80:80 depends_on: - backend backend: image: myapp/backend:latest environment: DB_HOST: db depends_on: - db db: image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: password volumes: - db-data:/var/lib/mysqlvolumes: db-data: AI 在此示例中，我们有三个服务：frontend、backend 和 db。frontend 服务依赖于 backend 服务，而 backend 服务依赖于 db 服务。这确保应用程序按正确顺序部署。 通过使用 Docker Compose，你可以轻松管理多层应用程序的部署和扩展，使其成为基于容器的开发和部署的强大工具。 12.4 总结在本教程中，你已经学习了用于容器管理的关键 Docker Compose 命令，从开始使用 Docker Compose 到探索其使用的实际示例。通过掌握这些基本的 Docker Compose 命令，你可以简化容器编排流程，并确保应用程序的顺利部署和管理。"}]